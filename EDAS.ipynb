{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Librería Genética\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# Subfunciones de estimadores\n",
    "from sklearn.base import clone\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][30]\n",
    "from sklearn.base import is_classifier\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][535]\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_validation.py][346]\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][386]\n",
    "from sklearn.model_selection._search import check_cv\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_split.py][1866]\n",
    "from sklearn.model_selection._search import _check_param_grid\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][343]\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/scorer.py][250]\n",
    "from sklearn.utils.validation import _num_samples\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][105]\n",
    "from sklearn.utils.validation import indexable\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][208]\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Selección para estimadores\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metricas para estimadores\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Estimadores\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones Genéticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_param_types_maxint(params):\n",
    "\tparams_data = list(params.items())  # name_values\n",
    "\tparams_type = [isinstance(params[key][0], float) + 1 for key in params.keys()]  # gene_type\n",
    "\tparams_size = [len(params[key]) - 1 for key in params.keys()]  # maxints\n",
    "\treturn params_data, params_type, params_size\n",
    "\n",
    "\n",
    "def _initIndividual(pcls, maxints):\n",
    "\t\"\"\"[Iniciar Individuo]\n",
    "\tArguments:\n",
    "\t\tpcls {[creator.Individual]} -- [Iniciar individuo con indices aleatorios]\n",
    "\t\tmaxints {[params_size]} -- [lista de máximos índices]\n",
    "\tReturns:\n",
    "\t\t[creator.Individual] -- [Creación de individuo]\n",
    "\t\"\"\"\n",
    "\tpart = pcls(rnd.randint(0, maxint) for maxint in maxints)\n",
    "\treturn part\n",
    "\n",
    "\n",
    "def _mutIndividual(individual, maxints, prob_mutacion):\n",
    "\t\"\"\"[Mutación Individuo]\n",
    "\tArguments:\n",
    "\t\tindividual {[creator.Individual]} -- [Individuo de población]\n",
    "\t\tmaxints {[lista]} -- [lista de máximos índices]\n",
    "\t\tprob_mutacion {[float]} -- [probabilidad de mutación del gen]\n",
    "\tReturns:\n",
    "\t\t[creator.Individual] -- [Individuo mutado]\n",
    "\t\"\"\"\n",
    "\tfor i in range(len(maxints)):\n",
    "\t\tif rnd.random() < prob_mutacion:\n",
    "\t\t\tindividual[i] = rnd.randint(0, maxints[i])\n",
    "\treturn individual,\n",
    "\n",
    "\n",
    "def _cxIndividual(ind1, ind2, prob_cruce, gene_type):\n",
    "\t\"\"\"[Cruce de Individuos]\n",
    "\tArguments:\n",
    "\t\tind1 {[creator.Individual]} -- [Individuo 1]\n",
    "\t\tind2 {[creator.Individual]} -- [Individuo 2]\n",
    "\t\tindpb {[float]} -- [probabilidad de emparejar]\n",
    "\t\tgene_type {[list]} -- [tipos de dato de los parámetros, CATEGORICO o NUMERICO]\n",
    "\tReturns:\n",
    "\t\t[creator.Individual,creator.Individual] -- [nuevos Individuos]\n",
    "\t\"\"\"\n",
    "\tCATEGORICO = 1  # int o str\n",
    "\tNUMERICO = 2  # float\n",
    "\tfor i in range(len(ind1)):\n",
    "\t\tif rnd.random() < prob_cruce:\n",
    "\t\t\tif gene_type[i] == CATEGORICO:\n",
    "\t\t\t\tind1[i], ind2[i] = ind2[i], ind1[i]\n",
    "\t\t\telse:\n",
    "\t\t\t\tsorted_ind = sorted([ind1[i], ind2[i]])\n",
    "\t\t\t\tind1[i] = rnd.randint(sorted_ind[0], sorted_ind[1])\n",
    "\t\t\t\tind2[i] = rnd.randint(sorted_ind[0], sorted_ind[1])\n",
    "\treturn ind1, ind2\n",
    "\n",
    "\n",
    "def _individual_to_params(individual, name_values):\n",
    "\t\"\"\"[Set de parámetro según individuo]\n",
    "\tArguments:\n",
    "\t\tindividual {[creator.Individual]} -- [individuo]\n",
    "\t\tname_values {[list]} -- [lista de parámetros, params_data]\n",
    "\tReturns:\n",
    "\t\t[diccionario] -- [parámetros del individuo]\n",
    "\t\"\"\"\n",
    "\treturn dict((name, values[gene]) for gene, (name, values) in zip(individual, name_values))\n",
    "\n",
    "\n",
    "def _evalFunction(individual, name_values, X, y, scorer, cv, uniform, fit_params,\n",
    "\t\t\t\tverbose=0, error_score='raise', score_cache={}):\n",
    "\t\"\"\"[Evaluación del modelo]\n",
    "\tArguments:\n",
    "\t\tindividual {[creator.Individual]} -- [Individuo]\n",
    "\t\tname_values {[list]} -- [parámetros en general]\n",
    "\t\tX {[array]} -- [Input]\n",
    "\t\ty {[array]} -- [Output]\n",
    "\t\tscorer {[string]} -- [Parámetro de evaluación, precisión]\n",
    "\t\tcv {[int | cross-validation]} -- [Especificación de los folds]\n",
    "\t\tuniform {[boolean]} -- [True hace que la data se distribuya uniformemente en los folds]\n",
    "\t\tfit_params {[dict | None]} -- [parámetros para estimator.fit]\n",
    "\tKeyword Arguments:\n",
    "\t\tverbose {integer} -- [Mensajes de descripción] (default: {0})\n",
    "\t\terror_score {numerico} -- [valor asignado si ocurre un error en fitting] (default: {'raise'})\n",
    "\t\tscore_cache {dict} -- [description] (default: {{}})\n",
    "\t\"\"\"\n",
    "\tparameters = _individual_to_params(individual, name_values)\n",
    "\tscore = 0\n",
    "\tn_test = 0\n",
    "\tparamkey = str(individual)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tfor train, test in cv.split(X, y):\n",
    "\t\t\t_score = _fit_and_score(estimator=individual.est, X=X, y=y, scorer=scorer,\n",
    "\t\t\t\t\t\ttrain=train, test=test, verbose=verbose,\n",
    "\t\t\t\t\t\tparameters=parameters, fit_params=fit_params,\n",
    "\t\t\t\t\t\terror_score=error_score)[0]\n",
    "\t\t\tif uniform:\n",
    "\t\t\t\tscore += _score * len(test)\n",
    "\t\t\t\tn_test += len(test)\n",
    "\t\t\telse:\n",
    "\t\t\t\tscore += _score\n",
    "\t\t\t\tn_test += 1\n",
    "\t\tassert n_test > 0, \"No se completo el fitting, Verificar data.\"\n",
    "\t\tscore /= float(n_test)\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\treturn (score,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
