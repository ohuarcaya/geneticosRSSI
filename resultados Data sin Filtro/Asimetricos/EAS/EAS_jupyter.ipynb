{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Librería Genética\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Subfunciones de estimadores\n",
    "from sklearn.base import clone\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][30]\n",
    "from sklearn.base import is_classifier\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][535]\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_validation.py][346]\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][386]\n",
    "from sklearn.model_selection._search import check_cv\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_split.py][1866]\n",
    "from sklearn.model_selection._search import _check_param_grid\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][343]\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/scorer.py][250]\n",
    "from sklearn.utils.validation import _num_samples\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][105]\n",
    "from sklearn.utils.validation import indexable\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][208]\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "\n",
    "# Selección para estimadores\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metricas para estimadores\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Estimadores\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Ensembles algorithms\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# find distance error al 0.2%\n",
    "def distance_error(estimator, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 7)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    # coord pred\n",
    "    x1 = np.int32((y_pred + 2) % 3)\n",
    "    y1 = np.int32((y_pred - 1) / 3)\n",
    "    # coord real\n",
    "    x2 = np.int32((y_test + 2) % 3)\n",
    "    y2 = np.int32((y_test - 1) / 3)\n",
    "    # pasar variacion a distancias metros\n",
    "    vx = np.abs(x1 - x2)*1.5\n",
    "    vy = np.abs(y1 - y2)*1.5\n",
    "    #vx = vx*0.5 + (vx-1)*(vx>0)\n",
    "    #vy = vy*0.5 + (vy-1)*(vy>0)\n",
    "    # pitagoras\n",
    "    err_distance = np.sqrt(vx*vx + vy*vy)\n",
    "    return err_distance\n",
    "\n",
    "def _createDataset(frecuencias, values, seed = 7):\n",
    "    # crear dataset\n",
    "    names_ = frecuencias[0].columns.values\n",
    "    # reestructuracion\n",
    "    salida_final = pd.DataFrame(columns=names_)\n",
    "    for sec in range(1,16):\n",
    "        dataset = pd.DataFrame(columns=names_)\n",
    "        corte = min([frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values])\n",
    "        tx = 0\n",
    "        dataset[names_[tx]] = dataset[names_[tx]].append(frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]])\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        for tx in range(1,5):\n",
    "            dataset[names_[tx]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]].reset_index()\n",
    "        dataset[names_[tx+1]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx+1]].reset_index()\n",
    "        # join parts\n",
    "        salida_final = salida_final.append(dataset)\n",
    "    # shuffle dataset\n",
    "    salida_final = shuffle(salida_final, random_state=seed).reset_index(drop=True)\n",
    "    salida_final = salida_final.apply(pd.to_numeric)\n",
    "    # dataframe to X,y \n",
    "    X = salida_final[names_[:-1]]\n",
    "    y = salida_final[names_[-1]]\n",
    "    return X,y\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    # LDA : Warning(Variables are collinear)\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    #\"\"\"\n",
    "    models.append(('SVC', SVC(random_state=rs)))\n",
    "    models.append(('GaussianNB', GaussianNB()))\n",
    "    models.append(('MLPClassifier', MLPClassifier()))\n",
    "    #\"\"\"\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    #\"\"\"\n",
    "    models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=rs)))\n",
    "    models.append(('LogisticRegression', LogisticRegression()))\n",
    "    # Bagging and Boosting\n",
    "    # models.append(('ExtraTreesClassifier', ExtraTreesClassifier(n_estimators=150)))\n",
    "    models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state=rs)))\n",
    "    models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier(random_state=rs),\n",
    "                                                            random_state=rs)))\n",
    "    # models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier())))\n",
    "    models.append(('RandomForestClassifier', RandomForestClassifier(random_state=rs)))\n",
    "    models.append(('GradientBoostingClassifier',\n",
    "                   GradientBoostingClassifier(random_state=rs)))\n",
    "    # models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "    # Voting\n",
    "    estimators = []\n",
    "    estimators.append((\"Voting_GradientBoostingClassifier\", GradientBoostingClassifier(random_state=rs)))\n",
    "    estimators.append((\"Voting_ExtraTreesClassifier\", ExtraTreesClassifier(random_state=rs)))\n",
    "    voting = VotingClassifier(estimators)\n",
    "    models.append(('VotingClassifier', voting))\n",
    "    #\"\"\"\n",
    "    return models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _initIndividual(individuo, maxints):\n",
    "\t\"\"\"[Iniciar Individuo]\n",
    "\tArguments:\n",
    "\t\tpcls {[creator.Individual]} -- [Iniciar individuo con indices aleatorios]\n",
    "\t\tmaxints {[params_size]} -- [lista de máximos índices]\n",
    "\tReturns:\n",
    "\t\t[creator.Individual] -- [Creación de individuo]\n",
    "\t\"\"\"\n",
    "\treturn individuo(rnd.randint(0, maxint) for maxint in maxints)\n",
    "\n",
    "def _mutIndividual(individual, maxints, prob_mutacion):\n",
    "\t\"\"\"[Mutación Individuo]\n",
    "\tArguments:\n",
    "\t\tindividual {[creator.Individual]} -- [Individuo de población]\n",
    "\t\tmaxints {[lista]} -- [lista de máximos índices]\n",
    "\t\tprob_mutacion {[float]} -- [probabilidad de mutación del gen]\n",
    "\tReturns:\n",
    "\t\t[creator.Individual] -- [Individuo mutado]\n",
    "\t\"\"\"\n",
    "\tfor i in range(len(maxints)):\n",
    "\t\tif rnd.random() < prob_mutacion:\n",
    "\t\t\tindividual[i] = rnd.randint(0, maxints[i])\n",
    "\treturn individual,\n",
    "\n",
    "def _cxIndividual(ind1, ind2, prob_cruce):\n",
    "\t\"\"\"[Cruce de Individuos]\n",
    "\tArguments:\n",
    "\t\tind1 {[creator.Individual]} -- [Individuo 1]\n",
    "\t\tind2 {[creator.Individual]} -- [Individuo 2]\n",
    "\t\tindpb {[float]} -- [probabilidad de emparejar]\n",
    "\t\tgene_type {[list]} -- [tipos de dato de los parámetros, CATEGORICO o NUMERICO]\n",
    "\tReturns:\n",
    "\t\t[creator.Individual,creator.Individual] -- [nuevos Individuos]\n",
    "\t\"\"\"\n",
    "\tCATEGORICO = 1  # int o str\n",
    "\tNUMERICO = 2  # float\n",
    "\tfor i in range(len(ind1)):\n",
    "\t\tif rnd.random() < prob_cruce:\n",
    "\t\t\tsorted_ind = sorted([ind1[i], ind2[i]])\n",
    "\t\t\tind1[i] = rnd.randint(sorted_ind[0], sorted_ind[1])\n",
    "\t\t\tind2[i] = rnd.randint(sorted_ind[0], sorted_ind[1])\n",
    "\treturn ind1, ind2\n",
    "\n",
    "def _individual_to_params(frecuencias, values):\n",
    "    # crear dataset\n",
    "    names_ = frecuencias[0].columns.values\n",
    "    seed = 7\n",
    "    # reestructuracion\n",
    "    salida_final = pd.DataFrame(columns=names_)\n",
    "    for sec in range(1,16):\n",
    "        dataset = pd.DataFrame(columns=names_)\n",
    "        corte = min([frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values])\n",
    "        #l = [frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values]\n",
    "        #corte = max(l)\n",
    "        #tx=l.index(max(l))\n",
    "        tx = 0\n",
    "        dataset[names_[tx]] = dataset[names_[tx]].append(frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]])\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        for tx in range(1,5):\n",
    "            dataset[names_[tx]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]].reset_index(drop=True)\n",
    "        dataset[names_[tx+1]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx+1]].reset_index(drop=True)\n",
    "        # join parts\n",
    "        salida_final = salida_final.append(dataset)\n",
    "    # shuffle dataset\n",
    "    salida_final = shuffle(salida_final, random_state=seed).reset_index(drop=True)\n",
    "    salida_final = salida_final.apply(pd.to_numeric)\n",
    "    # dataframe to X,y \n",
    "    X = salida_final[names_[:-1]]\n",
    "    y = salida_final[names_[-1]]\n",
    "    return X,y\n",
    "\n",
    "def _evalFunction(individual, frecuencias, scorer, num_folds, score_cache, desv_cache, error_cache, resultados_cache):\n",
    "\t\"\"\"[Evaluación del modelo]\n",
    "\tArguments:\n",
    "\t\tindividual {[creator.Individual]} -- [Individuo]\n",
    "\t\tfrecuencias {[list]} -- [lista de dataframes]\n",
    "\t\tX {[array]} -- [Input]\n",
    "\t\ty {[array]} -- [Output]\n",
    "\t\tscorer {[string]} -- [Parámetro de evaluación, precisión]\n",
    "\t\tcv {[int | cross-validation]} -- [Especificación de los folds]\n",
    "\t\tuniform {[boolean]} -- [True hace que la data se distribuya uniformemente en los folds]\n",
    "\t\tfit_params {[dict | None]} -- [parámetros para estimator.fit]\n",
    "\tKeyword Arguments:\n",
    "\t\tverbose {integer} -- [Mensajes de descripción] (default: {0})\n",
    "\t\terror_score {numerico} -- [valor asignado si ocurre un error en fitting] (default: {'raise'})\n",
    "\t\tscore_cache {dict} -- [description] (default: {{}})\n",
    "\t\"\"\"\n",
    "\tX, y = _individual_to_params(frecuencias, individual)\n",
    "\tscore = 0\n",
    "\tn_test = 0\n",
    "\tname = str(individual.est).split('(')[0]\n",
    "\tparamkey = str(np.array(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=10, shuffle=False)\n",
    "\t\t#cv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scoring)\n",
    "\t\tcv_results = cross_val_score(individual.est, X, y, cv=kfold, scoring=scorer)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\tdesv_cache[paramkey] = cv_results.std()\n",
    "\t\tdis_err = distance_error(individual.est, X, y)\n",
    "\t\terror_cache[paramkey] = np.mean(dis_err)\n",
    "\t\tresults = {'Modelo': name, 'Configuracion':np.int32(individual)+1, 'values': cv_results, 'Accuracy': score, 'stdAccuracy': desv_cache[paramkey], 'errorMetrico': error_cache[paramkey], 'error':dis_err}  \n",
    "\t\tresultados_cache.append(results)\n",
    "\treturn (score,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EvolutiveSearchCV:\n",
    "\tdef __init__(self, estimator, scoring=None, num_folds=4,\n",
    "\t\t\t\trefit=True, verbose=False, population_size=50,\n",
    "\t\t\t\tgene_mutation_prob=0.2, gene_crossover_prob=0.5,\n",
    "\t\t\t\ttournament_size=3, generations_number=10, gene_type=None,\n",
    "\t\t\t\tn_jobs=1, uniform=True, error_score='raise',\n",
    "\t\t\t\tfit_params={}):\n",
    "\t\t# Parámetros iniciales\n",
    "\t\tself.estimator = estimator\n",
    "\t\t#self.params = params\n",
    "\t\tself.scoring = scoring\n",
    "\t\tself.num_folds = num_folds\n",
    "\t\tself.refit = refit\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.population_size = population_size\n",
    "\t\tself.gene_mutation_prob = gene_mutation_prob\n",
    "\t\tself.gene_crossover_prob = gene_crossover_prob\n",
    "\t\tself.tournament_size = tournament_size\n",
    "\t\tself.generations_number = generations_number\n",
    "\t\tself.gene_type = gene_type\n",
    "\t\tself.n_jobs = n_jobs\n",
    "\t\tself.uniform = uniform\n",
    "\t\tself.error_score = error_score\n",
    "\t\tself.fit_params = fit_params\n",
    "\t\t# Parámetros adicionales\n",
    "\t\tself._individual_evals = {}\n",
    "\t\tself.all_history_ = None\n",
    "\t\tself.all_logbooks_ = None\n",
    "\t\tself._cv_results = None\n",
    "\t\tself.best_score_ = None\n",
    "\t\tself.best_params_ = None\n",
    "\t\tself.scorer_ = None\n",
    "\t\t#self.score_cache = {}\n",
    "\t\tself.__manager = Manager()\n",
    "\t\tself.score_cache = self.__manager.dict()\n",
    "\t\tself.desv_cache = self.__manager.dict()\n",
    "\t\tself.error_cache = self.__manager.dict()\n",
    "\t\tself.resultados = self.__manager.list()\n",
    "\t\t#self.score_cache = dict()\n",
    "\t\t#self.desv_cache = dict()\n",
    "\t\t#self.error_cache = dict()\n",
    "\t\t# Fitness [base.Fitness], objetivo 1\n",
    "\t\tcreator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "\t\t# Individuo [list], parámetros:est, FinessMax\n",
    "\t\tcreator.create(\"Individual\", list, est=clone(self.estimator), fitness=creator.FitnessMax)\n",
    "\t#@property\n",
    "\tdef cv_results_(self):\n",
    "\t\tif self._cv_results is None:\n",
    "\t\t\tout = defaultdict(list)\n",
    "\t\t\tgen = self.all_history_\n",
    "\t\t\t# Get individuals and indexes, their list of scores,\n",
    "\t\t\t# and additionally the name_values for this set of parameters\n",
    "\t\t\tidxs, individuals, each_scores = zip(*[(idx, indiv, np.mean(indiv.fitness.values))\n",
    "\t\t\t\t\t\t\t\t\t\t\tfor idx, indiv in list(gen.genealogy_history.items())\n",
    "\t\t\t\t\t\t\t\t\t\t\tif indiv.fitness.valid and not np.all(np.isnan(indiv.fitness.values))])\n",
    "\t\t\t#name_values, _, _ = _get_param_types_maxint(self.params)\n",
    "\t\t\t# Add to output\n",
    "\t\t\t#out['param_index'] += [p] * len(idxs)\n",
    "\t\t\tout['index'] += idxs\n",
    "\t\t\t#out['params'] += [_individual_to_params(indiv, name_values) for indiv in individuals]\n",
    "\t\t\tout['params'] += [str(np.add(indiv,1)) for indiv in individuals]\n",
    "\t\t\tout['mean_test_score'] += [np.nanmean(scores) for scores in each_scores]\n",
    "\t\t\tout['std_test_score'] += [np.nanstd(scores) for scores in each_scores]\n",
    "\t\t\tout['min_test_score'] += [np.nanmin(scores) for scores in each_scores]\n",
    "\t\t\tout['max_test_score'] += [np.nanmax(scores) for scores in each_scores]\n",
    "\t\t\tout['nan_test_score?'] += [np.any(np.isnan(scores)) for scores in each_scores]\n",
    "\t\t\tself._cv_results = out\n",
    "\t\treturn self._cv_results\n",
    "\t@property\n",
    "\tdef best_index_(self):\n",
    "\t\treturn np.argmax(self.cv_results_['max_test_score'])\n",
    "\t# fit y refit general\n",
    "\tdef fit(self, frecuencias):\n",
    "\t\tself.best_estimator_ = None\n",
    "\t\tself.best_mem_score_ = float(\"-inf\")\n",
    "\t\tself.best_mem_params_ = None\n",
    "\t\t#_check_param_grid(self.params)\n",
    "\t\tself._fit(frecuencias)\n",
    "\t\t#if self.refit:\n",
    "\t\t#\tself.best_estimator_ = clone(self.estimator)\n",
    "\t\t#\t#self.best_estimator_.set_params(**self.best_mem_params_)\n",
    "\t\t#\tself.best_estimator_.fit(frecuencias)\n",
    "\t# fit individual\n",
    "\tdef _fit(self, frecuencias):\n",
    "\t\tself._cv_results = None  # Indicador de necesidad de actualización\n",
    "\t\tself.scorer_ = check_scoring(self.estimator, scoring=self.scoring)\n",
    "\t\t#n_samples = _num_samples(X)\n",
    "\t\t# verificar longitudes x,y \n",
    "\t\t#if _num_samples(y) != n_samples:\n",
    "\t\t#\traise ValueError('Target [y], data [X] dont agree')\n",
    "\t\t#cv = check_cv(self.cv, y=y, classifier=is_classifier(self.estimator))\n",
    "\t\ttoolbox = base.Toolbox()\n",
    "\t\t# name_values = lista de parametros, gene_type = [1:categorico; 2:numérico], maxints = size(parametros)\n",
    "\t\t#name_values, self.gene_type, maxints = _get_param_types_maxint(parameter_dict)\n",
    "\t\tmaxints = [5]*5\n",
    "\t\t#if self.verbose:\n",
    "\t\t#\tprint(\"Tipos: %s, rangos: %s\" % (self.gene_type, maxints))\n",
    "\t\t# registro de función Individuo\n",
    "\t\ttoolbox.register(\"individual\", _initIndividual, creator.Individual, maxints=maxints)\n",
    "\t\t# registro de función Población\n",
    "\t\ttoolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\t\t# Paralelísmo, create pool\n",
    "\t\tif not isinstance(self.n_jobs, int):\n",
    "\t\t\tself.n_jobs=1\n",
    "\t\tpool = Pool(self.n_jobs)\n",
    "\t\ttoolbox.register(\"map\", pool.map)\n",
    "\t\t# registro de función Evaluación\n",
    "\t\ttoolbox.register(\"evaluate\", _evalFunction,\n",
    "\t\t\t\t\t\tfrecuencias=frecuencias,\n",
    "\t\t\t\t\t\tscorer=self.scorer_, num_folds=10, \n",
    "\t\t\t\t\t\tscore_cache=self.score_cache,\n",
    "\t\t\t\t\t\tdesv_cache=self.desv_cache,\n",
    "\t\t\t\t\t\terror_cache=self.error_cache,\n",
    "\t\t\t\t\t\tresultados_cache=self.resultados)\n",
    "\t\t# registro de función Cruce\n",
    "\t\ttoolbox.register(\"mate\", _cxIndividual, prob_cruce=self.gene_crossover_prob)\n",
    "\t\t# registro de función Mutación\n",
    "\t\ttoolbox.register(\"mutate\", _mutIndividual, prob_mutacion=self.gene_mutation_prob, maxints=maxints)\n",
    "\t\t# registro de función Selección\n",
    "\t\ttoolbox.register(\"select\", tools.selTournament, tournsize=self.tournament_size)\n",
    "\t\t# Creación de Población\n",
    "\t\tpop = toolbox.population(n=self.population_size)\n",
    "\t\t# Mejor Individuo que ha existido\n",
    "\t\thof = tools.HallOfFame(1)\n",
    "\t\t# Stats\n",
    "\t\tstats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "\t\tstats.register(\"avg\", np.nanmean)\n",
    "\t\tstats.register(\"min\", np.nanmin)\n",
    "\t\tstats.register(\"max\", np.nanmax)\n",
    "\t\tstats.register(\"std\", np.nanstd)\n",
    "\t\t# Genealogía\n",
    "\t\thist = tools.History()\n",
    "\t\t# Decoración de operadores de variaznza\n",
    "\t\ttoolbox.decorate(\"mate\", hist.decorator)\n",
    "\t\ttoolbox.decorate(\"mutate\", hist.decorator)\n",
    "\t\thist.update(pop)\n",
    "\t\t# Posibles combinaciones\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint('--- Evolve in {0} possible combinations ---'.format(np.prod(np.array(maxints) + 1)))\n",
    "\t\tpop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=self.gene_crossover_prob, \n",
    "\t\t\t\t\t\t\t\t\t\tmutpb=self.gene_mutation_prob,\n",
    "\t\t\t\t\t\t\t\t\t\tngen=self.generations_number, \n",
    "\t\t\t\t\t\t\t\t\t\tstats=stats,\n",
    "\t\t\t\t\t\t\t\t\t\thalloffame=hof, \n",
    "\t\t\t\t\t\t\t\t\t\tverbose=self.verbose)\n",
    "\t\t#pop, logbook = algorithms.eaGenerateUpdate(toolbox,\n",
    "\t\t#\t\t\t\t\t\t\t\tngen=self.generations_number, stats=stats,\n",
    "\t\t#\t\t\t\t\t\t\t\thalloffame=hof, verbose=self.verbose)\n",
    "\t\t# Save History\n",
    "\t\tself.all_history_ = hist\n",
    "\t\tself.all_logbooks_ = logbook\n",
    "\t\t# Mejor score y parametros\n",
    "\t\tcurrent_best_score_ = hof[0].fitness.values[0]\n",
    "\t\tcurrent_best_params_ = str(hof[0]) #_individual_to_params(hof[0], name_values)\n",
    "\t\t#if self.verbose:\n",
    "\t\t#\tprint(\"Best individual is: %s\\nwith fitness: %s\" % (\n",
    "\t\t#\t\tcurrent_best_params_, current_best_score_))\n",
    "\t\tif current_best_score_ > self.best_mem_score_:\n",
    "\t\t\tself.best_mem_score_ = current_best_score_\n",
    "\t\t\tself.best_mem_params_ = current_best_params_\n",
    "\t\t# fin paralelización, close pool\n",
    "\t\tpool.close()\n",
    "\t\tpool.join()\n",
    "\t\tself.best_score_ = current_best_score_\n",
    "\t\tself.best_params_ = current_best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "frecuencias = []\n",
    "names_ = ['Be01', 'Be02', 'Be03', 'Be04', 'Be05', 'Sector']\n",
    "\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x01'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x02'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x03'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x04'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x05'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x06'))#, names=names_))\n",
    "\"\"\"\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx1.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx2.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx3.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx4.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx5.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx6.csv', names=names_))\n",
    "\"\"\"\n",
    "num_jobs=cpu_count()\n",
    "estimadores = set_models()\n",
    "salida = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modeling... LinearDiscriminantAnalysis\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg    \tmin   \tmax     \tstd      \n",
      "0  \t100   \t0.60339\t0.4445\t0.723288\t0.0636956\n",
      "1  \t72    \t0.64773\t0.463493\t0.746997\t0.0494812\n",
      "2  \t68    \t0.67429\t0.535698\t0.730107\t0.0361528\n",
      "3  \t74    \t0.687642\t0.522542\t0.762404\t0.0409531\n",
      "4  \t64    \t0.706598\t0.615734\t0.762404\t0.0298466\n",
      "5  \t66    \t0.713628\t0.558037\t0.771807\t0.044902 \n",
      "6  \t59    \t0.723594\t0.592665\t0.771807\t0.0395529\n",
      "7  \t72    \t0.732655\t0.524803\t0.771807\t0.0429418\n",
      "8  \t80    \t0.729652\t0.602137\t0.771807\t0.0433388\n",
      "9  \t73    \t0.742763\t0.540227\t0.771807\t0.0437117\n",
      "10 \t60    \t0.745645\t0.530167\t0.771807\t0.0472812\n",
      "\n",
      "Modeling... SVC\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax    \tstd      \n",
      "0  \t100   \t0.711878\t0.593877\t0.81467\t0.0492236\n",
      "1  \t74    \t0.75267 \t0.621088\t0.829871\t0.0370581\n",
      "2  \t70    \t0.772666\t0.684441\t0.829871\t0.0306006\n",
      "3  \t58    \t0.791893\t0.721027\t0.829871\t0.0265424\n",
      "4  \t55    \t0.805153\t0.68397 \t0.829871\t0.0266921\n",
      "5  \t61    \t0.813972\t0.674243\t0.829871\t0.0265135\n",
      "6  \t77    \t0.818762\t0.722796\t0.829871\t0.0222309\n",
      "7  \t60    \t0.814217\t0.651823\t0.829871\t0.0336188\n",
      "8  \t70    \t0.818254\t0.716725\t0.829871\t0.0258881\n",
      "9  \t70    \t0.812171\t0.670999\t0.829871\t0.0353547\n",
      "10 \t64    \t0.81366 \t0.66651 \t0.829871\t0.0344249\n",
      "\n",
      "Modeling... GaussianNB\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax    \tstd    \n",
      "0  \t100   \t0.729316\t0.601265\t0.81665\t0.04368\n",
      "1  \t61    \t0.760662\t0.661063\t0.837709\t0.0356432\n",
      "2  \t72    \t0.784025\t0.64059 \t0.859765\t0.0312339\n",
      "3  \t64    \t0.800859\t0.69093 \t0.859765\t0.0352192\n",
      "4  \t62    \t0.815598\t0.694204\t0.859765\t0.032292 \n",
      "5  \t78    \t0.826372\t0.699283\t0.859765\t0.0319361\n",
      "6  \t67    \t0.837324\t0.712821\t0.859765\t0.0316891\n",
      "7  \t61    \t0.848286\t0.752656\t0.859765\t0.0247374\n",
      "8  \t67    \t0.846631\t0.746848\t0.859765\t0.0245629\n",
      "9  \t67    \t0.838689\t0.711373\t0.859765\t0.0374321\n",
      "10 \t64    \t0.844563\t0.688435\t0.859765\t0.0317849\n",
      "\n",
      "Modeling... MLPClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.491341\t0.338491\t0.627489\t0.0626363\n",
      "1  \t74    \t0.541162\t0.400899\t0.627489\t0.0490389\n",
      "2  \t71    \t0.568237\t0.38995 \t0.653766\t0.0438817\n",
      "3  \t57    \t0.598699\t0.480617\t0.653766\t0.0352254\n",
      "4  \t68    \t0.605828\t0.420768\t0.697901\t0.039959 \n",
      "5  \t63    \t0.622714\t0.414716\t0.697901\t0.0449758\n",
      "6  \t54    \t0.626428\t0.482339\t0.697901\t0.0441656\n",
      "7  \t71    \t0.63031 \t0.443283\t0.697901\t0.059443 \n",
      "8  \t62    \t0.656266\t0.505592\t0.697901\t0.046109 \n",
      "9  \t61    \t0.670382\t0.473978\t0.697901\t0.0520117\n",
      "10 \t73    \t0.67629 \t0.439808\t0.697901\t0.0471539\n",
      "\n",
      "Modeling... KNeighborsClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.755584\t0.643531\t0.862702\t0.0470952\n",
      "1  \t64    \t0.792319\t0.700655\t0.862702\t0.0354265\n",
      "2  \t61    \t0.818669\t0.704922\t0.872901\t0.0280376\n",
      "3  \t74    \t0.826279\t0.71249 \t0.872901\t0.0307944\n",
      "4  \t60    \t0.840109\t0.775815\t0.872901\t0.0231818\n",
      "5  \t64    \t0.850262\t0.748921\t0.875878\t0.0236471\n",
      "6  \t76    \t0.85471 \t0.711823\t0.875878\t0.0265205\n",
      "7  \t58    \t0.859268\t0.774767\t0.875878\t0.0235572\n",
      "8  \t78    \t0.861527\t0.803088\t0.875878\t0.0194034\n",
      "9  \t61    \t0.859324\t0.675281\t0.875878\t0.032452 \n",
      "10 \t62    \t0.861561\t0.765535\t0.87778 \t0.0267421\n",
      "\n",
      "Modeling... DecisionTreeClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax    \tstd      \n",
      "0  \t100   \t0.731305\t0.630899\t0.82267\t0.0432932\n",
      "1  \t63    \t0.764164\t0.642592\t0.82267\t0.034963 \n",
      "2  \t58    \t0.779009\t0.669858\t0.836225\t0.0325604\n",
      "3  \t69    \t0.797295\t0.676417\t0.836225\t0.0279231\n",
      "4  \t68    \t0.812195\t0.673483\t0.836225\t0.0244642\n",
      "5  \t81    \t0.812447\t0.693982\t0.836225\t0.0286819\n",
      "6  \t69    \t0.82171 \t0.722823\t0.836225\t0.0229606\n",
      "7  \t61    \t0.825211\t0.695631\t0.859512\t0.0245959\n",
      "8  \t70    \t0.831567\t0.721583\t0.859512\t0.0164666\n",
      "9  \t70    \t0.829152\t0.718034\t0.859512\t0.0221174\n",
      "10 \t66    \t0.829041\t0.703667\t0.859512\t0.0241353\n",
      "\n",
      "Modeling... LogisticRegression\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd     \n",
      "0  \t100   \t0.553613\t0.406189\t0.692137\t0.057419\n",
      "1  \t59    \t0.604376\t0.519928\t0.692137\t0.0421099\n",
      "2  \t72    \t0.631065\t0.490099\t0.699953\t0.0466871\n",
      "3  \t67    \t0.651364\t0.526328\t0.699953\t0.0405586\n",
      "4  \t55    \t0.668432\t0.542022\t0.699953\t0.037301 \n",
      "5  \t65    \t0.665282\t0.517936\t0.699953\t0.0423312\n",
      "6  \t66    \t0.669169\t0.562688\t0.699953\t0.0383967\n",
      "7  \t63    \t0.675691\t0.465571\t0.708543\t0.0444148\n",
      "8  \t58    \t0.684923\t0.552035\t0.708543\t0.0331618\n",
      "9  \t58    \t0.684159\t0.555669\t0.708543\t0.0356223\n",
      "10 \t77    \t0.676269\t0.55577 \t0.708543\t0.0406077\n",
      "\n",
      "Modeling... ExtraTreesClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.787725\t0.666735\t0.862138\t0.0425707\n",
      "1  \t71    \t0.820648\t0.728246\t0.870845\t0.0300694\n",
      "2  \t65    \t0.839576\t0.766103\t0.882427\t0.0213923\n",
      "3  \t71    \t0.844548\t0.757526\t0.882427\t0.0244885\n",
      "4  \t63    \t0.854321\t0.772716\t0.882427\t0.0213389\n",
      "5  \t62    \t0.864146\t0.798293\t0.892472\t0.0169842\n",
      "6  \t78    \t0.860324\t0.783448\t0.892472\t0.0242422\n",
      "7  \t73    \t0.868377\t0.770112\t0.892472\t0.0228773\n",
      "8  \t60    \t0.874911\t0.819044\t0.892472\t0.0168083\n",
      "9  \t71    \t0.877504\t0.78236 \t0.892472\t0.0191019\n",
      "10 \t74    \t0.874464\t0.767229\t0.892472\t0.0264688\n",
      "\n",
      "Modeling... AdaBoostClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd     \n",
      "0  \t100   \t0.780299\t0.650812\t0.851423\t0.037723\n",
      "1  \t68    \t0.799291\t0.677706\t0.853537\t0.0334858\n",
      "2  \t66    \t0.823067\t0.721691\t0.867757\t0.0267081\n",
      "3  \t72    \t0.828996\t0.663265\t0.868741\t0.0288492\n",
      "4  \t61    \t0.840963\t0.743117\t0.868741\t0.0213716\n",
      "5  \t59    \t0.844037\t0.70885 \t0.868741\t0.0248773\n",
      "6  \t70    \t0.844774\t0.729132\t0.886523\t0.0260517\n",
      "7  \t70    \t0.854338\t0.755627\t0.886523\t0.0238618\n",
      "8  \t64    \t0.859275\t0.731091\t0.886523\t0.024518 \n",
      "9  \t71    \t0.86736 \t0.755643\t0.886523\t0.02197  \n",
      "10 \t73    \t0.87188 \t0.767624\t0.886523\t0.0234625\n",
      "\n",
      "Modeling... RandomForestClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.788786\t0.686886\t0.862384\t0.0392541\n",
      "1  \t57    \t0.820024\t0.715974\t0.862384\t0.0286956\n",
      "2  \t64    \t0.836989\t0.768741\t0.882418\t0.0238812\n",
      "3  \t62    \t0.845999\t0.720547\t0.884131\t0.0295919\n",
      "4  \t60    \t0.857504\t0.77652 \t0.884131\t0.0235963\n",
      "5  \t57    \t0.864563\t0.782838\t0.884131\t0.0229294\n",
      "6  \t70    \t0.871912\t0.810454\t0.884131\t0.0174487\n",
      "7  \t60    \t0.873448\t0.78955 \t0.886346\t0.0195619\n",
      "8  \t63    \t0.874345\t0.739193\t0.892714\t0.0237002\n",
      "9  \t70    \t0.87381 \t0.783745\t0.892714\t0.0212186\n",
      "10 \t63    \t0.876438\t0.818625\t0.892714\t0.0177176\n",
      "\n",
      "Modeling... GradientBoostingClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg    \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.83073\t0.733351\t0.884406\t0.0290606\n",
      "1  \t60    \t0.85802\t0.799352\t0.899267\t0.0188119\n",
      "2  \t68    \t0.866668\t0.796975\t0.901487\t0.0196813\n",
      "3  \t73    \t0.875336\t0.823626\t0.91452 \t0.0172403\n",
      "4  \t62    \t0.881618\t0.821913\t0.91452 \t0.0181525\n",
      "5  \t61    \t0.889643\t0.812653\t0.91452 \t0.0213248\n",
      "6  \t74    \t0.897436\t0.806418\t0.91452 \t0.0172506\n",
      "7  \t62    \t0.897707\t0.825356\t0.91452 \t0.0180551\n",
      "8  \t49    \t0.900579\t0.815198\t0.91452 \t0.018002 \n",
      "9  \t63    \t0.901103\t0.814855\t0.91452 \t0.0228192\n",
      "10 \t62    \t0.907939\t0.838103\t0.91452 \t0.0171142\n",
      "\n",
      "Modeling... VotingClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.802041\t0.711605\t0.875839\t0.0339031\n",
      "1  \t57    \t0.828657\t0.742872\t0.87524 \t0.0282483\n",
      "2  \t66    \t0.844591\t0.759845\t0.888248\t0.0259531\n",
      "3  \t60    \t0.854478\t0.785994\t0.886096\t0.0230071\n",
      "4  \t59    \t0.866946\t0.743879\t0.886269\t0.0217288\n",
      "5  \t67    \t0.867814\t0.779545\t0.904359\t0.0235779\n",
      "6  \t59    \t0.875649\t0.784617\t0.904359\t0.0180444\n",
      "7  \t62    \t0.877863\t0.801986\t0.904359\t0.0196253\n",
      "8  \t66    \t0.883107\t0.75773 \t0.904359\t0.0221619\n",
      "9  \t74    \t0.886824\t0.787333\t0.904359\t0.0232783\n",
      "10 \t57    \t0.893562\t0.811402\t0.904359\t0.0204443\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    return models\n",
    "\"\"\"\n",
    "estimadores = set_models()\n",
    "\n",
    "reserva = {}\n",
    "lista_resultados = []\n",
    "for name, model in estimadores:\n",
    "    print(\"\\nModeling...\", name)\n",
    "    splits = 10\n",
    "    simetricas = [[i]*5 for i in range(6)]\n",
    "    #for individual in simetricas:\n",
    "    #acc, desv, err = evaluate(frecuencias, individual, model)\n",
    "    #salida[str(name)+\"-\"+str(individual)] = str(acc) + \"-\"+ str(desv) + \"-\" + str(err)\n",
    "    #print(name,\" \", individual, \"\\t\", acc, \"\\t\", desv, \"\\t\", err)\n",
    "    gs = EvolutiveSearchCV(estimator=model, scoring=\"accuracy\", num_folds=10, n_jobs=num_jobs,\n",
    "                        verbose=True, refit=True, \n",
    "                        population_size=100, \n",
    "                        gene_mutation_prob=0.3, \n",
    "                        gene_crossover_prob=0.5,\n",
    "                        tournament_size=4,\n",
    "                        generations_number=10)\n",
    "    gs.fit(frecuencias)\n",
    "    reserva[name]=(gs.score_cache, gs.desv_cache , gs.error_cache)\n",
    "    lista_resultados = lista_resultados + list(gs.resultados)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4090</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.185316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 5]</td>\n",
       "      <td>0.909314</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>0.192849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.904359</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.199940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 1, 5]</td>\n",
       "      <td>0.902372</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.254808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 1]</td>\n",
       "      <td>0.901734</td>\n",
       "      <td>0.015191</td>\n",
       "      <td>0.239624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 3]</td>\n",
       "      <td>0.901487</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.217585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 5]</td>\n",
       "      <td>0.900296</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.285474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 5]</td>\n",
       "      <td>0.900138</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.219814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 5]</td>\n",
       "      <td>0.899650</td>\n",
       "      <td>0.014597</td>\n",
       "      <td>0.215366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 4]</td>\n",
       "      <td>0.899511</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.213565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 4]</td>\n",
       "      <td>0.899267</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.282091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.896850</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.205363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 2]</td>\n",
       "      <td>0.896844</td>\n",
       "      <td>0.013843</td>\n",
       "      <td>0.217836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4088</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.895867</td>\n",
       "      <td>0.009047</td>\n",
       "      <td>0.221426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4185</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 2, 5]</td>\n",
       "      <td>0.894691</td>\n",
       "      <td>0.013031</td>\n",
       "      <td>0.234800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 4, 3, 1]</td>\n",
       "      <td>0.894621</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.256632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 1]</td>\n",
       "      <td>0.893911</td>\n",
       "      <td>0.019609</td>\n",
       "      <td>0.231236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4046</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 4, 3, 4]</td>\n",
       "      <td>0.893399</td>\n",
       "      <td>0.015777</td>\n",
       "      <td>0.247722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 5]</td>\n",
       "      <td>0.892923</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>0.303146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 5]</td>\n",
       "      <td>0.892923</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>0.303146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 5]</td>\n",
       "      <td>0.892714</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>0.216563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.892472</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.196575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 1, 3]</td>\n",
       "      <td>0.892444</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>0.252796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4200</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 4, 3, 5]</td>\n",
       "      <td>0.892442</td>\n",
       "      <td>0.013724</td>\n",
       "      <td>0.270351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 3]</td>\n",
       "      <td>0.890491</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>0.264053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4121</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 6, 3, 2]</td>\n",
       "      <td>0.890456</td>\n",
       "      <td>0.012392</td>\n",
       "      <td>0.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 3, 3, 2]</td>\n",
       "      <td>0.890212</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.267753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[4, 1, 3, 3, 1]</td>\n",
       "      <td>0.889589</td>\n",
       "      <td>0.019120</td>\n",
       "      <td>0.292011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 4]</td>\n",
       "      <td>0.889487</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.267946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 6, 3, 3]</td>\n",
       "      <td>0.889273</td>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.317109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 4, 6, 4, 3]</td>\n",
       "      <td>0.441565</td>\n",
       "      <td>0.039488</td>\n",
       "      <td>1.510141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[3, 2, 5, 3, 3]</td>\n",
       "      <td>0.441191</td>\n",
       "      <td>0.024938</td>\n",
       "      <td>1.672056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 6, 6, 2]</td>\n",
       "      <td>0.439808</td>\n",
       "      <td>0.030533</td>\n",
       "      <td>1.380842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 1, 4, 2, 3]</td>\n",
       "      <td>0.439163</td>\n",
       "      <td>0.025796</td>\n",
       "      <td>1.391056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[6, 5, 5, 5, 3]</td>\n",
       "      <td>0.437881</td>\n",
       "      <td>0.044142</td>\n",
       "      <td>1.674947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 5, 2, 5, 1]</td>\n",
       "      <td>0.435506</td>\n",
       "      <td>0.019637</td>\n",
       "      <td>1.525366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 4, 1, 2, 5]</td>\n",
       "      <td>0.435256</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>1.463423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[2, 5, 1, 5, 3]</td>\n",
       "      <td>0.433279</td>\n",
       "      <td>0.024616</td>\n",
       "      <td>1.769609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 3, 4, 4, 6]</td>\n",
       "      <td>0.430192</td>\n",
       "      <td>0.017225</td>\n",
       "      <td>1.608205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[3, 2, 1, 5, 2]</td>\n",
       "      <td>0.427094</td>\n",
       "      <td>0.024863</td>\n",
       "      <td>1.557591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 5, 5, 3, 3]</td>\n",
       "      <td>0.424629</td>\n",
       "      <td>0.027814</td>\n",
       "      <td>1.917689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 1, 1, 3, 1]</td>\n",
       "      <td>0.420768</td>\n",
       "      <td>0.055045</td>\n",
       "      <td>1.015484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 3, 4, 2, 2]</td>\n",
       "      <td>0.415653</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>1.674877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 5, 1, 5, 4]</td>\n",
       "      <td>0.414716</td>\n",
       "      <td>0.015822</td>\n",
       "      <td>1.630005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 1, 5, 6]</td>\n",
       "      <td>0.414519</td>\n",
       "      <td>0.030143</td>\n",
       "      <td>1.756799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 5, 4, 2]</td>\n",
       "      <td>0.414041</td>\n",
       "      <td>0.029934</td>\n",
       "      <td>1.602151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 6, 3, 2, 5]</td>\n",
       "      <td>0.408834</td>\n",
       "      <td>0.025009</td>\n",
       "      <td>1.660177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 6, 5, 4]</td>\n",
       "      <td>0.407516</td>\n",
       "      <td>0.030405</td>\n",
       "      <td>1.825991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[2, 5, 5, 5, 3]</td>\n",
       "      <td>0.406189</td>\n",
       "      <td>0.012836</td>\n",
       "      <td>1.843488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 5, 5, 4]</td>\n",
       "      <td>0.404518</td>\n",
       "      <td>0.033109</td>\n",
       "      <td>1.763639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 2, 2, 5, 1]</td>\n",
       "      <td>0.400899</td>\n",
       "      <td>0.043041</td>\n",
       "      <td>1.632654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[6, 3, 5, 5, 3]</td>\n",
       "      <td>0.396636</td>\n",
       "      <td>0.035861</td>\n",
       "      <td>1.919272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 4, 5, 5]</td>\n",
       "      <td>0.389950</td>\n",
       "      <td>0.034038</td>\n",
       "      <td>1.762626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 5, 5, 6, 3]</td>\n",
       "      <td>0.384099</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>1.849752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 3, 6, 5, 3]</td>\n",
       "      <td>0.381886</td>\n",
       "      <td>0.035582</td>\n",
       "      <td>1.788076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 6, 5, 5]</td>\n",
       "      <td>0.378669</td>\n",
       "      <td>0.029919</td>\n",
       "      <td>2.017375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 1, 5, 4]</td>\n",
       "      <td>0.374797</td>\n",
       "      <td>0.023115</td>\n",
       "      <td>1.624341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 6, 5, 3]</td>\n",
       "      <td>0.363240</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>2.083504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 2, 1, 3]</td>\n",
       "      <td>0.358188</td>\n",
       "      <td>0.025958</td>\n",
       "      <td>1.830842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 2, 1, 3, 2]</td>\n",
       "      <td>0.338491</td>\n",
       "      <td>0.044988</td>\n",
       "      <td>1.234359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4604 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "4090  GradientBoostingClassifier  [6, 1, 3, 3, 5]  0.914520     0.008447   \n",
       "4227  GradientBoostingClassifier  [6, 1, 3, 6, 5]  0.909314     0.015718   \n",
       "4519            VotingClassifier  [6, 1, 3, 3, 5]  0.904359     0.010358   \n",
       "4174  GradientBoostingClassifier  [6, 1, 3, 1, 5]  0.902372     0.011416   \n",
       "4164  GradientBoostingClassifier  [6, 1, 2, 3, 1]  0.901734     0.015191   \n",
       "4031  GradientBoostingClassifier  [6, 1, 1, 3, 3]  0.901487     0.013594   \n",
       "4213  GradientBoostingClassifier  [6, 3, 2, 3, 5]  0.900296     0.012720   \n",
       "4151  GradientBoostingClassifier  [6, 1, 2, 3, 5]  0.900138     0.016621   \n",
       "4079  GradientBoostingClassifier  [6, 1, 1, 3, 5]  0.899650     0.014597   \n",
       "4155  GradientBoostingClassifier  [6, 1, 1, 3, 4]  0.899511     0.013050   \n",
       "4010  GradientBoostingClassifier  [6, 1, 2, 3, 4]  0.899267     0.012695   \n",
       "4154  GradientBoostingClassifier  [6, 1, 3, 3, 3]  0.896850     0.009726   \n",
       "4149  GradientBoostingClassifier  [6, 1, 1, 3, 2]  0.896844     0.013843   \n",
       "4088  GradientBoostingClassifier  [6, 1, 3, 3, 1]  0.895867     0.009047   \n",
       "4185  GradientBoostingClassifier  [6, 1, 3, 2, 5]  0.894691     0.013031   \n",
       "4115  GradientBoostingClassifier  [6, 1, 4, 3, 1]  0.894621     0.014890   \n",
       "4107  GradientBoostingClassifier  [6, 1, 1, 3, 1]  0.893911     0.019609   \n",
       "4046  GradientBoostingClassifier  [6, 1, 4, 3, 4]  0.893399     0.015777   \n",
       "4219  GradientBoostingClassifier  [6, 3, 3, 3, 5]  0.892923     0.013625   \n",
       "4220  GradientBoostingClassifier  [6, 3, 3, 3, 5]  0.892923     0.013625   \n",
       "3836      RandomForestClassifier  [6, 1, 3, 6, 5]  0.892714     0.013661   \n",
       "2972        ExtraTreesClassifier  [6, 1, 3, 3, 5]  0.892472     0.013311   \n",
       "4193  GradientBoostingClassifier  [6, 1, 3, 1, 3]  0.892444     0.011331   \n",
       "4200  GradientBoostingClassifier  [6, 1, 4, 3, 5]  0.892442     0.013724   \n",
       "4571            VotingClassifier  [6, 1, 1, 3, 3]  0.890491     0.017897   \n",
       "4121  GradientBoostingClassifier  [6, 4, 6, 3, 2]  0.890456     0.012392   \n",
       "4168  GradientBoostingClassifier  [6, 4, 3, 3, 2]  0.890212     0.012968   \n",
       "4131  GradientBoostingClassifier  [4, 1, 3, 3, 1]  0.889589     0.019120   \n",
       "4098  GradientBoostingClassifier  [6, 1, 3, 3, 4]  0.889487     0.013909   \n",
       "4163  GradientBoostingClassifier  [6, 1, 6, 3, 3]  0.889273     0.016554   \n",
       "...                          ...              ...       ...          ...   \n",
       "1213               MLPClassifier  [1, 4, 6, 4, 3]  0.441565     0.039488   \n",
       "2361          LogisticRegression  [3, 2, 5, 3, 3]  0.441191     0.024938   \n",
       "1574               MLPClassifier  [3, 2, 6, 6, 2]  0.439808     0.030533   \n",
       "1167               MLPClassifier  [3, 1, 4, 2, 3]  0.439163     0.025796   \n",
       "1195               MLPClassifier  [6, 5, 5, 5, 3]  0.437881     0.044142   \n",
       "1162               MLPClassifier  [1, 5, 2, 5, 1]  0.435506     0.019637   \n",
       "1239               MLPClassifier  [3, 4, 1, 2, 5]  0.435256     0.025500   \n",
       "2396          LogisticRegression  [2, 5, 1, 5, 3]  0.433279     0.024616   \n",
       "1232               MLPClassifier  [2, 3, 4, 4, 6]  0.430192     0.017225   \n",
       "2321          LogisticRegression  [3, 2, 1, 5, 2]  0.427094     0.024863   \n",
       "1223               MLPClassifier  [3, 5, 5, 3, 3]  0.424629     0.027814   \n",
       "1440               MLPClassifier  [2, 1, 1, 3, 1]  0.420768     0.055045   \n",
       "1177               MLPClassifier  [2, 3, 4, 2, 2]  0.415653     0.023900   \n",
       "1456               MLPClassifier  [4, 5, 1, 5, 4]  0.414716     0.015822   \n",
       "1307               MLPClassifier  [3, 2, 1, 5, 6]  0.414519     0.030143   \n",
       "1256               MLPClassifier  [1, 3, 5, 4, 2]  0.414041     0.029934   \n",
       "1182               MLPClassifier  [1, 6, 3, 2, 5]  0.408834     0.025009   \n",
       "1206               MLPClassifier  [3, 3, 6, 5, 4]  0.407516     0.030405   \n",
       "2319          LogisticRegression  [2, 5, 5, 5, 3]  0.406189     0.012836   \n",
       "1208               MLPClassifier  [3, 2, 5, 5, 4]  0.404518     0.033109   \n",
       "1301               MLPClassifier  [2, 2, 2, 5, 1]  0.400899     0.043041   \n",
       "1254               MLPClassifier  [6, 3, 5, 5, 3]  0.396636     0.035861   \n",
       "1359               MLPClassifier  [3, 2, 4, 5, 5]  0.389950     0.034038   \n",
       "1194               MLPClassifier  [3, 5, 5, 6, 3]  0.384099     0.027273   \n",
       "1261               MLPClassifier  [2, 3, 6, 5, 3]  0.381886     0.035582   \n",
       "1170               MLPClassifier  [1, 2, 6, 5, 5]  0.378669     0.029919   \n",
       "1222               MLPClassifier  [3, 2, 1, 5, 4]  0.374797     0.023115   \n",
       "1193               MLPClassifier  [1, 2, 6, 5, 3]  0.363240     0.018344   \n",
       "1171               MLPClassifier  [3, 3, 2, 1, 3]  0.358188     0.025958   \n",
       "1229               MLPClassifier  [2, 2, 1, 3, 2]  0.338491     0.044988   \n",
       "\n",
       "      errorMetrico  \n",
       "4090      0.185316  \n",
       "4227      0.192849  \n",
       "4519      0.199940  \n",
       "4174      0.254808  \n",
       "4164      0.239624  \n",
       "4031      0.217585  \n",
       "4213      0.285474  \n",
       "4151      0.219814  \n",
       "4079      0.215366  \n",
       "4155      0.213565  \n",
       "4010      0.282091  \n",
       "4154      0.205363  \n",
       "4149      0.217836  \n",
       "4088      0.221426  \n",
       "4185      0.234800  \n",
       "4115      0.256632  \n",
       "4107      0.231236  \n",
       "4046      0.247722  \n",
       "4219      0.303146  \n",
       "4220      0.303146  \n",
       "3836      0.216563  \n",
       "2972      0.196575  \n",
       "4193      0.252796  \n",
       "4200      0.270351  \n",
       "4571      0.264053  \n",
       "4121      0.268900  \n",
       "4168      0.267753  \n",
       "4131      0.292011  \n",
       "4098      0.267946  \n",
       "4163      0.317109  \n",
       "...            ...  \n",
       "1213      1.510141  \n",
       "2361      1.672056  \n",
       "1574      1.380842  \n",
       "1167      1.391056  \n",
       "1195      1.674947  \n",
       "1162      1.525366  \n",
       "1239      1.463423  \n",
       "2396      1.769609  \n",
       "1232      1.608205  \n",
       "2321      1.557591  \n",
       "1223      1.917689  \n",
       "1440      1.015484  \n",
       "1177      1.674877  \n",
       "1456      1.630005  \n",
       "1307      1.756799  \n",
       "1256      1.602151  \n",
       "1182      1.660177  \n",
       "1206      1.825991  \n",
       "2319      1.843488  \n",
       "1208      1.763639  \n",
       "1301      1.632654  \n",
       "1254      1.919272  \n",
       "1359      1.762626  \n",
       "1194      1.849752  \n",
       "1261      1.788076  \n",
       "1170      2.017375  \n",
       "1222      1.624341  \n",
       "1193      2.083504  \n",
       "1171      1.830842  \n",
       "1229      1.234359  \n",
       "\n",
       "[4604 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(lista_resultados).sort_values(['Accuracy'],ascending=False)\n",
    "df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico', 'values', 'error']].to_csv('EAS_resultados.csv', sep=',', index=False) \n",
    "display(df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4090</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.185316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.904359</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.199940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 5]</td>\n",
       "      <td>0.892714</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>0.216563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.892472</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.196575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.886523</td>\n",
       "      <td>0.021657</td>\n",
       "      <td>0.303764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 1]</td>\n",
       "      <td>0.877780</td>\n",
       "      <td>0.015037</td>\n",
       "      <td>0.264383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.859765</td>\n",
       "      <td>0.017182</td>\n",
       "      <td>0.310021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 5]</td>\n",
       "      <td>0.859512</td>\n",
       "      <td>0.020820</td>\n",
       "      <td>0.289376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>SVC</td>\n",
       "      <td>[6, 6, 1, 3, 1]</td>\n",
       "      <td>0.829871</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.513929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.771807</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.486200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[4, 1, 2, 3, 1]</td>\n",
       "      <td>0.708543</td>\n",
       "      <td>0.025945</td>\n",
       "      <td>0.647290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 1, 4, 6, 1]</td>\n",
       "      <td>0.697901</td>\n",
       "      <td>0.019551</td>\n",
       "      <td>0.729112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "4090  GradientBoostingClassifier  [6, 1, 3, 3, 5]  0.914520     0.008447   \n",
       "4519            VotingClassifier  [6, 1, 3, 3, 5]  0.904359     0.010358   \n",
       "3836      RandomForestClassifier  [6, 1, 3, 6, 5]  0.892714     0.013661   \n",
       "2972        ExtraTreesClassifier  [6, 1, 3, 3, 5]  0.892472     0.013311   \n",
       "3402          AdaBoostClassifier  [6, 1, 3, 3, 5]  0.886523     0.021657   \n",
       "1934        KNeighborsClassifier  [6, 1, 3, 6, 1]  0.877780     0.015037   \n",
       "973                   GaussianNB  [6, 1, 3, 3, 5]  0.859765     0.017182   \n",
       "2275      DecisionTreeClassifier  [6, 1, 3, 6, 5]  0.859512     0.020820   \n",
       "591                          SVC  [6, 6, 1, 3, 1]  0.829871     0.019038   \n",
       "314   LinearDiscriminantAnalysis  [6, 1, 3, 3, 5]  0.771807     0.020370   \n",
       "2632          LogisticRegression  [4, 1, 2, 3, 1]  0.708543     0.025945   \n",
       "1428               MLPClassifier  [4, 1, 4, 6, 1]  0.697901     0.019551   \n",
       "\n",
       "      errorMetrico  \n",
       "4090      0.185316  \n",
       "4519      0.199940  \n",
       "3836      0.216563  \n",
       "2972      0.196575  \n",
       "3402      0.303764  \n",
       "1934      0.264383  \n",
       "973       0.310021  \n",
       "2275      0.289376  \n",
       "591       0.513929  \n",
       "314       0.486200  \n",
       "2632      0.647290  \n",
       "1428      0.729112  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#topDf = df.drop_duplicates(subset=['Modelo'])\n",
    "#display(topDf)\n",
    "#pd.DataFrame(salida).sort_values(['Accuracy'], ascending=False)\n",
    "topDf=df.drop_duplicates(subset=['Modelo'])\n",
    "topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico', 'values', 'error']].to_csv('EAS_resultados_unique.csv', sep=',', index=False) \n",
    "display(topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataframe_plot = topDf\n",
    "def column_boxplot(dataframe_plot, column_plot, filename):\n",
    "    %pylab inline\n",
    "    pylab.rcParams['figure.figsize'] = (14, 8)\n",
    "    previos = ['LogisticRegression', 'LinearDiscriminantAnalysis', 'GaussianNB', 'MLPClassifier', \n",
    "               'SVC', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', \n",
    "               'ExtraTreesClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier', 'VotingClassifier']\n",
    "    nuevos = ['LoR', 'LDA', 'GNB', 'MLP', 'SVC', 'DT', 'k-NN', 'RF', 'ET', 'GBM', 'AB', 'VC']\n",
    "    num_models = len(nuevos)\n",
    "    num_splits = 10\n",
    "    dataframe_plot = dataframe_plot[['Modelo', 'Configuracion', 'Accuracy', 'errorMetrico', 'values', 'error']]\n",
    "    for i in range(12):\n",
    "        dataframe_plot['Modelo'] = dataframe_plot['Modelo'].str.replace(previos[i], nuevos[i])\n",
    "        #df['Modelo'] = df['Modelo'].str.replace('LinearDiscriminantAnalysis','LDA')\n",
    "    sorterIndex = dict(zip(nuevos,range(num_models)))\n",
    "    #test\n",
    "    dataframe_plot['Model_Rank'] = dataframe_plot['Modelo'].map(sorterIndex)\n",
    "    dataframe_plot = dataframe_plot.sort_values(['Model_Rank'],ascending=True).reset_index(drop=True)[dataframe_plot.columns[:-1]]\n",
    "    if column_plot == 'values':\n",
    "        y_label = 'Score'\n",
    "        x_label = 'Model'\n",
    "    else:\n",
    "        y_label = 'Error (m)'\n",
    "        x_label = 'Model Evaluated'\n",
    "    lista_plot = []\n",
    "    for i in range(num_models):\n",
    "        for j in range(num_splits):\n",
    "            d = {x_label:nuevos[i], y_label:dataframe_plot[column_plot][i][j]}\n",
    "            lista_plot.append(d)\n",
    "    #pd.DataFrame(lista_plot)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    ax_plot = sns.boxplot(data=pd.DataFrame(lista_plot), x=x_label, y=y_label, linewidth = 1.0)\n",
    "    plt.format='eps'\n",
    "    if column_plot == 'values':\n",
    "        medians = np.round(list(dataframe_plot['Accuracy']),3)\n",
    "        tope = 0.98\n",
    "    else:\n",
    "        medians = np.round(list(dataframe_plot['errorMetrico']),3)\n",
    "        tope = 6.8\n",
    "    median_labels = [str(s) for s in medians]\n",
    "    pos = range(num_models)\n",
    "    for tick,label in zip(pos,ax_plot.get_xticklabels()):\n",
    "        ax_plot.text(pos[tick], tope, median_labels[tick], \n",
    "                horizontalalignment='center', color='black') #, weight='semibold'\n",
    "    axes = plt.gca()\n",
    "    if column_plot == 'values':\n",
    "        axes.set_ylim([0.3,1.0])\n",
    "    else:\n",
    "        axes.set_ylim([-0.1, 7])\n",
    "    plt.savefig(filename + \".eps\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAHeCAYAAABT+34JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe52dd82898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'values', 'accuracy_eas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzEAAAHeCAYAAACrG4X+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRiHEAAAAADAKIQYAAACAUf4/E4xsE/5/PUIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe52c0f4630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'error', 'error_eas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_range = np.logspace(-2, 10, 13)\n",
    "gamma_range = np.logspace(-9, 3, 13)\n",
    "param_grid = dict(gamma=gamma_range, C=C_range)\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(\"The best parameters are %s with a score of %0.2f\"\n",
    "      % (grid.best_params_, grid.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
