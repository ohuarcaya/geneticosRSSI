{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Librería Genética\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Subfunciones de estimadores\n",
    "from sklearn.base import clone\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][30]\n",
    "from sklearn.base import is_classifier\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][535]\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_validation.py][346]\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][386]\n",
    "from sklearn.model_selection._search import check_cv\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_split.py][1866]\n",
    "from sklearn.model_selection._search import _check_param_grid\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][343]\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/scorer.py][250]\n",
    "from sklearn.utils.validation import _num_samples\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][105]\n",
    "from sklearn.utils.validation import indexable\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][208]\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "#from itertools import product\n",
    "import itertools as it #import product\n",
    "\n",
    "# Selección para estimadores\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metricas para estimadores\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Estimadores\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Ensembles algorithms\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find distance error al 0.2%\n",
    "def distance_error(estimator, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 7)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    # coord pred\n",
    "    x1 = np.int32((y_pred + 2) % 3)\n",
    "    y1 = np.int32((y_pred - 1) / 3)\n",
    "    # coord real\n",
    "    x2 = np.int32((y_test + 2) % 3)\n",
    "    y2 = np.int32((y_test - 1) / 3)\n",
    "    # pasar variacion a distancias metros\n",
    "    vx = np.abs(x1 - x2)*1.5\n",
    "    vy = np.abs(y1 - y2)*1.5\n",
    "    #vx = vx*0.5 + (vx-1)*(vx>0)\n",
    "    #vy = vy*0.5 + (vy-1)*(vy>0)\n",
    "    # pitagoras\n",
    "    err_distance = np.sqrt(vx*vx + vy*vy)\n",
    "    return err_distance\n",
    "\n",
    "#def _createDataset(frecuencias, values, seed = 7):\n",
    "def _createDataset(frecuencias, values):\n",
    "    # crear dataset\n",
    "    names_ = frecuencias[0].columns.values\n",
    "    seed = 7\n",
    "    # reestructuracion\n",
    "    salida_final = pd.DataFrame(columns=names_)\n",
    "    for sec in range(1,16):\n",
    "        dataset = pd.DataFrame(columns=names_)\n",
    "        corte = min([frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values])\n",
    "        #l = [frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values]\n",
    "        #corte = max(l)\n",
    "        #tx=l.index(max(l))\n",
    "        tx = 0\n",
    "        dataset[names_[tx]] = dataset[names_[tx]].append(frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]])\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        for tx in range(1,5):\n",
    "            dataset[names_[tx]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]].reset_index(drop=True)\n",
    "        dataset[names_[tx+1]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx+1]].reset_index(drop=True)\n",
    "        # join parts\n",
    "        salida_final = salida_final.append(dataset)\n",
    "    # shuffle dataset\n",
    "    salida_final = shuffle(salida_final, random_state=seed).reset_index(drop=True)\n",
    "    salida_final = salida_final.apply(pd.to_numeric)\n",
    "    # dataframe to X,y \n",
    "    X = salida_final[names_[:-1]]\n",
    "    y = salida_final[names_[-1]]\n",
    "    return X,y\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    # LDA : Warning(Variables are collinear)\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('SVC', SVC(random_state=rs)))\n",
    "    models.append(('GaussianNB', GaussianNB()))\n",
    "    models.append(('MLPClassifier', MLPClassifier()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=rs)))\n",
    "    models.append(('LogisticRegression', LogisticRegression()))\n",
    "    # Bagging and Boosting\n",
    "    # models.append(('ExtraTreesClassifier', ExtraTreesClassifier(n_estimators=150)))\n",
    "    models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state=rs)))\n",
    "    models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier(random_state=rs),\n",
    "                                                            random_state=rs)))\n",
    "    # models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier())))\n",
    "    models.append(('RandomForestClassifier', RandomForestClassifier(random_state=rs)))\n",
    "    models.append(('GradientBoostingClassifier',\n",
    "                   GradientBoostingClassifier(random_state=rs)))\n",
    "    # models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "    # Voting\n",
    "    estimators = []\n",
    "    estimators.append((\"Voting_GradientBoostingClassifier\", GradientBoostingClassifier(random_state=rs)))\n",
    "    estimators.append((\"Voting_ExtraTreesClassifier\", ExtraTreesClassifier(random_state=rs)))\n",
    "    voting = VotingClassifier(estimators)\n",
    "    models.append(('VotingClassifier', voting))\n",
    "    return models\n",
    "\n",
    "# The problem to optimize\n",
    "def getAccuracy( frecuencias, individual, estimator, score_cache, resultados ):\n",
    "\tX,y = _createDataset(frecuencias, individual)\n",
    "\t#print(X)\n",
    "\t#print\n",
    "\t#print\n",
    "\t#print(y)\n",
    "\tscore = 0\n",
    "\tscorer = \"accuracy\"\n",
    "\tname = str(estimator).split('(')[0]\n",
    "\tparamkey = str(np.int32(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=10, shuffle=False)\n",
    "\t\tcv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scorer)\n",
    "\t\t#print(name,\"  \",paramkey,\"   \")\n",
    "\t\t#print(len(X),\"  \",len(y),\"   \", kfold)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\tdesv = cv_results.std()\n",
    "\t\terror = distance_error(estimator, X, y)\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\tdict_result = {'Modelo': name, 'Configuracion':np.int32(individual)+1, 'values': cv_results, 'Accuracy': score, 'stdAccuracy': desv, 'errorMetrico': np.mean(error), 'error': error }\n",
    "\t\tresultados.append(dict_result)\n",
    "\treturn score\n",
    "\"\"\"\n",
    "def _evalFunction(individual, frecuencias, scorer, num_folds, score_cache, desv_cache, error_cache, resultados_cache):\n",
    "\tX, y = _individual_to_params(frecuencias, individual)\n",
    "\tscore = 0\n",
    "\tn_test = 0\n",
    "\tname = str(individual.est).split('(')[0]\n",
    "\tparamkey = str(np.array(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=10, shuffle=False)\n",
    "\t\t#cv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scoring)\n",
    "\t\tcv_results = cross_val_score(individual.est, X, y, cv=kfold, scoring=scorer)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\tdesv_cache[paramkey] = cv_results.std()\n",
    "\t\terror_cache[paramkey] = distance_error(individual.est, X, y)\n",
    "\t\tresults = {'Modelo': name, 'Configuracion':np.int32(individual)+1, 'values': cv_results, 'Accuracy': score, 'stdAccuracy': desv_cache[paramkey], 'errorMetrico': error_cache[paramkey]}  \n",
    "\t\tresultados_cache.append(results)\n",
    "\treturn (score,)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class eda:\n",
    "\tdef __init__(self, of, frecuencias, estimator):\n",
    "\t\t# Algorithm parameters\n",
    "\t\tself.iterations = 10\n",
    "\t\tself.sample_size = 100\n",
    "\t\tself.select_ratio = 0.5\n",
    "\t\tself.epsilon = 10e-6\n",
    "\n",
    "\t\t# class members\n",
    "\t\tself.objective_function = of\n",
    "\t\tself.dimensions = 5\n",
    "\t\tself.sample = []\n",
    "\t\tself.means = []\n",
    "\t\tself.stdevs = []\t\n",
    "\n",
    "\t\tself.debug = False\n",
    "\t\t# aditional parameters\n",
    "\t\tself.frecuencias = frecuencias\n",
    "\t\tself.estimator = estimator\n",
    "\t\tself.__manager = Manager()\n",
    "\t\tself.score_cache = {}\n",
    "\t\tself.resultados = self.__manager.list()\n",
    "\t\tself.n_jobs = cpu_count()\n",
    "        \n",
    "\n",
    "\tdef sample_sort(self): \n",
    "\t\t# sort rows on the last column\n",
    "\t\tself.sample = self.sample[ np.argsort( self.sample[:,-1], 0 ) ]\n",
    "\n",
    "\n",
    "\tdef dispersion_reduction(self):\n",
    "\t\tself.sample_sort()\n",
    "\n",
    "\t\t# number of points to select\n",
    "\t\tnb = int( np.floor( self.sample_size * self.select_ratio ) )\n",
    "\n",
    "\t\t# selection\n",
    "\t\t#self.sample = self.sample[:nb]\n",
    "\t\tself.sample = self.sample[self.sample_size-nb:]\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"dispersion reduction\")\n",
    "\t\t\tprint (str(self.sample))\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef estimate_parameters( self ):\n",
    "\t\t# points sub array (without values)\n",
    "\t\tmat = self.sample[:,:self.dimensions]\n",
    "\t\t\n",
    "\t\t# row means (axis 0 in scipy)\n",
    "\t\tself.means = np.mean( mat, 0 )\n",
    "\t\t\n",
    "\t\t# row standard deviation\n",
    "\t\tself.stdevs = np.std( mat, 0 )\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"estimate parameters\")\n",
    "\t\t\tprint (\"\\tmean=\" +str(self.means))\n",
    "\t\t\tprint (\"\\tstd-dev=\" + str(self.stdevs))\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef draw_sample(self):\n",
    "\t\t# for each variable to optimize\n",
    "\t\tfor i in range(self.dimensions):\n",
    "\t\t\t# if the dispersion is null\n",
    "\t\t\tif self.stdevs[i] == 0.0:\n",
    "\t\t\t\t# set it to a minimal value\n",
    "\t\t\t\tself.stdevs[i] = self.epsilon\n",
    "\t\t\n",
    "\t\t# empty sample\n",
    "\t\tself.sample = np.zeros( (self.sample_size, self.dimensions+1) )\n",
    "\t\t\n",
    "\t\t# for each point\n",
    "\t\tfor i in range( self.sample_size ):\n",
    "\t\t\t# draw in random normal\n",
    "\t\t\tp = np.random.normal( self.means, self.stdevs )\n",
    "\t\t\tp = np.array([0 if i<0 else (5 if i>5 else i) for i in p])\n",
    "\t\t\t# put it into the sample\n",
    "\t\t\tself.sample[i][:self.dimensions] = np.round(p)%(self.dimensions+1)\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"draw sample\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef evaluate(self):\n",
    "\t\t# for each point\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in range( self.sample_size ):\n",
    "\t\t\td = self.dimensions\n",
    "\t\t\t# call the objective function\n",
    "\t\t\t#   the third element is the result of the objective function call\n",
    "\t\t\t#   taking the first two elements as variables\n",
    "\t\t\t#r = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache )\n",
    "\t\t\t#self.sample[i][-1] = r\n",
    "\t\t\tself.sample[i][-1] = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache , self.resultados)\n",
    "\t\t\"\"\"\n",
    "\t\td = self.dimensions\n",
    "\t\t_pool = Pool(self.n_jobs)\n",
    "\t\t#self.sample[i][-1] = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache , self.resultados)\n",
    "\t\t_iterable = it.product([self.frecuencias], np.int32(self.sample[:,:d]), [self.estimator], [self.score_cache], [self.resultados])\n",
    "\t\tself.sample[:,-1] = _pool.starmap(self.objective_function, _iterable)\n",
    "\t\t_pool.close()\n",
    "\t\t_pool.join()\n",
    "\t\t#getAccuracy( frecuencias, individual, estimator, score_cache, resultados ):\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"evaluate\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef run(self):\n",
    "\t\t# uniform initialization\n",
    "\t\tself.sample = np.random.rand( self.sample_size, self.dimensions+1 )\n",
    "\t\t# cosmetic\n",
    "\t\t#self.sample = self.sample * 200 - 100\n",
    "\t\ttop_freq = 6\n",
    "\t\tself.sample = np.floor(np.random.rand(self.sample_size, self.dimensions +1)*top_freq)\n",
    "\t\t\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"initialization\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\t\tself.evaluate()\n",
    "\n",
    "\t\t# Multi process\n",
    "\t\t\n",
    "\t\ti = 0\n",
    "\t\twhile i < self.iterations:\n",
    "\t\t\tif self.debug:\n",
    "\t\t\t\tprint (\"iteration\",i)\n",
    "\t\t\t\tprint\n",
    "\n",
    "\t\t\ti += 1\n",
    "\t\t\tself.dispersion_reduction()\n",
    "\t\t\tprint(\"iter[\"+str(i)+\"]-top1: \"+str(self.sample[-1]))\n",
    "\t\t\tself.estimate_parameters()\n",
    "\t\t\tself.draw_sample()\n",
    "\t\t\tself.evaluate()\n",
    "\t\t\t# print top 1\n",
    "\t\t\tself.sample_sort()\n",
    "\n",
    "\t\t# sort the final sample\n",
    "\t\tself.sample_sort()\n",
    "\t\t# output the optimum\n",
    "\t\t#self.pool.close()\n",
    "\t\t#self.pool.join()\n",
    "\t\tranking = self.sample_size\n",
    "\t\t#print (\"#[ Configuración ]\\t Accuracy\")\n",
    "\t\t#for i in range(ranking):\n",
    "\t\t#\tlinea = str(self.sample[-i-1][:-1]+1) + \"\\t\" +str(self.sample[-i-1][-1])\n",
    "\t\t#\tprint(linea)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "frecuencias = []\n",
    "names_ = ['Be01', 'Be02', 'Be03', 'Be04', 'Be05', 'Sector']\n",
    "\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x01'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x02'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x03'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x04'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x05'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x06'))#, names=names_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modeling... LinearDiscriminantAnalysis\n",
      "iter[1]-top1: [ 5.          0.          0.          5.          4.          0.74510763]\n",
      "iter[2]-top1: [ 5.          0.          2.          2.          5.          0.72744946]\n",
      "iter[3]-top1: [ 5.          0.          2.          0.          4.          0.75297214]\n",
      "iter[4]-top1: [ 5.          0.          2.          0.          0.          0.73380345]\n",
      "iter[5]-top1: [ 3.          0.          1.          0.          0.          0.73609261]\n",
      "iter[6]-top1: [ 3.          0.          3.          2.          0.          0.74027304]\n",
      "iter[7]-top1: [ 5.          3.          3.          2.          0.          0.71442543]\n",
      "iter[8]-top1: [ 5.          3.          2.          0.          0.          0.71809291]\n",
      "iter[9]-top1: [ 5.          4.          3.          2.          0.          0.72911702]\n",
      "iter[10]-top1: [ 5.          3.          2.          0.          0.          0.71809291]\n",
      "\n",
      "Modeling... SVC\n",
      "iter[1]-top1: [ 3.          0.          5.          5.          0.          0.80894265]\n",
      "iter[2]-top1: [ 4.          0.          2.          5.          0.          0.82780446]\n",
      "iter[3]-top1: [ 5.          3.          2.          2.          0.          0.80880196]\n",
      "iter[4]-top1: [ 5.          4.          2.          5.          0.          0.82656438]\n",
      "iter[5]-top1: [ 5.          5.          2.          5.          0.          0.81666528]\n",
      "iter[6]-top1: [ 5.          0.          3.          5.          0.          0.81711861]\n",
      "iter[7]-top1: [ 5.          4.          2.          2.          2.          0.79764597]\n",
      "iter[8]-top1: [ 5.          0.          1.          2.          0.          0.81129167]\n",
      "iter[9]-top1: [ 5.          2.          2.          2.          0.          0.81666647]\n",
      "iter[10]-top1: [ 5.          2.          1.          5.          0.          0.81886278]\n",
      "\n",
      "Modeling... GaussianNB\n",
      "iter[1]-top1: [ 5.          5.          0.          0.          4.          0.83193406]\n",
      "iter[2]-top1: [ 5.         3.         2.         3.         0.         0.8207824]\n",
      "iter[3]-top1: [ 3.          0.          2.          1.          0.          0.82214509]\n",
      "iter[4]-top1: [ 3.          3.          2.          3.          0.          0.81351221]\n",
      "iter[5]-top1: [ 3.          0.          2.          2.          0.          0.84503254]\n",
      "iter[6]-top1: [ 5.          0.          2.          3.          4.          0.84535784]\n",
      "iter[7]-top1: [ 5.          0.          2.          3.          4.          0.84535784]\n",
      "iter[8]-top1: [ 5.          5.          2.          2.          0.          0.82131254]\n",
      "iter[9]-top1: [ 3.          0.          1.          2.          3.          0.82565669]\n",
      "iter[10]-top1: [ 3.          5.          0.          2.          1.          0.82127139]\n",
      "\n",
      "Modeling... MLPClassifier\n",
      "iter[1]-top1: [ 0.          0.          2.          5.          0.          0.63065717]\n",
      "iter[2]-top1: [ 5.          0.          1.          2.          5.          0.63970779]\n",
      "iter[3]-top1: [ 3.          0.          3.          0.          5.          0.62652071]\n",
      "iter[4]-top1: [ 5.          3.          3.          5.          4.          0.60928266]\n",
      "iter[5]-top1: [ 5.          0.          3.          0.          3.          0.63470531]\n",
      "iter[6]-top1: [ 5.          0.          3.          0.          3.          0.64359378]\n",
      "iter[7]-top1: [ 3.          0.          3.          0.          5.          0.63951012]\n",
      "iter[8]-top1: [ 5.          0.          1.          0.          5.          0.64296082]\n",
      "iter[9]-top1: [ 5.          0.          3.          0.          5.          0.63277532]\n",
      "iter[10]-top1: [ 5.          0.          1.          0.          5.          0.64416621]\n",
      "\n",
      "Modeling... KNeighborsClassifier\n",
      "iter[1]-top1: [ 5.          5.          5.          0.          3.          0.83513824]\n",
      "iter[2]-top1: [ 3.          0.          2.          3.          0.          0.83524804]\n",
      "iter[3]-top1: [ 5.          0.          2.          2.          0.          0.86629256]\n",
      "iter[4]-top1: [ 5.          3.          2.          2.          4.          0.84254529]\n",
      "iter[5]-top1: [ 5.          3.          1.          2.          0.          0.85354523]\n",
      "iter[6]-top1: [ 5.          0.          2.          2.          0.          0.86629256]\n",
      "iter[7]-top1: [ 5.         0.         1.         2.         1.         0.8540718]\n",
      "iter[8]-top1: [ 5.          0.          2.          2.          0.          0.86629256]\n",
      "iter[9]-top1: [ 5.          0.          2.          2.          1.          0.85553104]\n",
      "iter[10]-top1: [ 5.          3.          1.          2.          0.          0.85354523]\n",
      "\n",
      "Modeling... DecisionTreeClassifier\n",
      "iter[1]-top1: [ 5.          0.          3.          2.          5.          0.82836186]\n",
      "iter[2]-top1: [ 5.          0.          5.          5.          0.          0.82266994]\n",
      "iter[3]-top1: [ 5.          5.          2.          2.          1.          0.82141035]\n",
      "iter[4]-top1: [ 5.          4.          3.          2.          1.          0.81404586]\n",
      "iter[5]-top1: [ 5.          0.          2.          2.          0.          0.83207049]\n",
      "iter[6]-top1: [ 5.          0.          3.          2.          0.          0.82909535]\n",
      "iter[7]-top1: [ 5.          3.          1.          2.          1.          0.81653189]\n",
      "iter[8]-top1: [ 5.          5.          0.          2.          1.          0.81935357]\n",
      "iter[9]-top1: [ 5.          5.          2.          2.          1.          0.82141035]\n",
      "iter[10]-top1: [ 5.          3.          1.          2.          5.          0.82404558]\n",
      "\n",
      "Modeling... LogisticRegression\n",
      "iter[1]-top1: [ 4.          0.          2.          2.          0.          0.67863876]\n",
      "iter[2]-top1: [ 5.          0.          2.          0.          2.          0.68296499]\n",
      "iter[3]-top1: [ 3.          3.          1.          3.          0.          0.65295439]\n",
      "iter[4]-top1: [ 5.          3.          1.          0.          4.          0.66676195]\n",
      "iter[5]-top1: [ 5.          4.          1.          2.          0.          0.65412132]\n",
      "iter[6]-top1: [ 3.          5.          1.          0.          0.          0.66306378]\n",
      "iter[7]-top1: [ 5.          3.          2.          0.          5.          0.65843521]\n",
      "iter[8]-top1: [ 3.          4.          1.          2.          0.          0.69419972]\n",
      "iter[9]-top1: [ 3.          4.          1.          2.          0.          0.69419972]\n",
      "iter[10]-top1: [ 5.          3.          2.          2.          4.          0.65609855]\n",
      "\n",
      "Modeling... ExtraTreesClassifier\n",
      "iter[1]-top1: [ 5.          5.          2.          2.          1.          0.86794295]\n",
      "iter[2]-top1: [ 5.          4.          2.          2.          4.          0.85731139]\n",
      "iter[3]-top1: [ 5.          5.          3.          2.          1.          0.85530866]\n",
      "iter[4]-top1: [ 3.        4.        1.        5.        0.        0.864933]\n",
      "iter[5]-top1: [ 5.          2.          2.          5.          4.          0.85780761]\n",
      "iter[6]-top1: [ 5.         4.         2.         2.         2.         0.8678759]\n",
      "iter[7]-top1: [ 5.          3.          2.          2.          0.          0.86479218]\n",
      "iter[8]-top1: [ 5.         4.         2.         2.         2.         0.8678759]\n",
      "iter[9]-top1: [ 5.          5.          2.          2.          1.          0.86794295]\n",
      "iter[10]-top1: [ 5.         4.         2.         2.         2.         0.8678759]\n",
      "\n",
      "Modeling... AdaBoostClassifier\n",
      "iter[1]-top1: [ 5.          0.          2.          1.          4.          0.87314571]\n",
      "iter[2]-top1: [ 5.          4.          2.          2.          4.          0.85485378]\n",
      "iter[3]-top1: [ 5.          3.          2.          2.          1.          0.86718482]\n",
      "iter[4]-top1: [ 5.          4.          3.          5.          0.          0.86445299]\n",
      "iter[5]-top1: [ 5.         0.         3.         0.         4.         0.8646951]\n",
      "iter[6]-top1: [ 5.          0.          2.          3.          4.          0.87387293]\n",
      "iter[7]-top1: [ 5.          0.          2.          0.          2.          0.87166975]\n",
      "iter[8]-top1: [ 5.          0.          1.          2.          3.          0.88117359]\n",
      "iter[9]-top1: [ 5.          0.          1.          2.          3.          0.88117359]\n",
      "iter[10]-top1: [ 5.          0.          0.          2.          1.          0.87753354]\n",
      "\n",
      "Modeling... RandomForestClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter[1]-top1: [ 5.          4.          2.          2.          0.          0.86471452]\n",
      "iter[2]-top1: [ 5.          0.          1.          0.          0.          0.87168938]\n",
      "iter[3]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[4]-top1: [ 5.          0.          5.          2.          0.          0.87264834]\n",
      "iter[5]-top1: [ 5.          0.          2.          2.          5.          0.86726996]\n",
      "iter[6]-top1: [ 5.          5.          1.          2.          1.          0.86212476]\n",
      "iter[7]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[8]-top1: [ 5.          0.          2.          2.          0.          0.88241815]\n",
      "iter[9]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[10]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "\n",
      "Modeling... GradientBoostingClassifier\n",
      "iter[1]-top1: [ 5.          3.          3.          2.          5.          0.88195656]\n",
      "iter[2]-top1: [ 5.        0.        0.        2.        3.        0.899511]\n",
      "iter[3]-top1: [ 5.          0.          5.          2.          3.          0.89437653]\n",
      "iter[4]-top1: [ 5.          2.          2.          2.          2.          0.89022955]\n",
      "iter[5]-top1: [ 5.          0.          2.          2.          2.          0.89685014]\n",
      "iter[6]-top1: [ 5.          4.          1.          2.          3.          0.89756468]\n",
      "iter[7]-top1: [ 5.          0.          2.          2.          4.          0.91451981]\n",
      "iter[8]-top1: [ 5.          2.          1.          2.          4.          0.90029568]\n",
      "iter[9]-top1: [ 5.          0.          2.          2.          4.          0.91451981]\n",
      "iter[10]-top1: [ 5.          2.          1.          2.          4.          0.90029568]\n",
      "\n",
      "Modeling... VotingClassifier\n",
      "iter[1]-top1: [ 3.          0.          1.          2.          3.          0.86956657]\n",
      "iter[2]-top1: [ 5.         0.         1.         2.         5.         0.8819381]\n",
      "iter[3]-top1: [ 5.          0.          2.          2.          4.          0.90435902]\n",
      "iter[4]-top1: [ 5.          0.          0.          2.          2.          0.89049079]\n",
      "iter[5]-top1: [ 5.          0.          1.          2.          4.          0.88626883]\n",
      "iter[6]-top1: [ 5.          0.          2.          2.          5.          0.87240921]\n",
      "iter[7]-top1: [ 5.          4.          2.          2.          2.          0.87523968]\n",
      "iter[8]-top1: [ 5.          0.          1.          2.          0.          0.88951637]\n",
      "iter[9]-top1: [ 5.          0.          2.          2.          1.          0.87655793]\n",
      "iter[10]-top1: [ 5.          2.          2.          2.          2.          0.87568937]\n"
     ]
    }
   ],
   "source": [
    "#n_neighbors = 5 7 11\n",
    "#weights = 'distance'\n",
    "#algorithm = 'kd_tree' 'ball_tree'\n",
    "#estimator = KNeighborsClassifier(n_jobs=8, weights = 'distance', n_neighbors = 5, algorithm = 'kd_tree')\n",
    "#a = eda( getAccuracy, frecuencias, estimator )\n",
    "#a.run()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    return models\n",
    "\"\"\"\n",
    "estimadores = set_models()\n",
    "\n",
    "#reserva = {}\n",
    "lista_resultados = []\n",
    "for name, model in estimadores:\n",
    "    print(\"\\nModeling...\", name)\n",
    "    splits = 10\n",
    "    #simetricas = [[i]*5 for i in range(6)]\n",
    "    #for individual in simetricas:\n",
    "    #acc, desv, err = evaluate(frecuencias, individual, model)\n",
    "    #salida[str(name)+\"-\"+str(individual)] = str(acc) + \"-\"+ str(desv) + \"-\" + str(err)\n",
    "    #print(name,\" \", individual, \"\\t\", acc, \"\\t\", desv, \"\\t\", err)\n",
    "    #gs = EvolutiveSearchCV(estimator=model, scoring=\"accuracy\", num_folds=10, n_jobs=num_jobs,\n",
    "    #                    verbose=True, refit=True, \n",
    "    #                    population_size=100, \n",
    "    #                    gene_mutation_prob=0.3, \n",
    "    #                    gene_crossover_prob=0.5,\n",
    "    #                    tournament_size=4,\n",
    "    #                    generations_number=10)\n",
    "    a = eda( getAccuracy, frecuencias, model )\n",
    "    a.run()\n",
    "    #gs.fit(frecuencias)\n",
    "    #reserva[name]=(gs.score_cache, gs.desv_cache , gs.error_cache)\n",
    "    lista_resultados = lista_resultados + list(a.resultados)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.185316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12266</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.904359</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.199940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11645</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 3]</td>\n",
       "      <td>0.901487</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.217585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11880</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 5]</td>\n",
       "      <td>0.900296</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.285474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11053</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 4]</td>\n",
       "      <td>0.899511</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.213565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11560</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 4]</td>\n",
       "      <td>0.899267</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.282091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11919</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 2, 3, 4]</td>\n",
       "      <td>0.897565</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.253806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11361</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.896850</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.205363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11613</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.895867</td>\n",
       "      <td>0.009047</td>\n",
       "      <td>0.221426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11201</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 6, 3, 4]</td>\n",
       "      <td>0.894377</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.351797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11641</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 5]</td>\n",
       "      <td>0.892923</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>0.303146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11177</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 1, 3]</td>\n",
       "      <td>0.892444</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>0.252796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12035</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 1, 3, 2]</td>\n",
       "      <td>0.892176</td>\n",
       "      <td>0.015825</td>\n",
       "      <td>0.258867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11983</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 1]</td>\n",
       "      <td>0.891953</td>\n",
       "      <td>0.012587</td>\n",
       "      <td>0.330746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 2, 3, 5]</td>\n",
       "      <td>0.890931</td>\n",
       "      <td>0.015342</td>\n",
       "      <td>0.281643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12407</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 3]</td>\n",
       "      <td>0.890491</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>0.264053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11700</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 2, 3, 1]</td>\n",
       "      <td>0.890237</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.322348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11266</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 3]</td>\n",
       "      <td>0.890230</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.309097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 3, 3, 2]</td>\n",
       "      <td>0.890212</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.267753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11635</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 3, 4, 5]</td>\n",
       "      <td>0.890197</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.397993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12771</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 1]</td>\n",
       "      <td>0.889516</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.242226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11356</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 6]</td>\n",
       "      <td>0.889506</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.320004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11687</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 4]</td>\n",
       "      <td>0.889480</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.278274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11730</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 3, 3, 1]</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.015853</td>\n",
       "      <td>0.252018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11119</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[3, 1, 3, 6, 5]</td>\n",
       "      <td>0.888997</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.251329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11527</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 6, 3, 3, 2]</td>\n",
       "      <td>0.888537</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.343026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11171</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 4, 3, 2]</td>\n",
       "      <td>0.888229</td>\n",
       "      <td>0.016147</td>\n",
       "      <td>0.301604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11915</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 1, 3, 2]</td>\n",
       "      <td>0.887515</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>0.315821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11756</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 2, 3, 6]</td>\n",
       "      <td>0.887057</td>\n",
       "      <td>0.016659</td>\n",
       "      <td>0.292530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12013</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 2, 3, 2]</td>\n",
       "      <td>0.886332</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.279088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 6, 2, 2, 3]</td>\n",
       "      <td>0.423066</td>\n",
       "      <td>0.021372</td>\n",
       "      <td>1.581231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 4, 2, 3]</td>\n",
       "      <td>0.421809</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>1.558057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 4, 3, 3]</td>\n",
       "      <td>0.421431</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>1.685936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 5, 2, 4]</td>\n",
       "      <td>0.420732</td>\n",
       "      <td>0.034762</td>\n",
       "      <td>1.694155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6654</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[5, 2, 1, 5, 4]</td>\n",
       "      <td>0.419955</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>1.508277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 3, 5, 3]</td>\n",
       "      <td>0.419056</td>\n",
       "      <td>0.016850</td>\n",
       "      <td>1.542667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 4, 5, 5]</td>\n",
       "      <td>0.418961</td>\n",
       "      <td>0.028824</td>\n",
       "      <td>1.650632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 4, 2, 5]</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.021446</td>\n",
       "      <td>1.734582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 1, 5, 3]</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.027727</td>\n",
       "      <td>1.565682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 4, 4, 2, 3]</td>\n",
       "      <td>0.415656</td>\n",
       "      <td>0.033724</td>\n",
       "      <td>1.714427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[6, 2, 5, 5, 4]</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>1.691831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 6, 6, 2]</td>\n",
       "      <td>0.413259</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>1.526337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 1, 4, 3]</td>\n",
       "      <td>0.413162</td>\n",
       "      <td>0.031568</td>\n",
       "      <td>1.731319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 4, 5, 3]</td>\n",
       "      <td>0.405455</td>\n",
       "      <td>0.016395</td>\n",
       "      <td>1.715351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 4, 5, 3]</td>\n",
       "      <td>0.405221</td>\n",
       "      <td>0.046626</td>\n",
       "      <td>1.668807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 2, 4, 3]</td>\n",
       "      <td>0.405106</td>\n",
       "      <td>0.036076</td>\n",
       "      <td>1.713588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 5, 5, 1]</td>\n",
       "      <td>0.403820</td>\n",
       "      <td>0.036375</td>\n",
       "      <td>1.641445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 5, 2, 5, 3]</td>\n",
       "      <td>0.402352</td>\n",
       "      <td>0.032370</td>\n",
       "      <td>1.741361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 2, 5, 5, 2]</td>\n",
       "      <td>0.397598</td>\n",
       "      <td>0.031872</td>\n",
       "      <td>1.658666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 5, 3, 3]</td>\n",
       "      <td>0.395522</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>1.951455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 3, 2, 3]</td>\n",
       "      <td>0.395496</td>\n",
       "      <td>0.028140</td>\n",
       "      <td>1.696034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 5, 5, 5, 3]</td>\n",
       "      <td>0.390227</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>1.980451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 4, 1, 2, 3]</td>\n",
       "      <td>0.387164</td>\n",
       "      <td>0.033905</td>\n",
       "      <td>1.748202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 3, 2, 3, 1]</td>\n",
       "      <td>0.386235</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>1.224438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 2, 2, 1, 3]</td>\n",
       "      <td>0.383250</td>\n",
       "      <td>0.041203</td>\n",
       "      <td>1.399935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 4, 2, 3]</td>\n",
       "      <td>0.378005</td>\n",
       "      <td>0.031552</td>\n",
       "      <td>1.789375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 1, 2, 5]</td>\n",
       "      <td>0.373034</td>\n",
       "      <td>0.035059</td>\n",
       "      <td>1.583257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 2, 1, 3, 1]</td>\n",
       "      <td>0.371248</td>\n",
       "      <td>0.053470</td>\n",
       "      <td>1.170780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 1, 2, 2, 3]</td>\n",
       "      <td>0.370198</td>\n",
       "      <td>0.056502</td>\n",
       "      <td>1.392767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 1, 2, 3]</td>\n",
       "      <td>0.269936</td>\n",
       "      <td>0.044508</td>\n",
       "      <td>1.899153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9257 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "11561  GradientBoostingClassifier  [6, 1, 3, 3, 5]  0.914520     0.008447   \n",
       "12266            VotingClassifier  [6, 1, 3, 3, 5]  0.904359     0.010358   \n",
       "11645  GradientBoostingClassifier  [6, 1, 1, 3, 3]  0.901487     0.013594   \n",
       "11880  GradientBoostingClassifier  [6, 3, 2, 3, 5]  0.900296     0.012720   \n",
       "11053  GradientBoostingClassifier  [6, 1, 1, 3, 4]  0.899511     0.013050   \n",
       "11560  GradientBoostingClassifier  [6, 1, 2, 3, 4]  0.899267     0.012695   \n",
       "11919  GradientBoostingClassifier  [6, 5, 2, 3, 4]  0.897565     0.009551   \n",
       "11361  GradientBoostingClassifier  [6, 1, 3, 3, 3]  0.896850     0.009726   \n",
       "11613  GradientBoostingClassifier  [6, 1, 3, 3, 1]  0.895867     0.009047   \n",
       "11201  GradientBoostingClassifier  [6, 1, 6, 3, 4]  0.894377     0.015300   \n",
       "11641  GradientBoostingClassifier  [6, 3, 3, 3, 5]  0.892923     0.013625   \n",
       "11177  GradientBoostingClassifier  [6, 1, 3, 1, 3]  0.892444     0.011331   \n",
       "12035  GradientBoostingClassifier  [6, 4, 1, 3, 2]  0.892176     0.015825   \n",
       "11983  GradientBoostingClassifier  [6, 3, 2, 3, 1]  0.891953     0.012587   \n",
       "11946  GradientBoostingClassifier  [6, 4, 2, 3, 5]  0.890931     0.015342   \n",
       "12407            VotingClassifier  [6, 1, 1, 3, 3]  0.890491     0.017897   \n",
       "11700  GradientBoostingClassifier  [6, 5, 2, 3, 1]  0.890237     0.016098   \n",
       "11266  GradientBoostingClassifier  [6, 3, 3, 3, 3]  0.890230     0.010172   \n",
       "11990  GradientBoostingClassifier  [6, 4, 3, 3, 2]  0.890212     0.012968   \n",
       "11635  GradientBoostingClassifier  [6, 5, 3, 4, 5]  0.890197     0.010327   \n",
       "12771            VotingClassifier  [6, 1, 2, 3, 1]  0.889516     0.012902   \n",
       "11356  GradientBoostingClassifier  [6, 3, 2, 3, 6]  0.889506     0.013688   \n",
       "11687  GradientBoostingClassifier  [6, 3, 2, 3, 4]  0.889480     0.009786   \n",
       "11730  GradientBoostingClassifier  [6, 4, 3, 3, 1]  0.888998     0.015853   \n",
       "11119  GradientBoostingClassifier  [3, 1, 3, 6, 5]  0.888997     0.015706   \n",
       "11527  GradientBoostingClassifier  [6, 6, 3, 3, 2]  0.888537     0.007836   \n",
       "11171  GradientBoostingClassifier  [6, 5, 4, 3, 2]  0.888229     0.016147   \n",
       "11915  GradientBoostingClassifier  [6, 5, 1, 3, 2]  0.887515     0.018435   \n",
       "11756  GradientBoostingClassifier  [6, 4, 2, 3, 6]  0.887057     0.016659   \n",
       "12013  GradientBoostingClassifier  [6, 4, 2, 3, 2]  0.886332     0.019547   \n",
       "...                           ...              ...       ...          ...   \n",
       "3467                MLPClassifier  [2, 6, 2, 2, 3]  0.423066     0.021372   \n",
       "3952                MLPClassifier  [5, 3, 4, 2, 3]  0.421809     0.014842   \n",
       "3376                MLPClassifier  [1, 3, 4, 3, 3]  0.421431     0.027081   \n",
       "3696                MLPClassifier  [5, 2, 5, 2, 4]  0.420732     0.034762   \n",
       "6654           LogisticRegression  [5, 2, 1, 5, 4]  0.419955     0.010029   \n",
       "3308                MLPClassifier  [5, 2, 3, 5, 3]  0.419056     0.016850   \n",
       "3655                MLPClassifier  [5, 2, 4, 5, 5]  0.418961     0.028824   \n",
       "3615                MLPClassifier  [3, 2, 4, 2, 5]  0.417476     0.021446   \n",
       "3692                MLPClassifier  [5, 3, 1, 5, 3]  0.416800     0.027727   \n",
       "3433                MLPClassifier  [3, 4, 4, 2, 3]  0.415656     0.033724   \n",
       "3553                MLPClassifier  [6, 2, 5, 5, 4]  0.414286     0.027891   \n",
       "3337                MLPClassifier  [1, 2, 6, 6, 2]  0.413259     0.032207   \n",
       "3386                MLPClassifier  [3, 2, 1, 4, 3]  0.413162     0.031568   \n",
       "3858                MLPClassifier  [5, 3, 4, 5, 3]  0.405455     0.016395   \n",
       "3316                MLPClassifier  [5, 2, 4, 5, 3]  0.405221     0.046626   \n",
       "3451                MLPClassifier  [3, 2, 2, 4, 3]  0.405106     0.036076   \n",
       "3373                MLPClassifier  [1, 2, 5, 5, 1]  0.403820     0.036375   \n",
       "3412                MLPClassifier  [2, 5, 2, 5, 3]  0.402352     0.032370   \n",
       "3587                MLPClassifier  [4, 2, 5, 5, 2]  0.397598     0.031872   \n",
       "3322                MLPClassifier  [1, 3, 5, 3, 3]  0.395522     0.029703   \n",
       "3680                MLPClassifier  [3, 3, 3, 2, 3]  0.395496     0.028140   \n",
       "3329                MLPClassifier  [4, 5, 5, 5, 3]  0.390227     0.011855   \n",
       "3331                MLPClassifier  [3, 4, 1, 2, 3]  0.387164     0.033905   \n",
       "3294                MLPClassifier  [2, 3, 2, 3, 1]  0.386235     0.067227   \n",
       "3402                MLPClassifier  [2, 2, 2, 1, 3]  0.383250     0.041203   \n",
       "3464                MLPClassifier  [3, 3, 4, 2, 3]  0.378005     0.031552   \n",
       "3452                MLPClassifier  [1, 2, 1, 2, 5]  0.373034     0.035059   \n",
       "3403                MLPClassifier  [2, 2, 1, 3, 1]  0.371248     0.053470   \n",
       "3629                MLPClassifier  [3, 1, 2, 2, 3]  0.370198     0.056502   \n",
       "3443                MLPClassifier  [3, 3, 1, 2, 3]  0.269936     0.044508   \n",
       "\n",
       "       errorMetrico  \n",
       "11561      0.185316  \n",
       "12266      0.199940  \n",
       "11645      0.217585  \n",
       "11880      0.285474  \n",
       "11053      0.213565  \n",
       "11560      0.282091  \n",
       "11919      0.253806  \n",
       "11361      0.205363  \n",
       "11613      0.221426  \n",
       "11201      0.351797  \n",
       "11641      0.303146  \n",
       "11177      0.252796  \n",
       "12035      0.258867  \n",
       "11983      0.330746  \n",
       "11946      0.281643  \n",
       "12407      0.264053  \n",
       "11700      0.322348  \n",
       "11266      0.309097  \n",
       "11990      0.267753  \n",
       "11635      0.397993  \n",
       "12771      0.242226  \n",
       "11356      0.320004  \n",
       "11687      0.278274  \n",
       "11730      0.252018  \n",
       "11119      0.251329  \n",
       "11527      0.343026  \n",
       "11171      0.301604  \n",
       "11915      0.315821  \n",
       "11756      0.292530  \n",
       "12013      0.279088  \n",
       "...             ...  \n",
       "3467       1.581231  \n",
       "3952       1.558057  \n",
       "3376       1.685936  \n",
       "3696       1.694155  \n",
       "6654       1.508277  \n",
       "3308       1.542667  \n",
       "3655       1.650632  \n",
       "3615       1.734582  \n",
       "3692       1.565682  \n",
       "3433       1.714427  \n",
       "3553       1.691831  \n",
       "3337       1.526337  \n",
       "3386       1.731319  \n",
       "3858       1.715351  \n",
       "3316       1.668807  \n",
       "3451       1.713588  \n",
       "3373       1.641445  \n",
       "3412       1.741361  \n",
       "3587       1.658666  \n",
       "3322       1.951455  \n",
       "3680       1.696034  \n",
       "3329       1.980451  \n",
       "3331       1.748202  \n",
       "3294       1.224438  \n",
       "3402       1.399935  \n",
       "3464       1.789375  \n",
       "3452       1.583257  \n",
       "3403       1.170780  \n",
       "3629       1.392767  \n",
       "3443       1.899153  \n",
       "\n",
       "[9257 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(lista_resultados).sort_values(['Accuracy'],ascending=False).drop_duplicates(subset=['Modelo', 'Accuracy', 'stdAccuracy', 'errorMetrico'])\n",
    "df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico', 'values', 'error']].to_csv('EDAS_resultados.csv', sep=',', index=False) \n",
    "display(df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.185316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12266</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.904359</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.199940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10641</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.882418</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.286972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9771</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 1]</td>\n",
       "      <td>0.881202</td>\n",
       "      <td>0.012816</td>\n",
       "      <td>0.258637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[6, 6, 3, 3, 2]</td>\n",
       "      <td>0.867943</td>\n",
       "      <td>0.013143</td>\n",
       "      <td>0.399393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.866293</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.280348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>[6, 1, 3, 4, 5]</td>\n",
       "      <td>0.845358</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.341620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.832070</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.357042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>SVC</td>\n",
       "      <td>[5, 1, 3, 6, 1]</td>\n",
       "      <td>0.827804</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>0.404551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[6, 1, 3, 1, 5]</td>\n",
       "      <td>0.752972</td>\n",
       "      <td>0.014543</td>\n",
       "      <td>0.511191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[4, 5, 2, 3, 1]</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.780340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[6, 1, 2, 1, 5]</td>\n",
       "      <td>0.646278</td>\n",
       "      <td>0.020987</td>\n",
       "      <td>0.778324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "11561  GradientBoostingClassifier  [6, 1, 3, 3, 5]  0.914520     0.008447   \n",
       "12266            VotingClassifier  [6, 1, 3, 3, 5]  0.904359     0.010358   \n",
       "10641      RandomForestClassifier  [6, 1, 3, 3, 1]  0.882418     0.009747   \n",
       "9771           AdaBoostClassifier  [6, 1, 1, 3, 1]  0.881202     0.012816   \n",
       "7702         ExtraTreesClassifier  [6, 6, 3, 3, 2]  0.867943     0.013143   \n",
       "4986         KNeighborsClassifier  [6, 1, 3, 3, 1]  0.866293     0.011922   \n",
       "2847                   GaussianNB  [6, 1, 3, 4, 5]  0.845358     0.018558   \n",
       "5890       DecisionTreeClassifier  [6, 1, 3, 3, 1]  0.832070     0.010714   \n",
       "1255                          SVC  [5, 1, 3, 6, 1]  0.827804     0.019018   \n",
       "233    LinearDiscriminantAnalysis  [6, 1, 3, 1, 5]  0.752972     0.014543   \n",
       "7391           LogisticRegression  [4, 5, 2, 3, 1]  0.694200     0.017259   \n",
       "4300                MLPClassifier  [6, 1, 2, 1, 5]  0.646278     0.020987   \n",
       "\n",
       "       errorMetrico  \n",
       "11561      0.185316  \n",
       "12266      0.199940  \n",
       "10641      0.286972  \n",
       "9771       0.258637  \n",
       "7702       0.399393  \n",
       "4986       0.280348  \n",
       "2847       0.341620  \n",
       "5890       0.357042  \n",
       "1255       0.404551  \n",
       "233        0.511191  \n",
       "7391       0.780340  \n",
       "4300       0.778324  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#topDf = df.drop_duplicates(subset=['Modelo'])\n",
    "#display(topDf)\n",
    "#pd.DataFrame(salida).sort_values(['Accuracy'], ascending=False)\n",
    "topDf=df.drop_duplicates(subset=['Modelo'])#.drop_duplicates()\n",
    "topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico', 'values', 'error']].to_csv('EDAS_resultados_unique.csv', sep=',', index=False) \n",
    "display(topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataframe_plot = topDf\n",
    "def column_boxplot(dataframe_plot, column_plot, filename):\n",
    "    %pylab inline\n",
    "    pylab.rcParams['figure.figsize'] = (14, 8)\n",
    "    previos = ['LogisticRegression', 'LinearDiscriminantAnalysis', 'GaussianNB', 'MLPClassifier', \n",
    "               'SVC', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', \n",
    "               'ExtraTreesClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier', 'VotingClassifier']\n",
    "    nuevos = ['LoR', 'LDA', 'GNB', 'MLP', 'SVC', 'DT', 'k-NN', 'RF', 'ET', 'GBM', 'AB', 'VC']\n",
    "    num_models = len(nuevos)\n",
    "    num_splits = 10\n",
    "    dataframe_plot = dataframe_plot[['Modelo', 'Configuracion', 'Accuracy', 'errorMetrico', 'values', 'error']]\n",
    "    for i in range(12):\n",
    "        dataframe_plot['Modelo'] = dataframe_plot['Modelo'].str.replace(previos[i], nuevos[i])\n",
    "        #df['Modelo'] = df['Modelo'].str.replace('LinearDiscriminantAnalysis','LDA')\n",
    "    sorterIndex = dict(zip(nuevos,range(num_models)))\n",
    "    #test\n",
    "    dataframe_plot['Model_Rank'] = dataframe_plot['Modelo'].map(sorterIndex)\n",
    "    dataframe_plot = dataframe_plot.sort_values(['Model_Rank'],ascending=True).reset_index(drop=True)[dataframe_plot.columns[:-1]]\n",
    "    if column_plot == 'values':\n",
    "        y_label = 'Score'\n",
    "        x_label = 'Model'\n",
    "    else:\n",
    "        y_label = 'Error (m)'\n",
    "        x_label = 'Model Evaluated'\n",
    "    lista_plot = []\n",
    "    for i in range(num_models):\n",
    "        for j in range(num_splits):\n",
    "            d = {x_label:nuevos[i], y_label:dataframe_plot[column_plot][i][j]}\n",
    "            lista_plot.append(d)\n",
    "    #pd.DataFrame(lista_plot)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    ax_plot = sns.boxplot(data=pd.DataFrame(lista_plot), x=x_label, y=y_label, linewidth = 1.0)\n",
    "    plt.format='eps'\n",
    "    if column_plot == 'values':\n",
    "        medians = np.round(list(dataframe_plot['Accuracy']),3)\n",
    "        tope = 0.98\n",
    "    else:\n",
    "        medians = np.round(list(dataframe_plot['errorMetrico']),3)\n",
    "        tope = 6.8\n",
    "    median_labels = [str(s) for s in medians]\n",
    "    pos = range(num_models)\n",
    "    for tick,label in zip(pos,ax_plot.get_xticklabels()):\n",
    "        ax_plot.text(pos[tick], tope, median_labels[tick], \n",
    "                horizontalalignment='center', color='black') #, weight='semibold'\n",
    "    axes = plt.gca()\n",
    "    if column_plot == 'values':\n",
    "        axes.set_ylim([0.3,1.0])\n",
    "    else:\n",
    "        axes.set_ylim([-0.1, 7])\n",
    "    plt.savefig(filename + \".eps\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAHeCAYAAABT+34JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGOf/A7UEc/MUnndBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f880b924c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'values', 'accuracy_edas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzEAAAHeCAYAAACrG4X+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVN80fabgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f880337ef28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'error', 'error_edas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>error</th>\n",
       "      <th>errorMetrico</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>0.914520</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.12132034356, 0.0, ...</td>\n",
       "      <td>0.185316</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>[0.915841584158, 0.898514851485, 0.91584158415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12266</th>\n",
       "      <td>0.904359</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[0.0, 0.0, 3.35410196625, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.199940</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>[0.915841584158, 0.905940594059, 0.89108910891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10641</th>\n",
       "      <td>0.882418</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.286972</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>[0.909756097561, 0.872860635697, 0.88264058679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9771</th>\n",
       "      <td>0.881202</td>\n",
       "      <td>[6, 1, 1, 3, 1]</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...</td>\n",
       "      <td>0.258637</td>\n",
       "      <td>0.012816</td>\n",
       "      <td>[0.885365853659, 0.892420537897, 0.88753056234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>0.867943</td>\n",
       "      <td>[6, 6, 3, 3, 2]</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.399393</td>\n",
       "      <td>0.013143</td>\n",
       "      <td>[0.878934624697, 0.891041162228, 0.84261501210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>0.866293</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...</td>\n",
       "      <td>0.280348</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>[0.863414634146, 0.867970660147, 0.86797066014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>0.845358</td>\n",
       "      <td>[6, 1, 3, 4, 5]</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>[0.0, 0.0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.341620</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>[0.831683168317, 0.861386138614, 0.83168316831...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>0.832070</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...</td>\n",
       "      <td>0.357042</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>[0.831707317073, 0.821515892421, 0.81907090464...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>0.827804</td>\n",
       "      <td>[5, 1, 3, 6, 1]</td>\n",
       "      <td>SVC</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.12132034356, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.404551</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>[0.79702970297, 0.836633663366, 0.821782178218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.752972</td>\n",
       "      <td>[6, 1, 3, 1, 5]</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[0.0, 2.12132034356, 3.0, 0.0, 0.0, 1.5, 0.0, ...</td>\n",
       "      <td>0.511191</td>\n",
       "      <td>0.014543</td>\n",
       "      <td>[0.737623762376, 0.789603960396, 0.74752475247...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>0.694200</td>\n",
       "      <td>[4, 5, 2, 3, 1]</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[0.0, 1.5, 0.0, 0.0, 0.0, 1.5, 1.5, 0.0, 0.0, ...</td>\n",
       "      <td>0.780340</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>[0.702764976959, 0.716589861751, 0.69585253456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>0.646278</td>\n",
       "      <td>[6, 1, 2, 1, 5]</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[0.0, 3.35410196625, 1.5, 0.0, 0.0, 1.5, 0.0, ...</td>\n",
       "      <td>0.778324</td>\n",
       "      <td>0.020987</td>\n",
       "      <td>[0.60880195599, 0.643031784841, 0.660146699267...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy    Configuracion                      Modelo  \\\n",
       "11561  0.914520  [6, 1, 3, 3, 5]  GradientBoostingClassifier   \n",
       "12266  0.904359  [6, 1, 3, 3, 5]            VotingClassifier   \n",
       "10641  0.882418  [6, 1, 3, 3, 1]      RandomForestClassifier   \n",
       "9771   0.881202  [6, 1, 1, 3, 1]          AdaBoostClassifier   \n",
       "7702   0.867943  [6, 6, 3, 3, 2]        ExtraTreesClassifier   \n",
       "4986   0.866293  [6, 1, 3, 3, 1]        KNeighborsClassifier   \n",
       "2847   0.845358  [6, 1, 3, 4, 5]                  GaussianNB   \n",
       "5890   0.832070  [6, 1, 3, 3, 1]      DecisionTreeClassifier   \n",
       "1255   0.827804  [5, 1, 3, 6, 1]                         SVC   \n",
       "233    0.752972  [6, 1, 3, 1, 5]  LinearDiscriminantAnalysis   \n",
       "7391   0.694200  [4, 5, 2, 3, 1]          LogisticRegression   \n",
       "4300   0.646278  [6, 1, 2, 1, 5]               MLPClassifier   \n",
       "\n",
       "                                                   error  errorMetrico  \\\n",
       "11561  [0.0, 0.0, 0.0, 0.0, 0.0, 2.12132034356, 0.0, ...      0.185316   \n",
       "12266  [0.0, 0.0, 3.35410196625, 0.0, 0.0, 0.0, 0.0, ...      0.199940   \n",
       "10641  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.286972   \n",
       "9771   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...      0.258637   \n",
       "7702   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.399393   \n",
       "4986   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...      0.280348   \n",
       "2847   [0.0, 0.0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.341620   \n",
       "5890   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...      0.357042   \n",
       "1255   [0.0, 0.0, 0.0, 2.12132034356, 0.0, 0.0, 0.0, ...      0.404551   \n",
       "233    [0.0, 2.12132034356, 3.0, 0.0, 0.0, 1.5, 0.0, ...      0.511191   \n",
       "7391   [0.0, 1.5, 0.0, 0.0, 0.0, 1.5, 1.5, 0.0, 0.0, ...      0.780340   \n",
       "4300   [0.0, 3.35410196625, 1.5, 0.0, 0.0, 1.5, 0.0, ...      0.778324   \n",
       "\n",
       "       stdAccuracy                                             values  \n",
       "11561     0.008447  [0.915841584158, 0.898514851485, 0.91584158415...  \n",
       "12266     0.010358  [0.915841584158, 0.905940594059, 0.89108910891...  \n",
       "10641     0.009747  [0.909756097561, 0.872860635697, 0.88264058679...  \n",
       "9771      0.012816  [0.885365853659, 0.892420537897, 0.88753056234...  \n",
       "7702      0.013143  [0.878934624697, 0.891041162228, 0.84261501210...  \n",
       "4986      0.011922  [0.863414634146, 0.867970660147, 0.86797066014...  \n",
       "2847      0.018558  [0.831683168317, 0.861386138614, 0.83168316831...  \n",
       "5890      0.010714  [0.831707317073, 0.821515892421, 0.81907090464...  \n",
       "1255      0.019018  [0.79702970297, 0.836633663366, 0.821782178218...  \n",
       "233       0.014543  [0.737623762376, 0.789603960396, 0.74752475247...  \n",
       "7391      0.017259  [0.702764976959, 0.716589861751, 0.69585253456...  \n",
       "4300      0.020987  [0.60880195599, 0.643031784841, 0.660146699267...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topDf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
