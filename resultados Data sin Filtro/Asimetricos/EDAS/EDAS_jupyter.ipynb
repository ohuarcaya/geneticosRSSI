{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Librería Genética\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Subfunciones de estimadores\n",
    "from sklearn.base import clone\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][30]\n",
    "from sklearn.base import is_classifier\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][535]\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_validation.py][346]\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][386]\n",
    "from sklearn.model_selection._search import check_cv\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_split.py][1866]\n",
    "from sklearn.model_selection._search import _check_param_grid\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][343]\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/scorer.py][250]\n",
    "from sklearn.utils.validation import _num_samples\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][105]\n",
    "from sklearn.utils.validation import indexable\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][208]\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "#from itertools import product\n",
    "import itertools as it #import product\n",
    "\n",
    "# Selección para estimadores\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metricas para estimadores\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Estimadores\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Ensembles algorithms\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find distance error al 0.2%\n",
    "def distance_error(estimator, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 7)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    # coord pred\n",
    "    x1 = np.int32((y_pred + 2) % 3)\n",
    "    y1 = np.int32((y_pred - 1) / 3)\n",
    "    # coord real\n",
    "    x2 = np.int32((y_test + 2) % 3)\n",
    "    y2 = np.int32((y_test - 1) / 3)\n",
    "    # pasar variacion a distancias metros\n",
    "    vx = np.abs(x1 - x2)*1.5\n",
    "    vy = np.abs(y1 - y2)*1.5\n",
    "    #vx = vx*0.5 + (vx-1)*(vx>0)\n",
    "    #vy = vy*0.5 + (vy-1)*(vy>0)\n",
    "    # pitagoras\n",
    "    err_distance = np.sqrt(vx*vx + vy*vy)\n",
    "    return err_distance\n",
    "\n",
    "#def _createDataset(frecuencias, values, seed = 7):\n",
    "def _createDataset(frecuencias, values):\n",
    "    # crear dataset\n",
    "    names_ = frecuencias[0].columns.values\n",
    "    seed = 7\n",
    "    # reestructuracion\n",
    "    salida_final = pd.DataFrame(columns=names_)\n",
    "    for sec in range(1,16):\n",
    "        dataset = pd.DataFrame(columns=names_)\n",
    "        corte = min([frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values])\n",
    "        #l = [frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values]\n",
    "        #corte = max(l)\n",
    "        #tx=l.index(max(l))\n",
    "        tx = 0\n",
    "        dataset[names_[tx]] = dataset[names_[tx]].append(frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]])\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        for tx in range(1,5):\n",
    "            dataset[names_[tx]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]].reset_index(drop=True)\n",
    "        dataset[names_[tx+1]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx+1]].reset_index(drop=True)\n",
    "        # join parts\n",
    "        salida_final = salida_final.append(dataset)\n",
    "    # shuffle dataset\n",
    "    salida_final = shuffle(salida_final, random_state=seed).reset_index(drop=True)\n",
    "    salida_final = salida_final.apply(pd.to_numeric)\n",
    "    # dataframe to X,y \n",
    "    X = salida_final[names_[:-1]]\n",
    "    y = salida_final[names_[-1]]\n",
    "    return X,y\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    # LDA : Warning(Variables are collinear)\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('SVC', SVC(random_state=rs)))\n",
    "    models.append(('GaussianNB', GaussianNB()))\n",
    "    models.append(('MLPClassifier', MLPClassifier()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=rs)))\n",
    "    models.append(('LogisticRegression', LogisticRegression()))\n",
    "    # Bagging and Boosting\n",
    "    # models.append(('ExtraTreesClassifier', ExtraTreesClassifier(n_estimators=150)))\n",
    "    models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state=rs)))\n",
    "    models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier(random_state=rs),\n",
    "                                                            random_state=rs)))\n",
    "    # models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier())))\n",
    "    models.append(('RandomForestClassifier', RandomForestClassifier(random_state=rs)))\n",
    "    models.append(('GradientBoostingClassifier',\n",
    "                   GradientBoostingClassifier(random_state=rs)))\n",
    "    # models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "    # Voting\n",
    "    estimators = []\n",
    "    estimators.append((\"Voting_GradientBoostingClassifier\", GradientBoostingClassifier(random_state=rs)))\n",
    "    estimators.append((\"Voting_ExtraTreesClassifier\", ExtraTreesClassifier(random_state=rs)))\n",
    "    voting = VotingClassifier(estimators)\n",
    "    models.append(('VotingClassifier', voting))\n",
    "    return models\n",
    "\n",
    "# The problem to optimize\n",
    "def getAccuracy( frecuencias, individual, estimator, score_cache, resultados ):\n",
    "\tX,y = _createDataset(frecuencias, individual)\n",
    "\t#print(X)\n",
    "\t#print\n",
    "\t#print\n",
    "\t#print(y)\n",
    "\tscore = 0\n",
    "\tscorer = \"accuracy\"\n",
    "\tname = str(estimator).split('(')[0]\n",
    "\tparamkey = str(np.int32(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=10, shuffle=False)\n",
    "\t\tcv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scorer)\n",
    "\t\t#print(name,\"  \",paramkey,\"   \")\n",
    "\t\t#print(len(X),\"  \",len(y),\"   \", kfold)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\tdesv = cv_results.std()\n",
    "\t\terror = distance_error(estimator, X, y)\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\tdict_result = {'Modelo': name, 'Configuracion':np.int32(individual)+1, 'values': cv_results, 'Accuracy': score, 'stdAccuracy': desv, 'errorMetrico': np.mean(error), 'error': error }\n",
    "\t\tresultados.append(dict_result)\n",
    "\treturn score\n",
    "\"\"\"\n",
    "def _evalFunction(individual, frecuencias, scorer, num_folds, score_cache, desv_cache, error_cache, resultados_cache):\n",
    "\tX, y = _individual_to_params(frecuencias, individual)\n",
    "\tscore = 0\n",
    "\tn_test = 0\n",
    "\tname = str(individual.est).split('(')[0]\n",
    "\tparamkey = str(np.array(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=10, shuffle=False)\n",
    "\t\t#cv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scoring)\n",
    "\t\tcv_results = cross_val_score(individual.est, X, y, cv=kfold, scoring=scorer)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\tdesv_cache[paramkey] = cv_results.std()\n",
    "\t\terror_cache[paramkey] = distance_error(individual.est, X, y)\n",
    "\t\tresults = {'Modelo': name, 'Configuracion':np.int32(individual)+1, 'values': cv_results, 'Accuracy': score, 'stdAccuracy': desv_cache[paramkey], 'errorMetrico': error_cache[paramkey]}  \n",
    "\t\tresultados_cache.append(results)\n",
    "\treturn (score,)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class eda:\n",
    "\tdef __init__(self, of, frecuencias, estimator):\n",
    "\t\t# Algorithm parameters\n",
    "\t\tself.iterations = 10\n",
    "\t\tself.sample_size = 100\n",
    "\t\tself.select_ratio = 0.5\n",
    "\t\tself.epsilon = 10e-6\n",
    "\n",
    "\t\t# class members\n",
    "\t\tself.objective_function = of\n",
    "\t\tself.dimensions = 5\n",
    "\t\tself.sample = []\n",
    "\t\tself.means = []\n",
    "\t\tself.stdevs = []\t\n",
    "\n",
    "\t\tself.debug = False\n",
    "\t\t# aditional parameters\n",
    "\t\tself.frecuencias = frecuencias\n",
    "\t\tself.estimator = estimator\n",
    "\t\tself.__manager = Manager()\n",
    "\t\tself.score_cache = {}\n",
    "\t\tself.resultados = self.__manager.list()\n",
    "\t\tself.n_jobs = cpu_count()\n",
    "        \n",
    "\n",
    "\tdef sample_sort(self): \n",
    "\t\t# sort rows on the last column\n",
    "\t\tself.sample = self.sample[ np.argsort( self.sample[:,-1], 0 ) ]\n",
    "\n",
    "\n",
    "\tdef dispersion_reduction(self):\n",
    "\t\tself.sample_sort()\n",
    "\n",
    "\t\t# number of points to select\n",
    "\t\tnb = int( np.floor( self.sample_size * self.select_ratio ) )\n",
    "\n",
    "\t\t# selection\n",
    "\t\t#self.sample = self.sample[:nb]\n",
    "\t\tself.sample = self.sample[self.sample_size-nb:]\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"dispersion reduction\")\n",
    "\t\t\tprint (str(self.sample))\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef estimate_parameters( self ):\n",
    "\t\t# points sub array (without values)\n",
    "\t\tmat = self.sample[:,:self.dimensions]\n",
    "\t\t\n",
    "\t\t# row means (axis 0 in scipy)\n",
    "\t\tself.means = np.mean( mat, 0 )\n",
    "\t\t\n",
    "\t\t# row standard deviation\n",
    "\t\tself.stdevs = np.std( mat, 0 )\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"estimate parameters\")\n",
    "\t\t\tprint (\"\\tmean=\" +str(self.means))\n",
    "\t\t\tprint (\"\\tstd-dev=\" + str(self.stdevs))\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef draw_sample(self):\n",
    "\t\t# for each variable to optimize\n",
    "\t\tfor i in range(self.dimensions):\n",
    "\t\t\t# if the dispersion is null\n",
    "\t\t\tif self.stdevs[i] == 0.0:\n",
    "\t\t\t\t# set it to a minimal value\n",
    "\t\t\t\tself.stdevs[i] = self.epsilon\n",
    "\t\t\n",
    "\t\t# empty sample\n",
    "\t\tself.sample = np.zeros( (self.sample_size, self.dimensions+1) )\n",
    "\t\t\n",
    "\t\t# for each point\n",
    "\t\tfor i in range( self.sample_size ):\n",
    "\t\t\t# draw in random normal\n",
    "\t\t\tp = np.random.normal( self.means, self.stdevs )\n",
    "\t\t\tp = np.array([0 if i<0 else (5 if i>5 else i) for i in p])\n",
    "\t\t\t# put it into the sample\n",
    "\t\t\tself.sample[i][:self.dimensions] = np.round(p)%(self.dimensions+1)\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"draw sample\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef evaluate(self):\n",
    "\t\t# for each point\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in range( self.sample_size ):\n",
    "\t\t\td = self.dimensions\n",
    "\t\t\t# call the objective function\n",
    "\t\t\t#   the third element is the result of the objective function call\n",
    "\t\t\t#   taking the first two elements as variables\n",
    "\t\t\t#r = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache )\n",
    "\t\t\t#self.sample[i][-1] = r\n",
    "\t\t\tself.sample[i][-1] = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache , self.resultados)\n",
    "\t\t\"\"\"\n",
    "\t\td = self.dimensions\n",
    "\t\t_pool = Pool(self.n_jobs)\n",
    "\t\t#self.sample[i][-1] = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache , self.resultados)\n",
    "\t\t_iterable = it.product([self.frecuencias], np.int32(self.sample[:,:d]), [self.estimator], [self.score_cache], [self.resultados])\n",
    "\t\tself.sample[:,-1] = _pool.starmap(self.objective_function, _iterable)\n",
    "\t\t_pool.close()\n",
    "\t\t_pool.join()\n",
    "\t\t#getAccuracy( frecuencias, individual, estimator, score_cache, resultados ):\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"evaluate\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef run(self):\n",
    "\t\t# uniform initialization\n",
    "\t\tself.sample = np.random.rand( self.sample_size, self.dimensions+1 )\n",
    "\t\t# cosmetic\n",
    "\t\t#self.sample = self.sample * 200 - 100\n",
    "\t\ttop_freq = 6\n",
    "\t\tself.sample = np.floor(np.random.rand(self.sample_size, self.dimensions +1)*top_freq)\n",
    "\t\t\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"initialization\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\t\tself.evaluate()\n",
    "\n",
    "\t\t# Multi process\n",
    "\t\t\n",
    "\t\ti = 0\n",
    "\t\twhile i < self.iterations:\n",
    "\t\t\tif self.debug:\n",
    "\t\t\t\tprint (\"iteration\",i)\n",
    "\t\t\t\tprint\n",
    "\n",
    "\t\t\ti += 1\n",
    "\t\t\tself.dispersion_reduction()\n",
    "\t\t\tprint(\"iter[\"+str(i)+\"]-top1: \"+str(self.sample[-1]))\n",
    "\t\t\tself.estimate_parameters()\n",
    "\t\t\tself.draw_sample()\n",
    "\t\t\tself.evaluate()\n",
    "\t\t\t# print top 1\n",
    "\t\t\tself.sample_sort()\n",
    "\n",
    "\t\t# sort the final sample\n",
    "\t\tself.sample_sort()\n",
    "\t\t# output the optimum\n",
    "\t\t#self.pool.close()\n",
    "\t\t#self.pool.join()\n",
    "\t\tranking = self.sample_size\n",
    "\t\t#print (\"#[ Configuración ]\\t Accuracy\")\n",
    "\t\t#for i in range(ranking):\n",
    "\t\t#\tlinea = str(self.sample[-i-1][:-1]+1) + \"\\t\" +str(self.sample[-i-1][-1])\n",
    "\t\t#\tprint(linea)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "frecuencias = []\n",
    "names_ = ['Be01', 'Be02', 'Be03', 'Be04', 'Be05', 'Sector']\n",
    "\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x01'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x02'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x03'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x04'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x05'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x06'))#, names=names_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modeling... LinearDiscriminantAnalysis\n",
      "iter[1]-top1: [ 5.          0.          0.          5.          4.          0.74510763]\n",
      "iter[2]-top1: [ 5.          0.          2.          2.          5.          0.72744946]\n",
      "iter[3]-top1: [ 5.          0.          2.          0.          4.          0.75297214]\n",
      "iter[4]-top1: [ 5.          0.          2.          0.          0.          0.73380345]\n",
      "iter[5]-top1: [ 3.          0.          1.          0.          0.          0.73609261]\n",
      "iter[6]-top1: [ 3.          0.          3.          2.          0.          0.74027304]\n",
      "iter[7]-top1: [ 5.          3.          3.          2.          0.          0.71442543]\n",
      "iter[8]-top1: [ 5.          3.          2.          0.          0.          0.71809291]\n",
      "iter[9]-top1: [ 5.          4.          3.          2.          0.          0.72911702]\n",
      "iter[10]-top1: [ 5.          3.          2.          0.          0.          0.71809291]\n",
      "\n",
      "Modeling... SVC\n",
      "iter[1]-top1: [ 3.          0.          5.          5.          0.          0.80894265]\n",
      "iter[2]-top1: [ 4.          0.          2.          5.          0.          0.82780446]\n",
      "iter[3]-top1: [ 5.          3.          2.          2.          0.          0.80880196]\n",
      "iter[4]-top1: [ 5.          4.          2.          5.          0.          0.82656438]\n",
      "iter[5]-top1: [ 5.          5.          2.          5.          0.          0.81666528]\n",
      "iter[6]-top1: [ 5.          0.          3.          5.          0.          0.81711861]\n",
      "iter[7]-top1: [ 5.          4.          2.          2.          2.          0.79764597]\n",
      "iter[8]-top1: [ 5.          0.          1.          2.          0.          0.81129167]\n",
      "iter[9]-top1: [ 5.          2.          2.          2.          0.          0.81666647]\n",
      "iter[10]-top1: [ 5.          2.          1.          5.          0.          0.81886278]\n",
      "\n",
      "Modeling... GaussianNB\n",
      "iter[1]-top1: [ 5.          5.          0.          0.          4.          0.83193406]\n",
      "iter[2]-top1: [ 5.         3.         2.         3.         0.         0.8207824]\n",
      "iter[3]-top1: [ 3.          0.          2.          1.          0.          0.82214509]\n",
      "iter[4]-top1: [ 3.          3.          2.          3.          0.          0.81351221]\n",
      "iter[5]-top1: [ 3.          0.          2.          2.          0.          0.84503254]\n",
      "iter[6]-top1: [ 5.          0.          2.          3.          4.          0.84535784]\n",
      "iter[7]-top1: [ 5.          0.          2.          3.          4.          0.84535784]\n",
      "iter[8]-top1: [ 5.          5.          2.          2.          0.          0.82131254]\n",
      "iter[9]-top1: [ 3.          0.          1.          2.          3.          0.82565669]\n",
      "iter[10]-top1: [ 3.          5.          0.          2.          1.          0.82127139]\n",
      "\n",
      "Modeling... MLPClassifier\n",
      "iter[1]-top1: [ 0.          0.          2.          5.          0.          0.63065717]\n",
      "iter[2]-top1: [ 5.          0.          1.          2.          5.          0.63970779]\n",
      "iter[3]-top1: [ 3.          0.          3.          0.          5.          0.62652071]\n",
      "iter[4]-top1: [ 5.          3.          3.          5.          4.          0.60928266]\n",
      "iter[5]-top1: [ 5.          0.          3.          0.          3.          0.63470531]\n",
      "iter[6]-top1: [ 5.          0.          3.          0.          3.          0.64359378]\n",
      "iter[7]-top1: [ 3.          0.          3.          0.          5.          0.63951012]\n",
      "iter[8]-top1: [ 5.          0.          1.          0.          5.          0.64296082]\n",
      "iter[9]-top1: [ 5.          0.          3.          0.          5.          0.63277532]\n",
      "iter[10]-top1: [ 5.          0.          1.          0.          5.          0.64416621]\n",
      "\n",
      "Modeling... KNeighborsClassifier\n",
      "iter[1]-top1: [ 5.          5.          5.          0.          3.          0.83513824]\n",
      "iter[2]-top1: [ 3.          0.          2.          3.          0.          0.83524804]\n",
      "iter[3]-top1: [ 5.          0.          2.          2.          0.          0.86629256]\n",
      "iter[4]-top1: [ 5.          3.          2.          2.          4.          0.84254529]\n",
      "iter[5]-top1: [ 5.          3.          1.          2.          0.          0.85354523]\n",
      "iter[6]-top1: [ 5.          0.          2.          2.          0.          0.86629256]\n",
      "iter[7]-top1: [ 5.         0.         1.         2.         1.         0.8540718]\n",
      "iter[8]-top1: [ 5.          0.          2.          2.          0.          0.86629256]\n",
      "iter[9]-top1: [ 5.          0.          2.          2.          1.          0.85553104]\n",
      "iter[10]-top1: [ 5.          3.          1.          2.          0.          0.85354523]\n",
      "\n",
      "Modeling... DecisionTreeClassifier\n",
      "iter[1]-top1: [ 5.          0.          3.          2.          5.          0.82836186]\n",
      "iter[2]-top1: [ 5.          0.          5.          5.          0.          0.82266994]\n",
      "iter[3]-top1: [ 5.          5.          2.          2.          1.          0.82141035]\n",
      "iter[4]-top1: [ 5.          4.          3.          2.          1.          0.81404586]\n",
      "iter[5]-top1: [ 5.          0.          2.          2.          0.          0.83207049]\n",
      "iter[6]-top1: [ 5.          0.          3.          2.          0.          0.82909535]\n",
      "iter[7]-top1: [ 5.          3.          1.          2.          1.          0.81653189]\n",
      "iter[8]-top1: [ 5.          5.          0.          2.          1.          0.81935357]\n",
      "iter[9]-top1: [ 5.          5.          2.          2.          1.          0.82141035]\n",
      "iter[10]-top1: [ 5.          3.          1.          2.          5.          0.82404558]\n",
      "\n",
      "Modeling... LogisticRegression\n",
      "iter[1]-top1: [ 4.          0.          2.          2.          0.          0.67863876]\n",
      "iter[2]-top1: [ 5.          0.          2.          0.          2.          0.68296499]\n",
      "iter[3]-top1: [ 3.          3.          1.          3.          0.          0.65295439]\n",
      "iter[4]-top1: [ 5.          3.          1.          0.          4.          0.66676195]\n",
      "iter[5]-top1: [ 5.          4.          1.          2.          0.          0.65412132]\n",
      "iter[6]-top1: [ 3.          5.          1.          0.          0.          0.66306378]\n",
      "iter[7]-top1: [ 5.          3.          2.          0.          5.          0.65843521]\n",
      "iter[8]-top1: [ 3.          4.          1.          2.          0.          0.69419972]\n",
      "iter[9]-top1: [ 3.          4.          1.          2.          0.          0.69419972]\n",
      "iter[10]-top1: [ 5.          3.          2.          2.          4.          0.65609855]\n",
      "\n",
      "Modeling... ExtraTreesClassifier\n",
      "iter[1]-top1: [ 5.          5.          2.          2.          1.          0.86794295]\n",
      "iter[2]-top1: [ 5.          4.          2.          2.          4.          0.85731139]\n",
      "iter[3]-top1: [ 5.          5.          3.          2.          1.          0.85530866]\n",
      "iter[4]-top1: [ 3.        4.        1.        5.        0.        0.864933]\n",
      "iter[5]-top1: [ 5.          2.          2.          5.          4.          0.85780761]\n",
      "iter[6]-top1: [ 5.         4.         2.         2.         2.         0.8678759]\n",
      "iter[7]-top1: [ 5.          3.          2.          2.          0.          0.86479218]\n",
      "iter[8]-top1: [ 5.         4.         2.         2.         2.         0.8678759]\n",
      "iter[9]-top1: [ 5.          5.          2.          2.          1.          0.86794295]\n",
      "iter[10]-top1: [ 5.         4.         2.         2.         2.         0.8678759]\n",
      "\n",
      "Modeling... AdaBoostClassifier\n",
      "iter[1]-top1: [ 5.          0.          2.          1.          4.          0.87314571]\n",
      "iter[2]-top1: [ 5.          4.          2.          2.          4.          0.85485378]\n",
      "iter[3]-top1: [ 5.          3.          2.          2.          1.          0.86718482]\n",
      "iter[4]-top1: [ 5.          4.          3.          5.          0.          0.86445299]\n",
      "iter[5]-top1: [ 5.         0.         3.         0.         4.         0.8646951]\n",
      "iter[6]-top1: [ 5.          0.          2.          3.          4.          0.87387293]\n",
      "iter[7]-top1: [ 5.          0.          2.          0.          2.          0.87166975]\n",
      "iter[8]-top1: [ 5.          0.          1.          2.          3.          0.88117359]\n",
      "iter[9]-top1: [ 5.          0.          1.          2.          3.          0.88117359]\n",
      "iter[10]-top1: [ 5.          0.          0.          2.          1.          0.87753354]\n",
      "\n",
      "Modeling... RandomForestClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter[1]-top1: [ 5.          4.          2.          2.          0.          0.86471452]\n",
      "iter[2]-top1: [ 5.          0.          1.          0.          0.          0.87168938]\n",
      "iter[3]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[4]-top1: [ 5.          0.          5.          2.          0.          0.87264834]\n",
      "iter[5]-top1: [ 5.          0.          2.          2.          5.          0.86726996]\n",
      "iter[6]-top1: [ 5.          5.          1.          2.          1.          0.86212476]\n",
      "iter[7]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[8]-top1: [ 5.          0.          2.          2.          0.          0.88241815]\n",
      "iter[9]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[10]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "\n",
      "Modeling... GradientBoostingClassifier\n",
      "iter[1]-top1: [ 5.          3.          3.          2.          5.          0.88195656]\n",
      "iter[2]-top1: [ 5.        0.        0.        2.        3.        0.899511]\n",
      "iter[3]-top1: [ 5.          0.          5.          2.          3.          0.89437653]\n",
      "iter[4]-top1: [ 5.          2.          2.          2.          2.          0.89022955]\n",
      "iter[5]-top1: [ 5.          0.          2.          2.          2.          0.89685014]\n",
      "iter[6]-top1: [ 5.          4.          1.          2.          3.          0.89756468]\n",
      "iter[7]-top1: [ 5.          0.          2.          2.          4.          0.91451981]\n",
      "iter[8]-top1: [ 5.          2.          1.          2.          4.          0.90029568]\n",
      "iter[9]-top1: [ 5.          0.          2.          2.          4.          0.91451981]\n",
      "iter[10]-top1: [ 5.          2.          1.          2.          4.          0.90029568]\n",
      "\n",
      "Modeling... VotingClassifier\n",
      "iter[1]-top1: [ 3.          0.          1.          2.          3.          0.86956657]\n",
      "iter[2]-top1: [ 5.         0.         1.         2.         5.         0.8819381]\n",
      "iter[3]-top1: [ 5.          0.          2.          2.          4.          0.90435902]\n",
      "iter[4]-top1: [ 5.          0.          0.          2.          2.          0.89049079]\n",
      "iter[5]-top1: [ 5.          0.          1.          2.          4.          0.88626883]\n",
      "iter[6]-top1: [ 5.          0.          2.          2.          5.          0.87240921]\n",
      "iter[7]-top1: [ 5.          4.          2.          2.          2.          0.87523968]\n",
      "iter[8]-top1: [ 5.          0.          1.          2.          0.          0.88951637]\n",
      "iter[9]-top1: [ 5.          0.          2.          2.          1.          0.87655793]\n",
      "iter[10]-top1: [ 5.          2.          2.          2.          2.          0.87568937]\n"
     ]
    }
   ],
   "source": [
    "#n_neighbors = 5 7 11\n",
    "#weights = 'distance'\n",
    "#algorithm = 'kd_tree' 'ball_tree'\n",
    "#estimator = KNeighborsClassifier(n_jobs=8, weights = 'distance', n_neighbors = 5, algorithm = 'kd_tree')\n",
    "#a = eda( getAccuracy, frecuencias, estimator )\n",
    "#a.run()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    return models\n",
    "\"\"\"\n",
    "estimadores = set_models()\n",
    "\n",
    "#reserva = {}\n",
    "lista_resultados = []\n",
    "for name, model in estimadores:\n",
    "    print(\"\\nModeling...\", name)\n",
    "    splits = 10\n",
    "    #simetricas = [[i]*5 for i in range(6)]\n",
    "    #for individual in simetricas:\n",
    "    #acc, desv, err = evaluate(frecuencias, individual, model)\n",
    "    #salida[str(name)+\"-\"+str(individual)] = str(acc) + \"-\"+ str(desv) + \"-\" + str(err)\n",
    "    #print(name,\" \", individual, \"\\t\", acc, \"\\t\", desv, \"\\t\", err)\n",
    "    #gs = EvolutiveSearchCV(estimator=model, scoring=\"accuracy\", num_folds=10, n_jobs=num_jobs,\n",
    "    #                    verbose=True, refit=True, \n",
    "    #                    population_size=100, \n",
    "    #                    gene_mutation_prob=0.3, \n",
    "    #                    gene_crossover_prob=0.5,\n",
    "    #                    tournament_size=4,\n",
    "    #                    generations_number=10)\n",
    "    a = eda( getAccuracy, frecuencias, model )\n",
    "    a.run()\n",
    "    #gs.fit(frecuencias)\n",
    "    #reserva[name]=(gs.score_cache, gs.desv_cache , gs.error_cache)\n",
    "    lista_resultados = lista_resultados + list(a.resultados)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.185316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12266</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.904359</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.199940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11645</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 3]</td>\n",
       "      <td>0.901487</td>\n",
       "      <td>0.013594</td>\n",
       "      <td>0.217585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11880</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 5]</td>\n",
       "      <td>0.900296</td>\n",
       "      <td>0.012720</td>\n",
       "      <td>0.285474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11053</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 4]</td>\n",
       "      <td>0.899511</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.213565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11560</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 4]</td>\n",
       "      <td>0.899267</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.282091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11919</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 2, 3, 4]</td>\n",
       "      <td>0.897565</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.253806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11361</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.896850</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.205363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11613</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.895867</td>\n",
       "      <td>0.009047</td>\n",
       "      <td>0.221426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11201</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 6, 3, 4]</td>\n",
       "      <td>0.894377</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.351797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11641</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 5]</td>\n",
       "      <td>0.892923</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>0.303146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11177</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 1, 3]</td>\n",
       "      <td>0.892444</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>0.252796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12035</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 1, 3, 2]</td>\n",
       "      <td>0.892176</td>\n",
       "      <td>0.015825</td>\n",
       "      <td>0.258867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11983</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 1]</td>\n",
       "      <td>0.891953</td>\n",
       "      <td>0.012587</td>\n",
       "      <td>0.330746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 2, 3, 5]</td>\n",
       "      <td>0.890931</td>\n",
       "      <td>0.015342</td>\n",
       "      <td>0.281643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12407</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 3]</td>\n",
       "      <td>0.890491</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>0.264053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11700</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 2, 3, 1]</td>\n",
       "      <td>0.890237</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.322348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11266</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 3]</td>\n",
       "      <td>0.890230</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.309097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 3, 3, 2]</td>\n",
       "      <td>0.890212</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.267753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11635</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 3, 4, 5]</td>\n",
       "      <td>0.890197</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.397993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12771</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 1]</td>\n",
       "      <td>0.889516</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.242226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11356</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 6]</td>\n",
       "      <td>0.889506</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.320004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11687</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 4]</td>\n",
       "      <td>0.889480</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.278274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11730</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 3, 3, 1]</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.015853</td>\n",
       "      <td>0.252018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11119</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[3, 1, 3, 6, 5]</td>\n",
       "      <td>0.888997</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.251329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11527</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 6, 3, 3, 2]</td>\n",
       "      <td>0.888537</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.343026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11171</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 4, 3, 2]</td>\n",
       "      <td>0.888229</td>\n",
       "      <td>0.016147</td>\n",
       "      <td>0.301604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11915</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 1, 3, 2]</td>\n",
       "      <td>0.887515</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>0.315821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11756</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 2, 3, 6]</td>\n",
       "      <td>0.887057</td>\n",
       "      <td>0.016659</td>\n",
       "      <td>0.292530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12013</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 2, 3, 2]</td>\n",
       "      <td>0.886332</td>\n",
       "      <td>0.019547</td>\n",
       "      <td>0.279088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 6, 2, 2, 3]</td>\n",
       "      <td>0.423066</td>\n",
       "      <td>0.021372</td>\n",
       "      <td>1.581231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 4, 2, 3]</td>\n",
       "      <td>0.421809</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>1.558057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3376</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 4, 3, 3]</td>\n",
       "      <td>0.421431</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>1.685936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3696</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 5, 2, 4]</td>\n",
       "      <td>0.420732</td>\n",
       "      <td>0.034762</td>\n",
       "      <td>1.694155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6654</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[5, 2, 1, 5, 4]</td>\n",
       "      <td>0.419955</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>1.508277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 3, 5, 3]</td>\n",
       "      <td>0.419056</td>\n",
       "      <td>0.016850</td>\n",
       "      <td>1.542667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 4, 5, 5]</td>\n",
       "      <td>0.418961</td>\n",
       "      <td>0.028824</td>\n",
       "      <td>1.650632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 4, 2, 5]</td>\n",
       "      <td>0.417476</td>\n",
       "      <td>0.021446</td>\n",
       "      <td>1.734582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3692</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 1, 5, 3]</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.027727</td>\n",
       "      <td>1.565682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 4, 4, 2, 3]</td>\n",
       "      <td>0.415656</td>\n",
       "      <td>0.033724</td>\n",
       "      <td>1.714427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[6, 2, 5, 5, 4]</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>1.691831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 6, 6, 2]</td>\n",
       "      <td>0.413259</td>\n",
       "      <td>0.032207</td>\n",
       "      <td>1.526337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 1, 4, 3]</td>\n",
       "      <td>0.413162</td>\n",
       "      <td>0.031568</td>\n",
       "      <td>1.731319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 4, 5, 3]</td>\n",
       "      <td>0.405455</td>\n",
       "      <td>0.016395</td>\n",
       "      <td>1.715351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 4, 5, 3]</td>\n",
       "      <td>0.405221</td>\n",
       "      <td>0.046626</td>\n",
       "      <td>1.668807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 2, 4, 3]</td>\n",
       "      <td>0.405106</td>\n",
       "      <td>0.036076</td>\n",
       "      <td>1.713588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 5, 5, 1]</td>\n",
       "      <td>0.403820</td>\n",
       "      <td>0.036375</td>\n",
       "      <td>1.641445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 5, 2, 5, 3]</td>\n",
       "      <td>0.402352</td>\n",
       "      <td>0.032370</td>\n",
       "      <td>1.741361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 2, 5, 5, 2]</td>\n",
       "      <td>0.397598</td>\n",
       "      <td>0.031872</td>\n",
       "      <td>1.658666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 5, 3, 3]</td>\n",
       "      <td>0.395522</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>1.951455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 3, 2, 3]</td>\n",
       "      <td>0.395496</td>\n",
       "      <td>0.028140</td>\n",
       "      <td>1.696034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 5, 5, 5, 3]</td>\n",
       "      <td>0.390227</td>\n",
       "      <td>0.011855</td>\n",
       "      <td>1.980451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 4, 1, 2, 3]</td>\n",
       "      <td>0.387164</td>\n",
       "      <td>0.033905</td>\n",
       "      <td>1.748202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3294</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 3, 2, 3, 1]</td>\n",
       "      <td>0.386235</td>\n",
       "      <td>0.067227</td>\n",
       "      <td>1.224438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 2, 2, 1, 3]</td>\n",
       "      <td>0.383250</td>\n",
       "      <td>0.041203</td>\n",
       "      <td>1.399935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 4, 2, 3]</td>\n",
       "      <td>0.378005</td>\n",
       "      <td>0.031552</td>\n",
       "      <td>1.789375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 1, 2, 5]</td>\n",
       "      <td>0.373034</td>\n",
       "      <td>0.035059</td>\n",
       "      <td>1.583257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3403</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 2, 1, 3, 1]</td>\n",
       "      <td>0.371248</td>\n",
       "      <td>0.053470</td>\n",
       "      <td>1.170780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 1, 2, 2, 3]</td>\n",
       "      <td>0.370198</td>\n",
       "      <td>0.056502</td>\n",
       "      <td>1.392767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 1, 2, 3]</td>\n",
       "      <td>0.269936</td>\n",
       "      <td>0.044508</td>\n",
       "      <td>1.899153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9257 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "11561  GradientBoostingClassifier  [6, 1, 3, 3, 5]  0.914520     0.008447   \n",
       "12266            VotingClassifier  [6, 1, 3, 3, 5]  0.904359     0.010358   \n",
       "11645  GradientBoostingClassifier  [6, 1, 1, 3, 3]  0.901487     0.013594   \n",
       "11880  GradientBoostingClassifier  [6, 3, 2, 3, 5]  0.900296     0.012720   \n",
       "11053  GradientBoostingClassifier  [6, 1, 1, 3, 4]  0.899511     0.013050   \n",
       "11560  GradientBoostingClassifier  [6, 1, 2, 3, 4]  0.899267     0.012695   \n",
       "11919  GradientBoostingClassifier  [6, 5, 2, 3, 4]  0.897565     0.009551   \n",
       "11361  GradientBoostingClassifier  [6, 1, 3, 3, 3]  0.896850     0.009726   \n",
       "11613  GradientBoostingClassifier  [6, 1, 3, 3, 1]  0.895867     0.009047   \n",
       "11201  GradientBoostingClassifier  [6, 1, 6, 3, 4]  0.894377     0.015300   \n",
       "11641  GradientBoostingClassifier  [6, 3, 3, 3, 5]  0.892923     0.013625   \n",
       "11177  GradientBoostingClassifier  [6, 1, 3, 1, 3]  0.892444     0.011331   \n",
       "12035  GradientBoostingClassifier  [6, 4, 1, 3, 2]  0.892176     0.015825   \n",
       "11983  GradientBoostingClassifier  [6, 3, 2, 3, 1]  0.891953     0.012587   \n",
       "11946  GradientBoostingClassifier  [6, 4, 2, 3, 5]  0.890931     0.015342   \n",
       "12407            VotingClassifier  [6, 1, 1, 3, 3]  0.890491     0.017897   \n",
       "11700  GradientBoostingClassifier  [6, 5, 2, 3, 1]  0.890237     0.016098   \n",
       "11266  GradientBoostingClassifier  [6, 3, 3, 3, 3]  0.890230     0.010172   \n",
       "11990  GradientBoostingClassifier  [6, 4, 3, 3, 2]  0.890212     0.012968   \n",
       "11635  GradientBoostingClassifier  [6, 5, 3, 4, 5]  0.890197     0.010327   \n",
       "12771            VotingClassifier  [6, 1, 2, 3, 1]  0.889516     0.012902   \n",
       "11356  GradientBoostingClassifier  [6, 3, 2, 3, 6]  0.889506     0.013688   \n",
       "11687  GradientBoostingClassifier  [6, 3, 2, 3, 4]  0.889480     0.009786   \n",
       "11730  GradientBoostingClassifier  [6, 4, 3, 3, 1]  0.888998     0.015853   \n",
       "11119  GradientBoostingClassifier  [3, 1, 3, 6, 5]  0.888997     0.015706   \n",
       "11527  GradientBoostingClassifier  [6, 6, 3, 3, 2]  0.888537     0.007836   \n",
       "11171  GradientBoostingClassifier  [6, 5, 4, 3, 2]  0.888229     0.016147   \n",
       "11915  GradientBoostingClassifier  [6, 5, 1, 3, 2]  0.887515     0.018435   \n",
       "11756  GradientBoostingClassifier  [6, 4, 2, 3, 6]  0.887057     0.016659   \n",
       "12013  GradientBoostingClassifier  [6, 4, 2, 3, 2]  0.886332     0.019547   \n",
       "...                           ...              ...       ...          ...   \n",
       "3467                MLPClassifier  [2, 6, 2, 2, 3]  0.423066     0.021372   \n",
       "3952                MLPClassifier  [5, 3, 4, 2, 3]  0.421809     0.014842   \n",
       "3376                MLPClassifier  [1, 3, 4, 3, 3]  0.421431     0.027081   \n",
       "3696                MLPClassifier  [5, 2, 5, 2, 4]  0.420732     0.034762   \n",
       "6654           LogisticRegression  [5, 2, 1, 5, 4]  0.419955     0.010029   \n",
       "3308                MLPClassifier  [5, 2, 3, 5, 3]  0.419056     0.016850   \n",
       "3655                MLPClassifier  [5, 2, 4, 5, 5]  0.418961     0.028824   \n",
       "3615                MLPClassifier  [3, 2, 4, 2, 5]  0.417476     0.021446   \n",
       "3692                MLPClassifier  [5, 3, 1, 5, 3]  0.416800     0.027727   \n",
       "3433                MLPClassifier  [3, 4, 4, 2, 3]  0.415656     0.033724   \n",
       "3553                MLPClassifier  [6, 2, 5, 5, 4]  0.414286     0.027891   \n",
       "3337                MLPClassifier  [1, 2, 6, 6, 2]  0.413259     0.032207   \n",
       "3386                MLPClassifier  [3, 2, 1, 4, 3]  0.413162     0.031568   \n",
       "3858                MLPClassifier  [5, 3, 4, 5, 3]  0.405455     0.016395   \n",
       "3316                MLPClassifier  [5, 2, 4, 5, 3]  0.405221     0.046626   \n",
       "3451                MLPClassifier  [3, 2, 2, 4, 3]  0.405106     0.036076   \n",
       "3373                MLPClassifier  [1, 2, 5, 5, 1]  0.403820     0.036375   \n",
       "3412                MLPClassifier  [2, 5, 2, 5, 3]  0.402352     0.032370   \n",
       "3587                MLPClassifier  [4, 2, 5, 5, 2]  0.397598     0.031872   \n",
       "3322                MLPClassifier  [1, 3, 5, 3, 3]  0.395522     0.029703   \n",
       "3680                MLPClassifier  [3, 3, 3, 2, 3]  0.395496     0.028140   \n",
       "3329                MLPClassifier  [4, 5, 5, 5, 3]  0.390227     0.011855   \n",
       "3331                MLPClassifier  [3, 4, 1, 2, 3]  0.387164     0.033905   \n",
       "3294                MLPClassifier  [2, 3, 2, 3, 1]  0.386235     0.067227   \n",
       "3402                MLPClassifier  [2, 2, 2, 1, 3]  0.383250     0.041203   \n",
       "3464                MLPClassifier  [3, 3, 4, 2, 3]  0.378005     0.031552   \n",
       "3452                MLPClassifier  [1, 2, 1, 2, 5]  0.373034     0.035059   \n",
       "3403                MLPClassifier  [2, 2, 1, 3, 1]  0.371248     0.053470   \n",
       "3629                MLPClassifier  [3, 1, 2, 2, 3]  0.370198     0.056502   \n",
       "3443                MLPClassifier  [3, 3, 1, 2, 3]  0.269936     0.044508   \n",
       "\n",
       "       errorMetrico  \n",
       "11561      0.185316  \n",
       "12266      0.199940  \n",
       "11645      0.217585  \n",
       "11880      0.285474  \n",
       "11053      0.213565  \n",
       "11560      0.282091  \n",
       "11919      0.253806  \n",
       "11361      0.205363  \n",
       "11613      0.221426  \n",
       "11201      0.351797  \n",
       "11641      0.303146  \n",
       "11177      0.252796  \n",
       "12035      0.258867  \n",
       "11983      0.330746  \n",
       "11946      0.281643  \n",
       "12407      0.264053  \n",
       "11700      0.322348  \n",
       "11266      0.309097  \n",
       "11990      0.267753  \n",
       "11635      0.397993  \n",
       "12771      0.242226  \n",
       "11356      0.320004  \n",
       "11687      0.278274  \n",
       "11730      0.252018  \n",
       "11119      0.251329  \n",
       "11527      0.343026  \n",
       "11171      0.301604  \n",
       "11915      0.315821  \n",
       "11756      0.292530  \n",
       "12013      0.279088  \n",
       "...             ...  \n",
       "3467       1.581231  \n",
       "3952       1.558057  \n",
       "3376       1.685936  \n",
       "3696       1.694155  \n",
       "6654       1.508277  \n",
       "3308       1.542667  \n",
       "3655       1.650632  \n",
       "3615       1.734582  \n",
       "3692       1.565682  \n",
       "3433       1.714427  \n",
       "3553       1.691831  \n",
       "3337       1.526337  \n",
       "3386       1.731319  \n",
       "3858       1.715351  \n",
       "3316       1.668807  \n",
       "3451       1.713588  \n",
       "3373       1.641445  \n",
       "3412       1.741361  \n",
       "3587       1.658666  \n",
       "3322       1.951455  \n",
       "3680       1.696034  \n",
       "3329       1.980451  \n",
       "3331       1.748202  \n",
       "3294       1.224438  \n",
       "3402       1.399935  \n",
       "3464       1.789375  \n",
       "3452       1.583257  \n",
       "3403       1.170780  \n",
       "3629       1.392767  \n",
       "3443       1.899153  \n",
       "\n",
       "[9257 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(lista_resultados).sort_values(['Accuracy'],ascending=False).drop_duplicates(subset=['Modelo', 'Accuracy', 'stdAccuracy', 'errorMetrico'])\n",
    "df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']].to_csv('EDAS_resultados.csv', sep=',', index=False) \n",
    "display(df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.185316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12266</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.904359</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.199940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10641</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.882418</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.286972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9771</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 1]</td>\n",
       "      <td>0.881202</td>\n",
       "      <td>0.012816</td>\n",
       "      <td>0.258637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[6, 6, 3, 3, 2]</td>\n",
       "      <td>0.867943</td>\n",
       "      <td>0.013143</td>\n",
       "      <td>0.399393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.866293</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.280348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>[6, 1, 3, 4, 5]</td>\n",
       "      <td>0.845358</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.341620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.832070</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.357042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>SVC</td>\n",
       "      <td>[5, 1, 3, 6, 1]</td>\n",
       "      <td>0.827804</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>0.404551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[6, 1, 3, 1, 5]</td>\n",
       "      <td>0.752972</td>\n",
       "      <td>0.014543</td>\n",
       "      <td>0.511191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[4, 5, 2, 3, 1]</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.780340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[6, 1, 2, 1, 5]</td>\n",
       "      <td>0.646278</td>\n",
       "      <td>0.020987</td>\n",
       "      <td>0.778324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "11561  GradientBoostingClassifier  [6, 1, 3, 3, 5]  0.914520     0.008447   \n",
       "12266            VotingClassifier  [6, 1, 3, 3, 5]  0.904359     0.010358   \n",
       "10641      RandomForestClassifier  [6, 1, 3, 3, 1]  0.882418     0.009747   \n",
       "9771           AdaBoostClassifier  [6, 1, 1, 3, 1]  0.881202     0.012816   \n",
       "7702         ExtraTreesClassifier  [6, 6, 3, 3, 2]  0.867943     0.013143   \n",
       "4986         KNeighborsClassifier  [6, 1, 3, 3, 1]  0.866293     0.011922   \n",
       "2847                   GaussianNB  [6, 1, 3, 4, 5]  0.845358     0.018558   \n",
       "5890       DecisionTreeClassifier  [6, 1, 3, 3, 1]  0.832070     0.010714   \n",
       "1255                          SVC  [5, 1, 3, 6, 1]  0.827804     0.019018   \n",
       "233    LinearDiscriminantAnalysis  [6, 1, 3, 1, 5]  0.752972     0.014543   \n",
       "7391           LogisticRegression  [4, 5, 2, 3, 1]  0.694200     0.017259   \n",
       "4300                MLPClassifier  [6, 1, 2, 1, 5]  0.646278     0.020987   \n",
       "\n",
       "       errorMetrico  \n",
       "11561      0.185316  \n",
       "12266      0.199940  \n",
       "10641      0.286972  \n",
       "9771       0.258637  \n",
       "7702       0.399393  \n",
       "4986       0.280348  \n",
       "2847       0.341620  \n",
       "5890       0.357042  \n",
       "1255       0.404551  \n",
       "233        0.511191  \n",
       "7391       0.780340  \n",
       "4300       0.778324  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#topDf = df.drop_duplicates(subset=['Modelo'])\n",
    "#display(topDf)\n",
    "#pd.DataFrame(salida).sort_values(['Accuracy'], ascending=False)\n",
    "topDf=df.drop_duplicates(subset=['Modelo'])#.drop_duplicates()\n",
    "topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']].to_csv('EDAS_resultados_unique.csv', sep=',', index=False) \n",
    "display(topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#dataframe_plot = topDf\n",
    "def column_boxplot(dataframe_plot, column_plot, filename, box_bool=True):\n",
    "    %pylab inline\n",
    "    pylab.rcParams['figure.figsize'] = (14, 8)\n",
    "    previos = ['LogisticRegression', 'LinearDiscriminantAnalysis', 'GaussianNB', 'MLPClassifier', \n",
    "               'SVC', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', \n",
    "               'ExtraTreesClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier', 'VotingClassifier']\n",
    "    nuevos = ['LoR', 'LDA', 'GNB', 'MLP', 'SVC', 'DT', 'k-NN', 'RF', 'ET', 'GBM', 'AB', 'VC']\n",
    "    num_models = len(nuevos)\n",
    "    dataframe_plot = dataframe_plot[['Modelo', 'Configuracion', 'Accuracy', 'errorMetrico', 'values', 'error']]\n",
    "    for i in range(num_models):\n",
    "        dataframe_plot['Modelo'] = dataframe_plot['Modelo'].str.replace(previos[i], nuevos[i])\n",
    "        #df['Modelo'] = df['Modelo'].str.replace('LinearDiscriminantAnalysis','LDA')\n",
    "    sorterIndex = dict(zip(nuevos,range(num_models)))\n",
    "    #test\n",
    "    dataframe_plot['Model_Rank'] = dataframe_plot['Modelo'].map(sorterIndex)\n",
    "    dataframe_plot = dataframe_plot.sort_values(['Model_Rank'],ascending=True).reset_index(drop=True)[dataframe_plot.columns[:-1]]\n",
    "    if column_plot == 'values':\n",
    "        y_label = 'Score'\n",
    "        x_label = 'Model'\n",
    "    else:\n",
    "        y_label = 'Error (m)'\n",
    "        x_label = 'Model Evaluated'\n",
    "    lista_plot = []\n",
    "    for i in range(num_models):\n",
    "        num_splits = len(list(dataframe_plot[column_plot])[i])\n",
    "        for j in range(num_splits):\n",
    "            d = {x_label:nuevos[i], y_label:dataframe_plot[column_plot][i][j]}\n",
    "            lista_plot.append(d)\n",
    "    #pd.DataFrame(lista_plot)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    if column_plot == 'values':\n",
    "        ax_plot = sns.boxplot(data=pd.DataFrame(lista_plot), x=x_label, y=y_label, linewidth = 1.0)\n",
    "    else:\n",
    "        #ax_plot = sns.barplot(data=pd.DataFrame(lista_plot), x=x_label, y=y_label, linewidth = 1.0)\n",
    "        if box_bool==True:\n",
    "            ax_plot = sns.boxplot(data=pd.DataFrame(lista_plot), x=x_label, y=y_label, linewidth = 1.0)\n",
    "        else:\n",
    "            ax_plot = sns.barplot(data=pd.DataFrame(lista_plot), x=x_label, y=y_label, linewidth = 1.0)\n",
    "    plt.format='eps'\n",
    "    if column_plot == 'values':\n",
    "        medians = np.round(list(dataframe_plot['Accuracy']),3)\n",
    "        tope = 0.98\n",
    "    else:\n",
    "        medians = np.round(list(dataframe_plot['errorMetrico']),3)\n",
    "        if box_bool==True:\n",
    "            tope = 6.8\n",
    "        else:\n",
    "            tope = 2.8\n",
    "    median_labels = [str(s) for s in medians]\n",
    "    pos = range(num_models)\n",
    "    for tick,label in zip(pos,ax_plot.get_xticklabels()):\n",
    "        ax_plot.text(pos[tick], tope, median_labels[tick], \n",
    "                horizontalalignment='center', color='black') #, weight='semibold'\n",
    "    axes = plt.gca()\n",
    "    if column_plot == 'values':\n",
    "        axes.set_ylim([0.3,1.0])\n",
    "    else:\n",
    "        axes.set_ylim([-0.1, tope+0.2])\n",
    "    plt.savefig(filename + \".eps\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy EDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAHeCAYAAABT+34JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGOf/A7UEc/MUnndBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f880b924c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'values', 'accuracy_edas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error EDAS Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzEAAAHeCAYAAACrG4X+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nc0LjhwmcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f880337ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'error', 'error_edas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAHeCAYAAABT+34JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wPYovMWqJAMUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f88034da7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'error', 'error_edas', box_bool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>error</th>\n",
       "      <th>errorMetrico</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>0.914520</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.12132034356, 0.0, ...</td>\n",
       "      <td>0.185316</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>[0.915841584158, 0.898514851485, 0.91584158415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12266</th>\n",
       "      <td>0.904359</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[0.0, 0.0, 3.35410196625, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.199940</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>[0.915841584158, 0.905940594059, 0.89108910891...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10641</th>\n",
       "      <td>0.882418</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.286972</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>[0.909756097561, 0.872860635697, 0.88264058679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9771</th>\n",
       "      <td>0.881202</td>\n",
       "      <td>[6, 1, 1, 3, 1]</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...</td>\n",
       "      <td>0.258637</td>\n",
       "      <td>0.012816</td>\n",
       "      <td>[0.885365853659, 0.892420537897, 0.88753056234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7702</th>\n",
       "      <td>0.867943</td>\n",
       "      <td>[6, 6, 3, 3, 2]</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.399393</td>\n",
       "      <td>0.013143</td>\n",
       "      <td>[0.878934624697, 0.891041162228, 0.84261501210...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>0.866293</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...</td>\n",
       "      <td>0.280348</td>\n",
       "      <td>0.011922</td>\n",
       "      <td>[0.863414634146, 0.867970660147, 0.86797066014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>0.845358</td>\n",
       "      <td>[6, 1, 3, 4, 5]</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>[0.0, 0.0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.341620</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>[0.831683168317, 0.861386138614, 0.83168316831...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>0.832070</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...</td>\n",
       "      <td>0.357042</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>[0.831707317073, 0.821515892421, 0.81907090464...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>0.827804</td>\n",
       "      <td>[5, 1, 3, 6, 1]</td>\n",
       "      <td>SVC</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.12132034356, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.404551</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>[0.79702970297, 0.836633663366, 0.821782178218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.752972</td>\n",
       "      <td>[6, 1, 3, 1, 5]</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[0.0, 2.12132034356, 3.0, 0.0, 0.0, 1.5, 0.0, ...</td>\n",
       "      <td>0.511191</td>\n",
       "      <td>0.014543</td>\n",
       "      <td>[0.737623762376, 0.789603960396, 0.74752475247...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>0.694200</td>\n",
       "      <td>[4, 5, 2, 3, 1]</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[0.0, 1.5, 0.0, 0.0, 0.0, 1.5, 1.5, 0.0, 0.0, ...</td>\n",
       "      <td>0.780340</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>[0.702764976959, 0.716589861751, 0.69585253456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4300</th>\n",
       "      <td>0.646278</td>\n",
       "      <td>[6, 1, 2, 1, 5]</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[0.0, 3.35410196625, 1.5, 0.0, 0.0, 1.5, 0.0, ...</td>\n",
       "      <td>0.778324</td>\n",
       "      <td>0.020987</td>\n",
       "      <td>[0.60880195599, 0.643031784841, 0.660146699267...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy    Configuracion                      Modelo  \\\n",
       "11561  0.914520  [6, 1, 3, 3, 5]  GradientBoostingClassifier   \n",
       "12266  0.904359  [6, 1, 3, 3, 5]            VotingClassifier   \n",
       "10641  0.882418  [6, 1, 3, 3, 1]      RandomForestClassifier   \n",
       "9771   0.881202  [6, 1, 1, 3, 1]          AdaBoostClassifier   \n",
       "7702   0.867943  [6, 6, 3, 3, 2]        ExtraTreesClassifier   \n",
       "4986   0.866293  [6, 1, 3, 3, 1]        KNeighborsClassifier   \n",
       "2847   0.845358  [6, 1, 3, 4, 5]                  GaussianNB   \n",
       "5890   0.832070  [6, 1, 3, 3, 1]      DecisionTreeClassifier   \n",
       "1255   0.827804  [5, 1, 3, 6, 1]                         SVC   \n",
       "233    0.752972  [6, 1, 3, 1, 5]  LinearDiscriminantAnalysis   \n",
       "7391   0.694200  [4, 5, 2, 3, 1]          LogisticRegression   \n",
       "4300   0.646278  [6, 1, 2, 1, 5]               MLPClassifier   \n",
       "\n",
       "                                                   error  errorMetrico  \\\n",
       "11561  [0.0, 0.0, 0.0, 0.0, 0.0, 2.12132034356, 0.0, ...      0.185316   \n",
       "12266  [0.0, 0.0, 3.35410196625, 0.0, 0.0, 0.0, 0.0, ...      0.199940   \n",
       "10641  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.286972   \n",
       "9771   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...      0.258637   \n",
       "7702   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.399393   \n",
       "4986   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...      0.280348   \n",
       "2847   [0.0, 0.0, 1.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.341620   \n",
       "5890   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...      0.357042   \n",
       "1255   [0.0, 0.0, 0.0, 2.12132034356, 0.0, 0.0, 0.0, ...      0.404551   \n",
       "233    [0.0, 2.12132034356, 3.0, 0.0, 0.0, 1.5, 0.0, ...      0.511191   \n",
       "7391   [0.0, 1.5, 0.0, 0.0, 0.0, 1.5, 1.5, 0.0, 0.0, ...      0.780340   \n",
       "4300   [0.0, 3.35410196625, 1.5, 0.0, 0.0, 1.5, 0.0, ...      0.778324   \n",
       "\n",
       "       stdAccuracy                                             values  \n",
       "11561     0.008447  [0.915841584158, 0.898514851485, 0.91584158415...  \n",
       "12266     0.010358  [0.915841584158, 0.905940594059, 0.89108910891...  \n",
       "10641     0.009747  [0.909756097561, 0.872860635697, 0.88264058679...  \n",
       "9771      0.012816  [0.885365853659, 0.892420537897, 0.88753056234...  \n",
       "7702      0.013143  [0.878934624697, 0.891041162228, 0.84261501210...  \n",
       "4986      0.011922  [0.863414634146, 0.867970660147, 0.86797066014...  \n",
       "2847      0.018558  [0.831683168317, 0.861386138614, 0.83168316831...  \n",
       "5890      0.010714  [0.831707317073, 0.821515892421, 0.81907090464...  \n",
       "1255      0.019018  [0.79702970297, 0.836633663366, 0.821782178218...  \n",
       "233       0.014543  [0.737623762376, 0.789603960396, 0.74752475247...  \n",
       "7391      0.017259  [0.702764976959, 0.716589861751, 0.69585253456...  \n",
       "4300      0.020987  [0.60880195599, 0.643031784841, 0.660146699267...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topDf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
