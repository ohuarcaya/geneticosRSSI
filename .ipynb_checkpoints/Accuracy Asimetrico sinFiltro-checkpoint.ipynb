{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Librería Genética\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Subfunciones de estimadores\n",
    "from sklearn.base import clone\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][30]\n",
    "from sklearn.base import is_classifier\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][535]\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_validation.py][346]\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][386]\n",
    "from sklearn.model_selection._search import check_cv\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_split.py][1866]\n",
    "from sklearn.model_selection._search import _check_param_grid\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][343]\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/scorer.py][250]\n",
    "from sklearn.utils.validation import _num_samples\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][105]\n",
    "from sklearn.utils.validation import indexable\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][208]\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "\n",
    "# Selección para estimadores\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metricas para estimadores\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Estimadores\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Ensembles algorithms\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (14, 8)\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# find distance error al 0.2%\n",
    "def distance_error(estimator, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 7)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    # coord pred\n",
    "    x1 = np.int32((y_pred + 2) % 3)\n",
    "    y1 = np.int32((y_pred - 1) / 3)\n",
    "    # coord real\n",
    "    x2 = np.int32((y_test + 2) % 3)\n",
    "    y2 = np.int32((y_test - 1) / 3)\n",
    "    # pasar variacion a distancias metros\n",
    "    vx = np.abs(x1 - x2)*1.5\n",
    "    vy = np.abs(y1 - y2)*1.5\n",
    "    #vx = vx*0.5 + (vx-1)*(vx>0)\n",
    "    #vy = vy*0.5 + (vy-1)*(vy>0)\n",
    "    # pitagoras\n",
    "    err_distance = np.sqrt(vx*vx + vy*vy)\n",
    "    return err_distance\n",
    "\n",
    "def _createDataset(frecuencias, values, seed = 7):\n",
    "    # crear dataset\n",
    "    names_ = frecuencias[0].columns.values\n",
    "    # reestructuracion\n",
    "    salida_final = pd.DataFrame(columns=names_)\n",
    "    for sec in range(1,16):\n",
    "        dataset = pd.DataFrame(columns=names_)\n",
    "        corte = min([frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values])\n",
    "        tx = 0\n",
    "        dataset[names_[tx]] = dataset[names_[tx]].append(frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]])\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        for tx in range(1,5):\n",
    "            dataset[names_[tx]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]].reset_index()\n",
    "        dataset[names_[tx+1]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx+1]].reset_index()\n",
    "        # join parts\n",
    "        salida_final = salida_final.append(dataset)\n",
    "    # shuffle dataset\n",
    "    salida_final = shuffle(salida_final, random_state=seed).reset_index(drop=True)\n",
    "    salida_final = salida_final.apply(pd.to_numeric)\n",
    "    # dataframe to X,y \n",
    "    X = salida_final[names_[:-1]]\n",
    "    y = salida_final[names_[-1]]\n",
    "    return X,y\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    # LDA : Warning(Variables are collinear)\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    #\"\"\"\n",
    "    models.append(('SVC', SVC(random_state=rs)))\n",
    "    models.append(('GaussianNB', GaussianNB()))\n",
    "    models.append(('MLPClassifier', MLPClassifier()))\n",
    "    #\"\"\"\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    #\"\"\"\n",
    "    models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=rs)))\n",
    "    models.append(('LogisticRegression', LogisticRegression()))\n",
    "    # Bagging and Boosting\n",
    "    # models.append(('ExtraTreesClassifier', ExtraTreesClassifier(n_estimators=150)))\n",
    "    models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state=rs)))\n",
    "    models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier(random_state=rs),\n",
    "                                                            random_state=rs)))\n",
    "    # models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier())))\n",
    "    models.append(('RandomForestClassifier', RandomForestClassifier(random_state=rs)))\n",
    "    models.append(('GradientBoostingClassifier',\n",
    "                   GradientBoostingClassifier(random_state=rs)))\n",
    "    # models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "    # Voting\n",
    "    estimators = []\n",
    "    estimators.append((\"Voting_GradientBoostingClassifier\", GradientBoostingClassifier(random_state=rs)))\n",
    "    estimators.append((\"Voting_ExtraTreesClassifier\", ExtraTreesClassifier(random_state=rs)))\n",
    "    voting = VotingClassifier(estimators)\n",
    "    models.append(('VotingClassifier', voting))\n",
    "    #\"\"\"\n",
    "    return models\n",
    "\n",
    "\n",
    "# The problem to optimize\n",
    "def evaluatex2( frecuencias, individual, estimator, score_cache={}, error_cache={}, \n",
    "             n_splits = 10, shuffle = False, scorer = \"accuracy\"):\n",
    "    X, y = _createDataset(frecuencias, individual)\n",
    "    metric_err = distance_error(estimator, X, y)\n",
    "    score = 0\n",
    "    paramkey = str(np.int32(individual)+1)\n",
    "    if paramkey in score_cache:\n",
    "        score = score_cache[paramkey]\n",
    "        error = error_cache[paramkey]\n",
    "    else:\n",
    "        kfold = KFold(n_splits=n_splits, shuffle=shuffle)\n",
    "        cv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scorer)\n",
    "        score = cv_results.mean()\n",
    "        error = cv_results.std()\n",
    "        #score_cache[paramkey] = score\n",
    "        #error_cache[paramkey] = error\n",
    "    return score, error, metric_err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _initIndividual(individuo, maxints):\n",
    "\t\"\"\"[Iniciar Individuo]\n",
    "\tArguments:\n",
    "\t\tpcls {[creator.Individual]} -- [Iniciar individuo con indices aleatorios]\n",
    "\t\tmaxints {[params_size]} -- [lista de máximos índices]\n",
    "\tReturns:\n",
    "\t\t[creator.Individual] -- [Creación de individuo]\n",
    "\t\"\"\"\n",
    "\treturn individuo(rnd.randint(0, maxint) for maxint in maxints)\n",
    "\n",
    "def _mutIndividual(individual, maxints, prob_mutacion):\n",
    "\t\"\"\"[Mutación Individuo]\n",
    "\tArguments:\n",
    "\t\tindividual {[creator.Individual]} -- [Individuo de población]\n",
    "\t\tmaxints {[lista]} -- [lista de máximos índices]\n",
    "\t\tprob_mutacion {[float]} -- [probabilidad de mutación del gen]\n",
    "\tReturns:\n",
    "\t\t[creator.Individual] -- [Individuo mutado]\n",
    "\t\"\"\"\n",
    "\tfor i in range(len(maxints)):\n",
    "\t\tif rnd.random() < prob_mutacion:\n",
    "\t\t\tindividual[i] = rnd.randint(0, maxints[i])\n",
    "\treturn individual,\n",
    "\n",
    "def _cxIndividual(ind1, ind2, prob_cruce):\n",
    "\t\"\"\"[Cruce de Individuos]\n",
    "\tArguments:\n",
    "\t\tind1 {[creator.Individual]} -- [Individuo 1]\n",
    "\t\tind2 {[creator.Individual]} -- [Individuo 2]\n",
    "\t\tindpb {[float]} -- [probabilidad de emparejar]\n",
    "\t\tgene_type {[list]} -- [tipos de dato de los parámetros, CATEGORICO o NUMERICO]\n",
    "\tReturns:\n",
    "\t\t[creator.Individual,creator.Individual] -- [nuevos Individuos]\n",
    "\t\"\"\"\n",
    "\tCATEGORICO = 1  # int o str\n",
    "\tNUMERICO = 2  # float\n",
    "\tfor i in range(len(ind1)):\n",
    "\t\tif rnd.random() < prob_cruce:\n",
    "\t\t\tsorted_ind = sorted([ind1[i], ind2[i]])\n",
    "\t\t\tind1[i] = rnd.randint(sorted_ind[0], sorted_ind[1])\n",
    "\t\t\tind2[i] = rnd.randint(sorted_ind[0], sorted_ind[1])\n",
    "\treturn ind1, ind2\n",
    "\n",
    "def _individual_to_params(frecuencias, values):\n",
    "    # crear dataset\n",
    "    names_ = frecuencias[0].columns.values\n",
    "    seed = 7\n",
    "    # reestructuracion\n",
    "    salida_final = pd.DataFrame(columns=names_)\n",
    "    for sec in range(1,16):\n",
    "        dataset = pd.DataFrame(columns=names_)\n",
    "        corte = min([frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values])\n",
    "        #l = [frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values]\n",
    "        #corte = max(l)\n",
    "        #tx=l.index(max(l))\n",
    "        tx = 0\n",
    "        dataset[names_[tx]] = dataset[names_[tx]].append(frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]])\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        for tx in range(1,5):\n",
    "            dataset[names_[tx]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]].reset_index(drop=True)\n",
    "        dataset[names_[tx+1]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx+1]].reset_index(drop=True)\n",
    "        # join parts\n",
    "        salida_final = salida_final.append(dataset)\n",
    "    # shuffle dataset\n",
    "    salida_final = shuffle(salida_final, random_state=seed).reset_index(drop=True)\n",
    "    salida_final = salida_final.apply(pd.to_numeric)\n",
    "    # dataframe to X,y \n",
    "    X = salida_final[names_[:-1]]\n",
    "    y = salida_final[names_[-1]]\n",
    "    return X,y\n",
    "\n",
    "def _evalFunction(individual, frecuencias, scorer, num_folds, score_cache, desv_cache, error_cache, resultados_cache):\n",
    "\t\"\"\"[Evaluación del modelo]\n",
    "\tArguments:\n",
    "\t\tindividual {[creator.Individual]} -- [Individuo]\n",
    "\t\tfrecuencias {[list]} -- [lista de dataframes]\n",
    "\t\tX {[array]} -- [Input]\n",
    "\t\ty {[array]} -- [Output]\n",
    "\t\tscorer {[string]} -- [Parámetro de evaluación, precisión]\n",
    "\t\tcv {[int | cross-validation]} -- [Especificación de los folds]\n",
    "\t\tuniform {[boolean]} -- [True hace que la data se distribuya uniformemente en los folds]\n",
    "\t\tfit_params {[dict | None]} -- [parámetros para estimator.fit]\n",
    "\tKeyword Arguments:\n",
    "\t\tverbose {integer} -- [Mensajes de descripción] (default: {0})\n",
    "\t\terror_score {numerico} -- [valor asignado si ocurre un error en fitting] (default: {'raise'})\n",
    "\t\tscore_cache {dict} -- [description] (default: {{}})\n",
    "\t\"\"\"\n",
    "\tX, y = _individual_to_params(frecuencias, individual)\n",
    "\tscore = 0\n",
    "\tn_test = 0\n",
    "\tname = str(individual.est).split('(')[0]\n",
    "\tparamkey = str(np.array(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=10, shuffle=False)\n",
    "\t\t#cv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scoring)\n",
    "\t\tcv_results = cross_val_score(individual.est, X, y, cv=kfold, scoring=scorer)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\tdesv_cache[paramkey] = cv_results.std()\n",
    "\t\tdis_err = distance_error(individual.est, X, y)\n",
    "\t\terror_cache[paramkey] = np.mean(dis_err)\n",
    "\t\tresults = {'Modelo': name, 'Configuracion':np.int32(individual)+1, 'values': cv_results, 'Accuracy': score, 'stdAccuracy': desv_cache[paramkey], 'errorMetrico': error_cache[paramkey], 'error':dis_err}  \n",
    "\t\tresultados_cache.append(results)\n",
    "\treturn (score,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EvolutiveSearchCV:\n",
    "\tdef __init__(self, estimator, scoring=None, num_folds=4,\n",
    "\t\t\t\trefit=True, verbose=False, population_size=50,\n",
    "\t\t\t\tgene_mutation_prob=0.2, gene_crossover_prob=0.5,\n",
    "\t\t\t\ttournament_size=3, generations_number=10, gene_type=None,\n",
    "\t\t\t\tn_jobs=1, uniform=True, error_score='raise',\n",
    "\t\t\t\tfit_params={}):\n",
    "\t\t# Parámetros iniciales\n",
    "\t\tself.estimator = estimator\n",
    "\t\t#self.params = params\n",
    "\t\tself.scoring = scoring\n",
    "\t\tself.num_folds = num_folds\n",
    "\t\tself.refit = refit\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.population_size = population_size\n",
    "\t\tself.gene_mutation_prob = gene_mutation_prob\n",
    "\t\tself.gene_crossover_prob = gene_crossover_prob\n",
    "\t\tself.tournament_size = tournament_size\n",
    "\t\tself.generations_number = generations_number\n",
    "\t\tself.gene_type = gene_type\n",
    "\t\tself.n_jobs = n_jobs\n",
    "\t\tself.uniform = uniform\n",
    "\t\tself.error_score = error_score\n",
    "\t\tself.fit_params = fit_params\n",
    "\t\t# Parámetros adicionales\n",
    "\t\tself._individual_evals = {}\n",
    "\t\tself.all_history_ = None\n",
    "\t\tself.all_logbooks_ = None\n",
    "\t\tself._cv_results = None\n",
    "\t\tself.best_score_ = None\n",
    "\t\tself.best_params_ = None\n",
    "\t\tself.scorer_ = None\n",
    "\t\t#self.score_cache = {}\n",
    "\t\tself.__manager = Manager()\n",
    "\t\tself.score_cache = self.__manager.dict()\n",
    "\t\tself.desv_cache = self.__manager.dict()\n",
    "\t\tself.error_cache = self.__manager.dict()\n",
    "\t\tself.resultados = self.__manager.list()\n",
    "\t\t#self.score_cache = dict()\n",
    "\t\t#self.desv_cache = dict()\n",
    "\t\t#self.error_cache = dict()\n",
    "\t\t# Fitness [base.Fitness], objetivo 1\n",
    "\t\tcreator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "\t\t# Individuo [list], parámetros:est, FinessMax\n",
    "\t\tcreator.create(\"Individual\", list, est=clone(self.estimator), fitness=creator.FitnessMax)\n",
    "\t#@property\n",
    "\tdef cv_results_(self):\n",
    "\t\tif self._cv_results is None:\n",
    "\t\t\tout = defaultdict(list)\n",
    "\t\t\tgen = self.all_history_\n",
    "\t\t\t# Get individuals and indexes, their list of scores,\n",
    "\t\t\t# and additionally the name_values for this set of parameters\n",
    "\t\t\tidxs, individuals, each_scores = zip(*[(idx, indiv, np.mean(indiv.fitness.values))\n",
    "\t\t\t\t\t\t\t\t\t\t\tfor idx, indiv in list(gen.genealogy_history.items())\n",
    "\t\t\t\t\t\t\t\t\t\t\tif indiv.fitness.valid and not np.all(np.isnan(indiv.fitness.values))])\n",
    "\t\t\t#name_values, _, _ = _get_param_types_maxint(self.params)\n",
    "\t\t\t# Add to output\n",
    "\t\t\t#out['param_index'] += [p] * len(idxs)\n",
    "\t\t\tout['index'] += idxs\n",
    "\t\t\t#out['params'] += [_individual_to_params(indiv, name_values) for indiv in individuals]\n",
    "\t\t\tout['params'] += [str(np.add(indiv,1)) for indiv in individuals]\n",
    "\t\t\tout['mean_test_score'] += [np.nanmean(scores) for scores in each_scores]\n",
    "\t\t\tout['std_test_score'] += [np.nanstd(scores) for scores in each_scores]\n",
    "\t\t\tout['min_test_score'] += [np.nanmin(scores) for scores in each_scores]\n",
    "\t\t\tout['max_test_score'] += [np.nanmax(scores) for scores in each_scores]\n",
    "\t\t\tout['nan_test_score?'] += [np.any(np.isnan(scores)) for scores in each_scores]\n",
    "\t\t\tself._cv_results = out\n",
    "\t\treturn self._cv_results\n",
    "\t@property\n",
    "\tdef best_index_(self):\n",
    "\t\treturn np.argmax(self.cv_results_['max_test_score'])\n",
    "\t# fit y refit general\n",
    "\tdef fit(self, frecuencias):\n",
    "\t\tself.best_estimator_ = None\n",
    "\t\tself.best_mem_score_ = float(\"-inf\")\n",
    "\t\tself.best_mem_params_ = None\n",
    "\t\t#_check_param_grid(self.params)\n",
    "\t\tself._fit(frecuencias)\n",
    "\t\t#if self.refit:\n",
    "\t\t#\tself.best_estimator_ = clone(self.estimator)\n",
    "\t\t#\t#self.best_estimator_.set_params(**self.best_mem_params_)\n",
    "\t\t#\tself.best_estimator_.fit(frecuencias)\n",
    "\t# fit individual\n",
    "\tdef _fit(self, frecuencias):\n",
    "\t\tself._cv_results = None  # Indicador de necesidad de actualización\n",
    "\t\tself.scorer_ = check_scoring(self.estimator, scoring=self.scoring)\n",
    "\t\t#n_samples = _num_samples(X)\n",
    "\t\t# verificar longitudes x,y \n",
    "\t\t#if _num_samples(y) != n_samples:\n",
    "\t\t#\traise ValueError('Target [y], data [X] dont agree')\n",
    "\t\t#cv = check_cv(self.cv, y=y, classifier=is_classifier(self.estimator))\n",
    "\t\ttoolbox = base.Toolbox()\n",
    "\t\t# name_values = lista de parametros, gene_type = [1:categorico; 2:numérico], maxints = size(parametros)\n",
    "\t\t#name_values, self.gene_type, maxints = _get_param_types_maxint(parameter_dict)\n",
    "\t\tmaxints = [5]*5\n",
    "\t\t#if self.verbose:\n",
    "\t\t#\tprint(\"Tipos: %s, rangos: %s\" % (self.gene_type, maxints))\n",
    "\t\t# registro de función Individuo\n",
    "\t\ttoolbox.register(\"individual\", _initIndividual, creator.Individual, maxints=maxints)\n",
    "\t\t# registro de función Población\n",
    "\t\ttoolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\t\t# Paralelísmo, create pool\n",
    "\t\tif not isinstance(self.n_jobs, int):\n",
    "\t\t\tself.n_jobs=1\n",
    "\t\tpool = Pool(self.n_jobs)\n",
    "\t\ttoolbox.register(\"map\", pool.map)\n",
    "\t\t# registro de función Evaluación\n",
    "\t\ttoolbox.register(\"evaluate\", _evalFunction,\n",
    "\t\t\t\t\t\tfrecuencias=frecuencias,\n",
    "\t\t\t\t\t\tscorer=self.scorer_, num_folds=10, \n",
    "\t\t\t\t\t\tscore_cache=self.score_cache,\n",
    "\t\t\t\t\t\tdesv_cache=self.desv_cache,\n",
    "\t\t\t\t\t\terror_cache=self.error_cache,\n",
    "\t\t\t\t\t\tresultados_cache=self.resultados)\n",
    "\t\t# registro de función Cruce\n",
    "\t\ttoolbox.register(\"mate\", _cxIndividual, prob_cruce=self.gene_crossover_prob)\n",
    "\t\t# registro de función Mutación\n",
    "\t\ttoolbox.register(\"mutate\", _mutIndividual, prob_mutacion=self.gene_mutation_prob, maxints=maxints)\n",
    "\t\t# registro de función Selección\n",
    "\t\ttoolbox.register(\"select\", tools.selTournament, tournsize=self.tournament_size)\n",
    "\t\t# Creación de Población\n",
    "\t\tpop = toolbox.population(n=self.population_size)\n",
    "\t\t# Mejor Individuo que ha existido\n",
    "\t\thof = tools.HallOfFame(1)\n",
    "\t\t# Stats\n",
    "\t\tstats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "\t\tstats.register(\"avg\", np.nanmean)\n",
    "\t\tstats.register(\"min\", np.nanmin)\n",
    "\t\tstats.register(\"max\", np.nanmax)\n",
    "\t\tstats.register(\"std\", np.nanstd)\n",
    "\t\t# Genealogía\n",
    "\t\thist = tools.History()\n",
    "\t\t# Decoración de operadores de variaznza\n",
    "\t\ttoolbox.decorate(\"mate\", hist.decorator)\n",
    "\t\ttoolbox.decorate(\"mutate\", hist.decorator)\n",
    "\t\thist.update(pop)\n",
    "\t\t# Posibles combinaciones\n",
    "\t\tif self.verbose:\n",
    "\t\t\tprint('--- Evolve in {0} possible combinations ---'.format(np.prod(np.array(maxints) + 1)))\n",
    "\t\tpop, logbook = algorithms.eaSimple(pop, toolbox, cxpb=self.gene_crossover_prob, \n",
    "\t\t\t\t\t\t\t\t\t\tmutpb=self.gene_mutation_prob,\n",
    "\t\t\t\t\t\t\t\t\t\tngen=self.generations_number, \n",
    "\t\t\t\t\t\t\t\t\t\tstats=stats,\n",
    "\t\t\t\t\t\t\t\t\t\thalloffame=hof, \n",
    "\t\t\t\t\t\t\t\t\t\tverbose=self.verbose)\n",
    "\t\t#pop, logbook = algorithms.eaGenerateUpdate(toolbox,\n",
    "\t\t#\t\t\t\t\t\t\t\tngen=self.generations_number, stats=stats,\n",
    "\t\t#\t\t\t\t\t\t\t\thalloffame=hof, verbose=self.verbose)\n",
    "\t\t# Save History\n",
    "\t\tself.all_history_ = hist\n",
    "\t\tself.all_logbooks_ = logbook\n",
    "\t\t# Mejor score y parametros\n",
    "\t\tcurrent_best_score_ = hof[0].fitness.values[0]\n",
    "\t\tcurrent_best_params_ = str(hof[0]) #_individual_to_params(hof[0], name_values)\n",
    "\t\t#if self.verbose:\n",
    "\t\t#\tprint(\"Best individual is: %s\\nwith fitness: %s\" % (\n",
    "\t\t#\t\tcurrent_best_params_, current_best_score_))\n",
    "\t\tif current_best_score_ > self.best_mem_score_:\n",
    "\t\t\tself.best_mem_score_ = current_best_score_\n",
    "\t\t\tself.best_mem_params_ = current_best_params_\n",
    "\t\t# fin paralelización, close pool\n",
    "\t\tpool.close()\n",
    "\t\tpool.join()\n",
    "\t\tself.best_score_ = current_best_score_\n",
    "\t\tself.best_params_ = current_best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "frecuencias = []\n",
    "names_ = ['Be01', 'Be02', 'Be03', 'Be04', 'Be05', 'Sector']\n",
    "\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x01'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x02'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x03'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x04'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x05'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x06'))#, names=names_))\n",
    "\"\"\"\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx1.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx2.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx3.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx4.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx5.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx6.csv', names=names_))\n",
    "\"\"\"\n",
    "num_jobs=cpu_count()\n",
    "estimadores = set_models()\n",
    "salida = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modeling... LinearDiscriminantAnalysis\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.602162\t0.430015\t0.714733\t0.0578487\n",
      "1  \t64    \t0.639021\t0.48552 \t0.733964\t0.0465497\n",
      "2  \t58    \t0.661476\t0.527302\t0.737233\t0.0413217\n",
      "3  \t51    \t0.688186\t0.585691\t0.760269\t0.0359697\n",
      "4  \t65    \t0.700641\t0.584127\t0.760269\t0.0379288\n",
      "5  \t56    \t0.723752\t0.606713\t0.760269\t0.0281947\n",
      "6  \t63    \t0.732182\t0.594408\t0.760269\t0.0318623\n",
      "7  \t54    \t0.738831\t0.601482\t0.760269\t0.0340588\n",
      "8  \t58    \t0.744755\t0.62659 \t0.771807\t0.0319388\n",
      "9  \t61    \t0.747261\t0.561662\t0.771807\t0.0337272\n",
      "10 \t63    \t0.74498 \t0.587835\t0.771807\t0.0366956\n",
      "\n",
      "Modeling... SVC\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd     \n",
      "0  \t100   \t0.708905\t0.616102\t0.811096\t0.043003\n",
      "1  \t56    \t0.742916\t0.645137\t0.811096\t0.0365082\n",
      "2  \t64    \t0.766034\t0.659494\t0.829563\t0.0346407\n",
      "3  \t61    \t0.787126\t0.648233\t0.829563\t0.0300895\n",
      "4  \t69    \t0.795334\t0.676101\t0.829563\t0.0307297\n",
      "5  \t57    \t0.800236\t0.636059\t0.829563\t0.0333599\n",
      "6  \t66    \t0.801788\t0.602835\t0.829563\t0.0380457\n",
      "7  \t64    \t0.81945 \t0.75599 \t0.829563\t0.0145643\n",
      "8  \t69    \t0.816703\t0.689584\t0.829563\t0.0266103\n",
      "9  \t64    \t0.817908\t0.676351\t0.829563\t0.0307306\n",
      "10 \t61    \t0.819887\t0.714876\t0.829563\t0.0256294\n",
      "\n",
      "Modeling... GaussianNB\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.732127\t0.579909\t0.829744\t0.0539211\n",
      "1  \t65    \t0.771658\t0.645682\t0.829744\t0.0390865\n",
      "2  \t64    \t0.793497\t0.699546\t0.847922\t0.0298782\n",
      "3  \t69    \t0.801755\t0.703166\t0.847922\t0.0329308\n",
      "4  \t67    \t0.811928\t0.666968\t0.860133\t0.032921 \n",
      "5  \t57    \t0.82345 \t0.715224\t0.860133\t0.0268373\n",
      "6  \t57    \t0.828561\t0.653968\t0.860133\t0.0354967\n",
      "7  \t73    \t0.837734\t0.694951\t0.860133\t0.0327489\n",
      "8  \t65    \t0.839187\t0.708351\t0.860133\t0.0364447\n",
      "9  \t72    \t0.847003\t0.725127\t0.860133\t0.0287708\n",
      "10 \t65    \t0.843954\t0.718597\t0.860133\t0.0303974\n",
      "\n",
      "Modeling... MLPClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.507232\t0.353325\t0.612018\t0.0601514\n",
      "1  \t68    \t0.555681\t0.41004 \t0.631536\t0.0464387\n",
      "2  \t60    \t0.57964 \t0.418374\t0.658012\t0.0416701\n",
      "3  \t69    \t0.590438\t0.43959 \t0.658012\t0.0402824\n",
      "4  \t62    \t0.607113\t0.446446\t0.66846 \t0.0420334\n",
      "5  \t69    \t0.622324\t0.515159\t0.672428\t0.0380336\n",
      "6  \t63    \t0.644414\t0.50266 \t0.677962\t0.0306748\n",
      "7  \t72    \t0.647145\t0.494637\t0.677962\t0.037099 \n",
      "8  \t71    \t0.648957\t0.474167\t0.691898\t0.0440343\n",
      "9  \t55    \t0.659013\t0.50839 \t0.691898\t0.0348311\n",
      "10 \t68    \t0.658509\t0.512863\t0.691898\t0.0429819\n",
      "\n",
      "Modeling... KNeighborsClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.763405\t0.610675\t0.845787\t0.0484868\n",
      "1  \t60    \t0.805233\t0.702745\t0.852685\t0.031484 \n",
      "2  \t65    \t0.820143\t0.688542\t0.852685\t0.031361 \n",
      "3  \t75    \t0.831008\t0.702641\t0.870416\t0.0267967\n",
      "4  \t64    \t0.837358\t0.764705\t0.875878\t0.0216292\n",
      "5  \t59    \t0.838136\t0.756843\t0.875878\t0.0271291\n",
      "6  \t61    \t0.84825 \t0.756258\t0.875878\t0.0216457\n",
      "7  \t68    \t0.851619\t0.702721\t0.875878\t0.0298971\n",
      "8  \t59    \t0.862355\t0.777267\t0.875878\t0.0213591\n",
      "9  \t73    \t0.866627\t0.777307\t0.875878\t0.020718 \n",
      "10 \t63    \t0.863985\t0.785958\t0.87778 \t0.0236586\n",
      "\n",
      "Modeling... DecisionTreeClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax    \tstd      \n",
      "0  \t100   \t0.711578\t0.603798\t0.83207\t0.0452008\n",
      "1  \t72    \t0.747418\t0.645909\t0.83207\t0.0387983\n",
      "2  \t67    \t0.779452\t0.677273\t0.83207\t0.0309842\n",
      "3  \t59    \t0.804685\t0.720548\t0.83427\t0.0222177\n",
      "4  \t65    \t0.813868\t0.666527\t0.852578\t0.0299696\n",
      "5  \t64    \t0.818855\t0.665524\t0.852578\t0.0293067\n",
      "6  \t70    \t0.824029\t0.712079\t0.852578\t0.0267934\n",
      "7  \t66    \t0.823549\t0.654707\t0.852578\t0.0357633\n",
      "8  \t68    \t0.830487\t0.670826\t0.852578\t0.0354772\n",
      "9  \t64    \t0.841561\t0.725716\t0.852578\t0.026143 \n",
      "10 \t59    \t0.841866\t0.655228\t0.859512\t0.0295059\n",
      "\n",
      "Modeling... LogisticRegression\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.544366\t0.391286\t0.648721\t0.0481618\n",
      "1  \t55    \t0.580565\t0.436155\t0.672937\t0.0423949\n",
      "2  \t76    \t0.609936\t0.50412 \t0.692137\t0.0383245\n",
      "3  \t76    \t0.631038\t0.51882 \t0.697879\t0.0397198\n",
      "4  \t74    \t0.65069 \t0.514502\t0.708543\t0.0398749\n",
      "5  \t59    \t0.665554\t0.52798 \t0.697879\t0.0364049\n",
      "6  \t63    \t0.676844\t0.548532\t0.698477\t0.0290376\n",
      "7  \t69    \t0.673949\t0.56747 \t0.708543\t0.0364116\n",
      "8  \t62    \t0.684791\t0.514984\t0.708543\t0.0305453\n",
      "9  \t57    \t0.685333\t0.571429\t0.708543\t0.0297661\n",
      "10 \t61    \t0.68597 \t0.541051\t0.708543\t0.0349878\n",
      "\n",
      "Modeling... ExtraTreesClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax    \tstd      \n",
      "0  \t100   \t0.791139\t0.679833\t0.86155\t0.0381711\n",
      "1  \t63    \t0.815363\t0.70771 \t0.877102\t0.0308238\n",
      "2  \t63    \t0.835048\t0.756424\t0.877102\t0.0251897\n",
      "3  \t63    \t0.847518\t0.750213\t0.881562\t0.0268502\n",
      "4  \t68    \t0.86264 \t0.762431\t0.892472\t0.0217332\n",
      "5  \t66    \t0.869255\t0.745033\t0.892472\t0.0200877\n",
      "6  \t58    \t0.869217\t0.763387\t0.892472\t0.0229302\n",
      "7  \t61    \t0.87569 \t0.788141\t0.892472\t0.0201312\n",
      "8  \t60    \t0.879249\t0.685637\t0.892472\t0.0316612\n",
      "9  \t61    \t0.88053 \t0.772026\t0.892472\t0.0247147\n",
      "10 \t67    \t0.882608\t0.781472\t0.892472\t0.0235871\n",
      "\n",
      "Modeling... AdaBoostClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin    \tmax    \tstd      \n",
      "0  \t100   \t0.784516\t0.69122\t0.87095\t0.0376762\n",
      "1  \t51    \t0.813497\t0.726265\t0.885086\t0.0310739\n",
      "2  \t67    \t0.832412\t0.71046 \t0.885086\t0.027193 \n",
      "3  \t70    \t0.84132 \t0.731785\t0.885086\t0.0268713\n",
      "4  \t64    \t0.853543\t0.753243\t0.886523\t0.0240223\n",
      "5  \t61    \t0.865538\t0.808459\t0.886523\t0.0187945\n",
      "6  \t58    \t0.871314\t0.782885\t0.893959\t0.0228756\n",
      "7  \t77    \t0.868323\t0.771436\t0.893959\t0.0304685\n",
      "8  \t65    \t0.87596 \t0.755593\t0.893959\t0.0246976\n",
      "9  \t65    \t0.876296\t0.816608\t0.893959\t0.018592 \n",
      "10 \t60    \t0.876957\t0.765515\t0.893959\t0.0228961\n",
      "\n",
      "Modeling... RandomForestClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin    \tmax     \tstd      \n",
      "0  \t100   \t0.790822\t0.69251\t0.872286\t0.0403577\n",
      "1  \t67    \t0.817327\t0.724954\t0.872286\t0.0303725\n",
      "2  \t72    \t0.835733\t0.706972\t0.882418\t0.0262081\n",
      "3  \t60    \t0.847924\t0.712291\t0.882418\t0.0284782\n",
      "4  \t71    \t0.854953\t0.785669\t0.884131\t0.0238836\n",
      "5  \t60    \t0.859014\t0.76277 \t0.882418\t0.0245561\n",
      "6  \t64    \t0.867115\t0.771695\t0.898412\t0.0222827\n",
      "7  \t67    \t0.872141\t0.798203\t0.898412\t0.0200072\n",
      "8  \t71    \t0.877283\t0.776591\t0.898412\t0.022788 \n",
      "9  \t61    \t0.882344\t0.793538\t0.898412\t0.024605 \n",
      "10 \t57    \t0.883986\t0.792389\t0.898412\t0.0253143\n",
      "\n",
      "Modeling... GradientBoostingClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.826473\t0.730747\t0.893399\t0.0321396\n",
      "1  \t66    \t0.849058\t0.765489\t0.893399\t0.0245679\n",
      "2  \t76    \t0.858498\t0.775922\t0.909314\t0.0234558\n",
      "3  \t70    \t0.869166\t0.796085\t0.91452 \t0.0208696\n",
      "4  \t75    \t0.874935\t0.782364\t0.91452 \t0.0259682\n",
      "5  \t65    \t0.88454 \t0.805281\t0.91452 \t0.0207687\n",
      "6  \t53    \t0.89425 \t0.834644\t0.91452 \t0.0188276\n",
      "7  \t66    \t0.900023\t0.821315\t0.91452 \t0.0195373\n",
      "8  \t75    \t0.905266\t0.834286\t0.91452 \t0.0191291\n",
      "9  \t69    \t0.908394\t0.858781\t0.91452 \t0.0141438\n",
      "10 \t69    \t0.905219\t0.835876\t0.91452 \t0.0203157\n",
      "\n",
      "Modeling... VotingClassifier\n",
      "--- Evolve in 7776 possible combinations ---\n",
      "gen\tnevals\tavg     \tmin     \tmax     \tstd      \n",
      "0  \t100   \t0.803813\t0.685021\t0.870318\t0.0329254\n",
      "1  \t60    \t0.829304\t0.758982\t0.889516\t0.0258821\n",
      "2  \t67    \t0.84795 \t0.784387\t0.886269\t0.0217369\n",
      "3  \t64    \t0.859019\t0.785132\t0.889516\t0.0224679\n",
      "4  \t60    \t0.867536\t0.79521 \t0.889516\t0.0216314\n",
      "5  \t69    \t0.868891\t0.793828\t0.889516\t0.0214381\n",
      "6  \t62    \t0.874057\t0.812818\t0.904359\t0.0190186\n",
      "7  \t64    \t0.873096\t0.782364\t0.904359\t0.0228611\n",
      "8  \t71    \t0.878045\t0.824322\t0.904359\t0.0188822\n",
      "9  \t66    \t0.880436\t0.791458\t0.904359\t0.0219142\n",
      "10 \t75    \t0.883991\t0.792559\t0.904359\t0.0249837\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    return models\n",
    "\"\"\"\n",
    "estimadores = set_models()\n",
    "\n",
    "reserva = {}\n",
    "lista_resultados = []\n",
    "for name, model in estimadores:\n",
    "    print(\"\\nModeling...\", name)\n",
    "    splits = 10\n",
    "    simetricas = [[i]*5 for i in range(6)]\n",
    "    #for individual in simetricas:\n",
    "    #acc, desv, err = evaluate(frecuencias, individual, model)\n",
    "    #salida[str(name)+\"-\"+str(individual)] = str(acc) + \"-\"+ str(desv) + \"-\" + str(err)\n",
    "    #print(name,\" \", individual, \"\\t\", acc, \"\\t\", desv, \"\\t\", err)\n",
    "    gs = EvolutiveSearchCV(estimator=model, scoring=\"accuracy\", num_folds=10, n_jobs=num_jobs,\n",
    "                        verbose=True, refit=True, \n",
    "                        population_size=100, \n",
    "                        gene_mutation_prob=0.3, \n",
    "                        gene_crossover_prob=0.5,\n",
    "                        tournament_size=4,\n",
    "                        generations_number=10)\n",
    "    gs.fit(frecuencias)\n",
    "    reserva[name]=(gs.score_cache, gs.desv_cache , gs.error_cache)\n",
    "    lista_resultados = lista_resultados + list(gs.resultados)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.141771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 5]</td>\n",
       "      <td>0.909314</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>0.183778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.904359</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.144397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 1, 5]</td>\n",
       "      <td>0.902372</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.217908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 1, 5]</td>\n",
       "      <td>0.902372</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.217908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 5]</td>\n",
       "      <td>0.900138</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.212657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 5]</td>\n",
       "      <td>0.899650</td>\n",
       "      <td>0.014597</td>\n",
       "      <td>0.152273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3933</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 4]</td>\n",
       "      <td>0.899267</td>\n",
       "      <td>0.012695</td>\n",
       "      <td>0.235990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 4, 5]</td>\n",
       "      <td>0.898893</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.197149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.898412</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 6, 5]</td>\n",
       "      <td>0.897986</td>\n",
       "      <td>0.019086</td>\n",
       "      <td>0.248957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4047</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 6, 1]</td>\n",
       "      <td>0.897887</td>\n",
       "      <td>0.012396</td>\n",
       "      <td>0.257207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4045</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 6, 1]</td>\n",
       "      <td>0.897887</td>\n",
       "      <td>0.012396</td>\n",
       "      <td>0.257207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.896850</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.152818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.896850</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.152818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 2, 5]</td>\n",
       "      <td>0.894691</td>\n",
       "      <td>0.013031</td>\n",
       "      <td>0.223159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 6, 3, 4]</td>\n",
       "      <td>0.894377</td>\n",
       "      <td>0.015300</td>\n",
       "      <td>0.290450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 5]</td>\n",
       "      <td>0.893959</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>0.220533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 6, 5]</td>\n",
       "      <td>0.893834</td>\n",
       "      <td>0.016349</td>\n",
       "      <td>0.241177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 4, 3, 4]</td>\n",
       "      <td>0.893399</td>\n",
       "      <td>0.015777</td>\n",
       "      <td>0.228211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 5]</td>\n",
       "      <td>0.892923</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>0.182199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3705</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 5]</td>\n",
       "      <td>0.892714</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>0.170651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.892472</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 4, 3, 5]</td>\n",
       "      <td>0.892442</td>\n",
       "      <td>0.013724</td>\n",
       "      <td>0.254979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 4, 6, 1]</td>\n",
       "      <td>0.891377</td>\n",
       "      <td>0.011051</td>\n",
       "      <td>0.272487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 1]</td>\n",
       "      <td>0.890732</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.227932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 3]</td>\n",
       "      <td>0.890491</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4480</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 3]</td>\n",
       "      <td>0.890491</td>\n",
       "      <td>0.017897</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 3]</td>\n",
       "      <td>0.890230</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.190046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 1]</td>\n",
       "      <td>0.889516</td>\n",
       "      <td>0.012902</td>\n",
       "      <td>0.238292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 6, 2, 5, 5]</td>\n",
       "      <td>0.447644</td>\n",
       "      <td>0.025194</td>\n",
       "      <td>1.299244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 4, 6, 4, 3]</td>\n",
       "      <td>0.446446</td>\n",
       "      <td>0.033009</td>\n",
       "      <td>0.996456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 2, 6, 5, 3]</td>\n",
       "      <td>0.445832</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>1.137444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[2, 6, 3, 5, 3]</td>\n",
       "      <td>0.443523</td>\n",
       "      <td>0.027814</td>\n",
       "      <td>1.140047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 6, 4, 2]</td>\n",
       "      <td>0.441837</td>\n",
       "      <td>0.029313</td>\n",
       "      <td>1.127433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 6, 5, 1]</td>\n",
       "      <td>0.439590</td>\n",
       "      <td>0.033924</td>\n",
       "      <td>1.177359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 6, 4, 2, 6]</td>\n",
       "      <td>0.439163</td>\n",
       "      <td>0.038609</td>\n",
       "      <td>1.140274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 1, 4, 4]</td>\n",
       "      <td>0.437737</td>\n",
       "      <td>0.018249</td>\n",
       "      <td>0.995017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 3, 2, 5, 2]</td>\n",
       "      <td>0.437348</td>\n",
       "      <td>0.017588</td>\n",
       "      <td>1.156431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 6, 3, 6, 3]</td>\n",
       "      <td>0.437342</td>\n",
       "      <td>0.039330</td>\n",
       "      <td>1.181365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[3, 3, 5, 6, 3]</td>\n",
       "      <td>0.436155</td>\n",
       "      <td>0.033584</td>\n",
       "      <td>1.194707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 5, 4, 5, 6]</td>\n",
       "      <td>0.435042</td>\n",
       "      <td>0.035063</td>\n",
       "      <td>1.124430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[3, 5, 6, 5, 3]</td>\n",
       "      <td>0.434204</td>\n",
       "      <td>0.033417</td>\n",
       "      <td>1.199912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 3, 1, 2, 3]</td>\n",
       "      <td>0.434131</td>\n",
       "      <td>0.027325</td>\n",
       "      <td>1.120872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 6, 5, 1, 3]</td>\n",
       "      <td>0.432383</td>\n",
       "      <td>0.033821</td>\n",
       "      <td>1.304822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[2, 3, 4, 5, 3]</td>\n",
       "      <td>0.430015</td>\n",
       "      <td>0.023552</td>\n",
       "      <td>1.211494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 2, 2, 6]</td>\n",
       "      <td>0.429851</td>\n",
       "      <td>0.015983</td>\n",
       "      <td>1.107772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 3, 2, 5]</td>\n",
       "      <td>0.427097</td>\n",
       "      <td>0.016752</td>\n",
       "      <td>1.177163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 4, 2, 3]</td>\n",
       "      <td>0.420898</td>\n",
       "      <td>0.024249</td>\n",
       "      <td>1.148747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 5, 5, 2, 3]</td>\n",
       "      <td>0.418374</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>1.158825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 4, 2, 2]</td>\n",
       "      <td>0.416960</td>\n",
       "      <td>0.020780</td>\n",
       "      <td>1.124528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 1, 5, 1]</td>\n",
       "      <td>0.415955</td>\n",
       "      <td>0.030737</td>\n",
       "      <td>1.079728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[3, 3, 5, 4, 3]</td>\n",
       "      <td>0.415682</td>\n",
       "      <td>0.013539</td>\n",
       "      <td>1.251097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 2, 1, 2]</td>\n",
       "      <td>0.410040</td>\n",
       "      <td>0.046326</td>\n",
       "      <td>0.883505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 5, 5, 5, 4]</td>\n",
       "      <td>0.407051</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>0.944669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[5, 2, 5, 5, 3]</td>\n",
       "      <td>0.391286</td>\n",
       "      <td>0.016082</td>\n",
       "      <td>1.326424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 2, 3, 1]</td>\n",
       "      <td>0.381745</td>\n",
       "      <td>0.040136</td>\n",
       "      <td>0.917573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 2, 2, 1, 3]</td>\n",
       "      <td>0.374687</td>\n",
       "      <td>0.066761</td>\n",
       "      <td>0.917573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 1, 1, 2]</td>\n",
       "      <td>0.372127</td>\n",
       "      <td>0.041856</td>\n",
       "      <td>1.140153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 6, 5, 3]</td>\n",
       "      <td>0.353325</td>\n",
       "      <td>0.015585</td>\n",
       "      <td>1.338952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4570 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "3987  GradientBoostingClassifier  [6, 1, 3, 3, 5]  0.914520     0.008447   \n",
       "3985  GradientBoostingClassifier  [6, 1, 3, 6, 5]  0.909314     0.015718   \n",
       "4478            VotingClassifier  [6, 1, 3, 3, 5]  0.904359     0.010358   \n",
       "4110  GradientBoostingClassifier  [6, 1, 3, 1, 5]  0.902372     0.011416   \n",
       "4108  GradientBoostingClassifier  [6, 1, 3, 1, 5]  0.902372     0.011416   \n",
       "4130  GradientBoostingClassifier  [6, 1, 2, 3, 5]  0.900138     0.016621   \n",
       "4133  GradientBoostingClassifier  [6, 1, 1, 3, 5]  0.899650     0.014597   \n",
       "3933  GradientBoostingClassifier  [6, 1, 2, 3, 4]  0.899267     0.012695   \n",
       "3991  GradientBoostingClassifier  [6, 1, 3, 4, 5]  0.898893     0.016274   \n",
       "3695      RandomForestClassifier  [6, 1, 3, 3, 5]  0.898412     0.007043   \n",
       "4103  GradientBoostingClassifier  [6, 1, 2, 6, 5]  0.897986     0.019086   \n",
       "4047  GradientBoostingClassifier  [6, 1, 2, 6, 1]  0.897887     0.012396   \n",
       "4045  GradientBoostingClassifier  [6, 1, 2, 6, 1]  0.897887     0.012396   \n",
       "4152  GradientBoostingClassifier  [6, 1, 3, 3, 3]  0.896850     0.009726   \n",
       "4148  GradientBoostingClassifier  [6, 1, 3, 3, 3]  0.896850     0.009726   \n",
       "4151  GradientBoostingClassifier  [6, 1, 3, 2, 5]  0.894691     0.013031   \n",
       "3928  GradientBoostingClassifier  [6, 1, 6, 3, 4]  0.894377     0.015300   \n",
       "3278          AdaBoostClassifier  [6, 1, 3, 6, 5]  0.893959     0.015106   \n",
       "4113  GradientBoostingClassifier  [6, 1, 1, 6, 5]  0.893834     0.016349   \n",
       "3778  GradientBoostingClassifier  [6, 1, 4, 3, 4]  0.893399     0.015777   \n",
       "4098  GradientBoostingClassifier  [6, 3, 3, 3, 5]  0.892923     0.013625   \n",
       "3705      RandomForestClassifier  [6, 1, 3, 6, 5]  0.892714     0.013661   \n",
       "2879        ExtraTreesClassifier  [6, 1, 3, 3, 5]  0.892472     0.013311   \n",
       "3951  GradientBoostingClassifier  [6, 1, 4, 3, 5]  0.892442     0.013724   \n",
       "4107  GradientBoostingClassifier  [6, 1, 4, 6, 1]  0.891377     0.011051   \n",
       "4114  GradientBoostingClassifier  [6, 1, 3, 6, 1]  0.890732     0.018414   \n",
       "4482            VotingClassifier  [6, 1, 1, 3, 3]  0.890491     0.017897   \n",
       "4480            VotingClassifier  [6, 1, 1, 3, 3]  0.890491     0.017897   \n",
       "4056  GradientBoostingClassifier  [6, 3, 3, 3, 3]  0.890230     0.010172   \n",
       "4283            VotingClassifier  [6, 1, 2, 3, 1]  0.889516     0.012902   \n",
       "...                          ...              ...       ...          ...   \n",
       "1118               MLPClassifier  [1, 6, 2, 5, 5]  0.447644     0.025194   \n",
       "1361               MLPClassifier  [2, 4, 6, 4, 3]  0.446446     0.033009   \n",
       "1158               MLPClassifier  [4, 2, 6, 5, 3]  0.445832     0.031587   \n",
       "2322          LogisticRegression  [2, 6, 3, 5, 3]  0.443523     0.027814   \n",
       "1134               MLPClassifier  [3, 3, 6, 4, 2]  0.441837     0.029313   \n",
       "1307               MLPClassifier  [5, 2, 6, 5, 1]  0.439590     0.033924   \n",
       "1212               MLPClassifier  [3, 6, 4, 2, 6]  0.439163     0.038609   \n",
       "1202               MLPClassifier  [3, 3, 1, 4, 4]  0.437737     0.018249   \n",
       "1186               MLPClassifier  [2, 3, 2, 5, 2]  0.437348     0.017588   \n",
       "1126               MLPClassifier  [2, 6, 3, 6, 3]  0.437342     0.039330   \n",
       "2359          LogisticRegression  [3, 3, 5, 6, 3]  0.436155     0.033584   \n",
       "1119               MLPClassifier  [3, 5, 4, 5, 6]  0.435042     0.035063   \n",
       "2315          LogisticRegression  [3, 5, 6, 5, 3]  0.434204     0.033417   \n",
       "1147               MLPClassifier  [4, 3, 1, 2, 3]  0.434131     0.027325   \n",
       "1113               MLPClassifier  [3, 6, 5, 1, 3]  0.432383     0.033821   \n",
       "96    LinearDiscriminantAnalysis  [2, 3, 4, 5, 3]  0.430015     0.023552   \n",
       "1216               MLPClassifier  [1, 2, 2, 2, 6]  0.429851     0.015983   \n",
       "1176               MLPClassifier  [1, 3, 3, 2, 5]  0.427097     0.016752   \n",
       "1185               MLPClassifier  [5, 2, 4, 2, 3]  0.420898     0.024249   \n",
       "1287               MLPClassifier  [5, 5, 5, 2, 3]  0.418374     0.021472   \n",
       "1199               MLPClassifier  [3, 3, 4, 2, 2]  0.416960     0.020780   \n",
       "1160               MLPClassifier  [5, 2, 1, 5, 1]  0.415955     0.030737   \n",
       "2278          LogisticRegression  [3, 3, 5, 4, 3]  0.415682     0.013539   \n",
       "1208               MLPClassifier  [3, 2, 2, 1, 2]  0.410040     0.046326   \n",
       "1110               MLPClassifier  [1, 5, 5, 5, 4]  0.407051     0.028062   \n",
       "2298          LogisticRegression  [5, 2, 5, 5, 3]  0.391286     0.016082   \n",
       "1149               MLPClassifier  [3, 3, 2, 3, 1]  0.381745     0.040136   \n",
       "1141               MLPClassifier  [2, 2, 2, 1, 3]  0.374687     0.066761   \n",
       "1117               MLPClassifier  [1, 3, 1, 1, 2]  0.372127     0.041856   \n",
       "1183               MLPClassifier  [1, 3, 6, 5, 3]  0.353325     0.015585   \n",
       "\n",
       "      errorMetrico  \n",
       "3987      0.141771  \n",
       "3985      0.183778  \n",
       "4478      0.144397  \n",
       "4110      0.217908  \n",
       "4108      0.217908  \n",
       "4130      0.212657  \n",
       "4133      0.152273  \n",
       "3933      0.235990  \n",
       "3991      0.197149  \n",
       "3695      0.165400  \n",
       "4103      0.248957  \n",
       "4047      0.257207  \n",
       "4045      0.257207  \n",
       "4152      0.152818  \n",
       "4148      0.152818  \n",
       "4151      0.223159  \n",
       "3928      0.290450  \n",
       "3278      0.220533  \n",
       "4113      0.241177  \n",
       "3778      0.228211  \n",
       "4098      0.182199  \n",
       "3705      0.170651  \n",
       "2879      0.165400  \n",
       "3951      0.254979  \n",
       "4107      0.272487  \n",
       "4114      0.227932  \n",
       "4482      0.183900  \n",
       "4480      0.183900  \n",
       "4056      0.190046  \n",
       "4283      0.238292  \n",
       "...            ...  \n",
       "1118      1.299244  \n",
       "1361      0.996456  \n",
       "1158      1.137444  \n",
       "2322      1.140047  \n",
       "1134      1.127433  \n",
       "1307      1.177359  \n",
       "1212      1.140274  \n",
       "1202      0.995017  \n",
       "1186      1.156431  \n",
       "1126      1.181365  \n",
       "2359      1.194707  \n",
       "1119      1.124430  \n",
       "2315      1.199912  \n",
       "1147      1.120872  \n",
       "1113      1.304822  \n",
       "96        1.211494  \n",
       "1216      1.107772  \n",
       "1176      1.177163  \n",
       "1185      1.148747  \n",
       "1287      1.158825  \n",
       "1199      1.124528  \n",
       "1160      1.079728  \n",
       "2278      1.251097  \n",
       "1208      0.883505  \n",
       "1110      0.944669  \n",
       "2298      1.326424  \n",
       "1149      0.917573  \n",
       "1141      0.917573  \n",
       "1117      1.140153  \n",
       "1183      1.338952  \n",
       "\n",
       "[4570 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(lista_resultados).sort_values(['Accuracy'],ascending=False)\n",
    "df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico', 'values', 'error']].to_csv('EAS_resultados.csv', sep=',', index=False) \n",
    "display(df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.141771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.904359</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.144397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3695</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.898412</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 5]</td>\n",
       "      <td>0.893959</td>\n",
       "      <td>0.015106</td>\n",
       "      <td>0.220533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.892472</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 1]</td>\n",
       "      <td>0.877780</td>\n",
       "      <td>0.015037</td>\n",
       "      <td>0.261604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>[4, 1, 2, 6, 1]</td>\n",
       "      <td>0.860133</td>\n",
       "      <td>0.017097</td>\n",
       "      <td>0.275033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 5]</td>\n",
       "      <td>0.859512</td>\n",
       "      <td>0.020820</td>\n",
       "      <td>0.257289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>SVC</td>\n",
       "      <td>[6, 6, 3, 3, 5]</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.017179</td>\n",
       "      <td>0.361796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.771807</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.343927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[4, 1, 2, 3, 1]</td>\n",
       "      <td>0.708543</td>\n",
       "      <td>0.025945</td>\n",
       "      <td>0.558120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 1, 4, 6, 1]</td>\n",
       "      <td>0.691898</td>\n",
       "      <td>0.029330</td>\n",
       "      <td>0.562799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "3987  GradientBoostingClassifier  [6, 1, 3, 3, 5]  0.914520     0.008447   \n",
       "4478            VotingClassifier  [6, 1, 3, 3, 5]  0.904359     0.010358   \n",
       "3695      RandomForestClassifier  [6, 1, 3, 3, 5]  0.898412     0.007043   \n",
       "3278          AdaBoostClassifier  [6, 1, 3, 6, 5]  0.893959     0.015106   \n",
       "2879        ExtraTreesClassifier  [6, 1, 3, 3, 5]  0.892472     0.013311   \n",
       "1854        KNeighborsClassifier  [6, 1, 3, 6, 1]  0.877780     0.015037   \n",
       "968                   GaussianNB  [4, 1, 2, 6, 1]  0.860133     0.017097   \n",
       "2227      DecisionTreeClassifier  [6, 1, 3, 6, 5]  0.859512     0.020820   \n",
       "513                          SVC  [6, 6, 3, 3, 5]  0.829563     0.017179   \n",
       "338   LinearDiscriminantAnalysis  [6, 1, 3, 3, 5]  0.771807     0.020370   \n",
       "2495          LogisticRegression  [4, 1, 2, 3, 1]  0.708543     0.025945   \n",
       "1455               MLPClassifier  [4, 1, 4, 6, 1]  0.691898     0.029330   \n",
       "\n",
       "      errorMetrico  \n",
       "3987      0.141771  \n",
       "4478      0.144397  \n",
       "3695      0.165400  \n",
       "3278      0.220533  \n",
       "2879      0.165400  \n",
       "1854      0.261604  \n",
       "968       0.275033  \n",
       "2227      0.257289  \n",
       "513       0.361796  \n",
       "338       0.343927  \n",
       "2495      0.558120  \n",
       "1455      0.562799  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#topDf = df.drop_duplicates(subset=['Modelo'])\n",
    "#display(topDf)\n",
    "#pd.DataFrame(salida).sort_values(['Accuracy'], ascending=False)\n",
    "topDf=df.drop_duplicates(subset=['Modelo'])\n",
    "topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico', 'values', 'error']].to_csv('EAS_resultados_unique.csv', sep=',', index=False) \n",
    "display(topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#column_plot = 'values'\n",
    "\n",
    "#dataframe_plot = topDf\n",
    "def column_boxplot(dataframe_plot, column_plot):\n",
    "    previos = ['LogisticRegression', 'LinearDiscriminantAnalysis', 'GaussianNB', 'MLPClassifier', \n",
    "               'SVC', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', \n",
    "               'ExtraTreesClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier', 'VotingClassifier']\n",
    "    nuevos = ['LoR', 'LDA', 'GNB', 'MLP', 'SVC', 'DT', 'k-NN', 'RF', 'ET', 'GBM', 'AB', 'VC']\n",
    "    num_models = len(nuevos)\n",
    "    num_splits = 10\n",
    "    dataframe_plot = dataframe_plot[['Modelo', 'Configuracion', 'Accuracy', 'errorMetrico', 'values', 'error']]\n",
    "    for i in range(12):\n",
    "        dataframe_plot['Modelo'] = dataframe_plot['Modelo'].str.replace(previos[i], nuevos[i])\n",
    "        #df['Modelo'] = df['Modelo'].str.replace('LinearDiscriminantAnalysis','LDA')\n",
    "    sorterIndex = dict(zip(nuevos,range(num_models)))\n",
    "    #test\n",
    "    dataframe_plot['Model_Rank'] = dataframe_plot['Modelo'].map(sorterIndex)\n",
    "    dataframe_plot = dataframe_plot.sort_values(['Model_Rank'],ascending=True).reset_index(drop=True)[dataframe_plot.columns[:-1]]\n",
    "    lista_plot = []\n",
    "    for i in range(num_models):\n",
    "        for j in range(num_splits):\n",
    "            d = {'Model':nuevos[i], 'Score':dataframe_plot[column_plot][i][j]}\n",
    "            lista_plot.append(d)\n",
    "    #pd.DataFrame(lista_plot)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    ax_plot = sns.boxplot(data=pd.DataFrame(lista_plot), x=\"Model\", y=\"Score\", linewidth = 1.0)\n",
    "    plt.format='eps'\n",
    "    if column_plot == 'values':\n",
    "        medians = np.round(list(dataframe_plot['Accuracy']),3)\n",
    "        tope = 0.98\n",
    "    else:\n",
    "        medians = np.round(list(dataframe_plot['errorMetrico']),3)\n",
    "        tope = 6.5\n",
    "    median_labels = [str(s) for s in medians]\n",
    "    pos = range(num_models)\n",
    "    for tick,label in zip(pos,ax_plot.get_xticklabels()):\n",
    "        ax_plot.text(pos[tick], tope, median_labels[tick], \n",
    "                horizontalalignment='center', color='black') #, weight='semibold'\n",
    "    axes = plt.gca()\n",
    "    if column_plot == 'values':\n",
    "        axes.set_ylim([0.3,1.0])\n",
    "    #else:\n",
    "    #    axes.set_ylim([0, 4])\n",
    "    plt.savefig('destination_path.eps')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAHeCAYAAABT+34JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f04f05d9828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzEAAAKgCAYAAACr2/PSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nImIAAICiiBgAAKAoIgYAACjK/wcE9ImXsVOMIwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0516009940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
