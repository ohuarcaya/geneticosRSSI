{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Librería Genética\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Subfunciones de estimadores\n",
    "from sklearn.base import clone\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][30]\n",
    "from sklearn.base import is_classifier\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][535]\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_validation.py][346]\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][386]\n",
    "from sklearn.model_selection._search import check_cv\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_split.py][1866]\n",
    "from sklearn.model_selection._search import _check_param_grid\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][343]\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/scorer.py][250]\n",
    "from sklearn.utils.validation import _num_samples\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][105]\n",
    "from sklearn.utils.validation import indexable\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][208]\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "from itertools import product\n",
    "\n",
    "# Selección para estimadores\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metricas para estimadores\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Estimadores\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Ensembles algorithms\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (14, 8)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find distance error al 0.2%\n",
    "def distance_error(estimator, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 7)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    # coord pred\n",
    "    x1 = np.int32((y_pred + 2) % 3)\n",
    "    y1 = np.int32((y_pred - 1) / 3)\n",
    "    # coord real\n",
    "    x2 = np.int32((y_test + 2) % 3)\n",
    "    y2 = np.int32((y_test - 1) / 3)\n",
    "    # pasar variacion a distancias metros\n",
    "    vx = np.abs(x1 - x2)*1.5\n",
    "    vy = np.abs(y1 - y2)*1.5\n",
    "    #vx = vx*0.5 + (vx-1)*(vx>0)\n",
    "    #vy = vy*0.5 + (vy-1)*(vy>0)\n",
    "    # pitagoras\n",
    "    err_distance = np.sqrt(vx*vx + vy*vy)\n",
    "    return err_distance\n",
    "\n",
    "#def _createDataset(frecuencias, values, seed = 7):\n",
    "def _createDataset(frecuencias, values):\n",
    "    # crear dataset\n",
    "    names_ = frecuencias[0].columns.values\n",
    "    seed = 7\n",
    "    # reestructuracion\n",
    "    salida_final = pd.DataFrame(columns=names_)\n",
    "    for sec in range(1,16):\n",
    "        dataset = pd.DataFrame(columns=names_)\n",
    "        corte = min([frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values])\n",
    "        #l = [frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values]\n",
    "        #corte = max(l)\n",
    "        #tx=l.index(max(l))\n",
    "        tx = 0\n",
    "        dataset[names_[tx]] = dataset[names_[tx]].append(frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]])\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        for tx in range(1,5):\n",
    "            dataset[names_[tx]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]].reset_index(drop=True)\n",
    "        dataset[names_[tx+1]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx+1]].reset_index(drop=True)\n",
    "        # join parts\n",
    "        salida_final = salida_final.append(dataset)\n",
    "    # shuffle dataset\n",
    "    salida_final = shuffle(salida_final, random_state=seed).reset_index(drop=True)\n",
    "    salida_final = salida_final.apply(pd.to_numeric)\n",
    "    # dataframe to X,y \n",
    "    X = salida_final[names_[:-1]]\n",
    "    y = salida_final[names_[-1]]\n",
    "    return X,y\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    # LDA : Warning(Variables are collinear)\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('SVC', SVC(random_state=rs)))\n",
    "    models.append(('GaussianNB', GaussianNB()))\n",
    "    models.append(('MLPClassifier', MLPClassifier()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=rs)))\n",
    "    models.append(('LogisticRegression', LogisticRegression()))\n",
    "    # Bagging and Boosting\n",
    "    # models.append(('ExtraTreesClassifier', ExtraTreesClassifier(n_estimators=150)))\n",
    "    models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state=rs)))\n",
    "    models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier(random_state=rs),\n",
    "                                                            random_state=rs)))\n",
    "    # models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier())))\n",
    "    models.append(('RandomForestClassifier', RandomForestClassifier(random_state=rs)))\n",
    "    models.append(('GradientBoostingClassifier',\n",
    "                   GradientBoostingClassifier(random_state=rs)))\n",
    "    # models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "    # Voting\n",
    "    estimators = []\n",
    "    estimators.append((\"Voting_GradientBoostingClassifier\", GradientBoostingClassifier(random_state=rs)))\n",
    "    estimators.append((\"Voting_ExtraTreesClassifier\", ExtraTreesClassifier(random_state=rs)))\n",
    "    voting = VotingClassifier(estimators)\n",
    "    models.append(('VotingClassifier', voting))\n",
    "    return models\n",
    "\n",
    "# The problem to optimize\n",
    "def getAccuracy( frecuencias, individual, estimator, score_cache, resultados ):\n",
    "\tX,y = _createDataset(frecuencias, individual)\n",
    "\t#print(X)\n",
    "\t#print\n",
    "\t#print\n",
    "\t#print(y)\n",
    "\tscore = 0\n",
    "\tscorer = \"accuracy\"\n",
    "\tname = str(estimator).split('(')[0]\n",
    "\tparamkey = str(np.int32(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=10, shuffle=False)\n",
    "\t\tcv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scorer)\n",
    "\t\t#print(name,\"  \",paramkey,\"   \")\n",
    "\t\t#print(len(X),\"  \",len(y),\"   \", kfold)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\tdesv = cv_results.std()\n",
    "\t\terror = distance_error(estimator, X, y)\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\tdict_result = {'Modelo': name, 'Configuracion':np.int32(individual)+1, 'values': cv_results, 'Accuracy': score, 'stdAccuracy': desv, 'errorMetrico': np.mean(error), 'error': error }\n",
    "\t\tresultados.append(dict_result)\n",
    "\treturn score\n",
    "\"\"\"\n",
    "def _evalFunction(individual, frecuencias, scorer, num_folds, score_cache, desv_cache, error_cache, resultados_cache):\n",
    "\tX, y = _individual_to_params(frecuencias, individual)\n",
    "\tscore = 0\n",
    "\tn_test = 0\n",
    "\tname = str(individual.est).split('(')[0]\n",
    "\tparamkey = str(np.array(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=10, shuffle=False)\n",
    "\t\t#cv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scoring)\n",
    "\t\tcv_results = cross_val_score(individual.est, X, y, cv=kfold, scoring=scorer)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\tdesv_cache[paramkey] = cv_results.std()\n",
    "\t\terror_cache[paramkey] = distance_error(individual.est, X, y)\n",
    "\t\tresults = {'Modelo': name, 'Configuracion':np.int32(individual)+1, 'values': cv_results, 'Accuracy': score, 'stdAccuracy': desv_cache[paramkey], 'errorMetrico': error_cache[paramkey]}  \n",
    "\t\tresultados_cache.append(results)\n",
    "\treturn (score,)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class eda:\n",
    "\tdef __init__(self, of, frecuencias, estimator):\n",
    "\t\t# Algorithm parameters\n",
    "\t\tself.iterations = 10\n",
    "\t\tself.sample_size = 100\n",
    "\t\tself.select_ratio = 0.5\n",
    "\t\tself.epsilon = 10e-6\n",
    "\n",
    "\t\t# class members\n",
    "\t\tself.objective_function = of\n",
    "\t\tself.dimensions = 5\n",
    "\t\tself.sample = []\n",
    "\t\tself.means = []\n",
    "\t\tself.stdevs = []\t\n",
    "\n",
    "\t\tself.debug = False\n",
    "\t\t# aditional parameters\n",
    "\t\tself.frecuencias = frecuencias\n",
    "\t\tself.estimator = estimator\n",
    "\t\tself.__manager = Manager()\n",
    "\t\tself.score_cache = {}\n",
    "\t\tself.resultados = self.__manager.list()\n",
    "\t\tself.n_jobs = cpu_count()\n",
    "        \n",
    "\n",
    "\tdef sample_sort(self): \n",
    "\t\t# sort rows on the last column\n",
    "\t\tself.sample = self.sample[ np.argsort( self.sample[:,-1], 0 ) ]\n",
    "\n",
    "\n",
    "\tdef dispersion_reduction(self):\n",
    "\t\tself.sample_sort()\n",
    "\n",
    "\t\t# number of points to select\n",
    "\t\tnb = int( np.floor( self.sample_size * self.select_ratio ) )\n",
    "\n",
    "\t\t# selection\n",
    "\t\t#self.sample = self.sample[:nb]\n",
    "\t\tself.sample = self.sample[self.sample_size-nb:]\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"dispersion reduction\")\n",
    "\t\t\tprint (str(self.sample))\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef estimate_parameters( self ):\n",
    "\t\t# points sub array (without values)\n",
    "\t\tmat = self.sample[:,:self.dimensions]\n",
    "\t\t\n",
    "\t\t# row means (axis 0 in scipy)\n",
    "\t\tself.means = np.mean( mat, 0 )\n",
    "\t\t\n",
    "\t\t# row standard deviation\n",
    "\t\tself.stdevs = np.std( mat, 0 )\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"estimate parameters\")\n",
    "\t\t\tprint (\"\\tmean=\" +str(self.means))\n",
    "\t\t\tprint (\"\\tstd-dev=\" + str(self.stdevs))\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef draw_sample(self):\n",
    "\t\t# for each variable to optimize\n",
    "\t\tfor i in range(self.dimensions):\n",
    "\t\t\t# if the dispersion is null\n",
    "\t\t\tif self.stdevs[i] == 0.0:\n",
    "\t\t\t\t# set it to a minimal value\n",
    "\t\t\t\tself.stdevs[i] = self.epsilon\n",
    "\t\t\n",
    "\t\t# empty sample\n",
    "\t\tself.sample = np.zeros( (self.sample_size, self.dimensions+1) )\n",
    "\t\t\n",
    "\t\t# for each point\n",
    "\t\tfor i in range( self.sample_size ):\n",
    "\t\t\t# draw in random normal\n",
    "\t\t\tp = np.random.normal( self.means, self.stdevs )\n",
    "\t\t\tp = np.array([0 if i<0 else (5 if i>5 else i) for i in p])\n",
    "\t\t\t# put it into the sample\n",
    "\t\t\tself.sample[i][:self.dimensions] = np.round(p)%(self.dimensions+1)\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"draw sample\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef evaluate(self):\n",
    "\t\t# for each point\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in range( self.sample_size ):\n",
    "\t\t\td = self.dimensions\n",
    "\t\t\t# call the objective function\n",
    "\t\t\t#   the third element is the result of the objective function call\n",
    "\t\t\t#   taking the first two elements as variables\n",
    "\t\t\t#r = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache )\n",
    "\t\t\t#self.sample[i][-1] = r\n",
    "\t\t\tself.sample[i][-1] = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache , self.resultados)\n",
    "\t\t\"\"\"\n",
    "\t\td = self.dimensions\n",
    "\t\t_pool = Pool(self.n_jobs)\n",
    "\t\t#self.sample[i][-1] = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache , self.resultados)\n",
    "\t\t_iterable = product([self.frecuencias], np.int32(self.sample[:,:d]), [self.estimator], [self.score_cache], [self.resultados])\n",
    "\t\tself.sample[:,-1] = _pool.starmap(self.objective_function, _iterable)\n",
    "\t\t_pool.close()\n",
    "\t\t_pool.join()\n",
    "\t\t#getAccuracy( frecuencias, individual, estimator, score_cache, resultados ):\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"evaluate\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef run(self):\n",
    "\t\t# uniform initialization\n",
    "\t\tself.sample = np.random.rand( self.sample_size, self.dimensions+1 )\n",
    "\t\t# cosmetic\n",
    "\t\t#self.sample = self.sample * 200 - 100\n",
    "\t\ttop_freq = 6\n",
    "\t\tself.sample = np.floor(np.random.rand(self.sample_size, self.dimensions +1)*top_freq)\n",
    "\t\t\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"initialization\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\t\tself.evaluate()\n",
    "\n",
    "\t\t# Multi process\n",
    "\t\t\n",
    "\t\ti = 0\n",
    "\t\twhile i < self.iterations:\n",
    "\t\t\tif self.debug:\n",
    "\t\t\t\tprint (\"iteration\",i)\n",
    "\t\t\t\tprint\n",
    "\n",
    "\t\t\ti += 1\n",
    "\t\t\tself.dispersion_reduction()\n",
    "\t\t\tprint(\"iter[\"+str(i)+\"]-top1: \"+str(self.sample[-1]))\n",
    "\t\t\tself.estimate_parameters()\n",
    "\t\t\tself.draw_sample()\n",
    "\t\t\tself.evaluate()\n",
    "\t\t\t# print top 1\n",
    "\t\t\tself.sample_sort()\n",
    "\n",
    "\t\t# sort the final sample\n",
    "\t\tself.sample_sort()\n",
    "\t\t# output the optimum\n",
    "\t\t#self.pool.close()\n",
    "\t\t#self.pool.join()\n",
    "\t\tranking = self.sample_size\n",
    "\t\t#print (\"#[ Configuración ]\\t Accuracy\")\n",
    "\t\t#for i in range(ranking):\n",
    "\t\t#\tlinea = str(self.sample[-i-1][:-1]+1) + \"\\t\" +str(self.sample[-i-1][-1])\n",
    "\t\t#\tprint(linea)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "frecuencias = []\n",
    "names_ = ['Be01', 'Be02', 'Be03', 'Be04', 'Be05', 'Sector']\n",
    "\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x01'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x02'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x03'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x04'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x05'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x06'))#, names=names_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modeling... LinearDiscriminantAnalysis\n",
      "iter[1]-top1: [ 0.         0.         2.         2.         0.         0.7200372]\n",
      "iter[2]-top1: [ 5.          0.          0.          2.          2.          0.73160892]\n",
      "iter[3]-top1: [ 5.          0.          3.          3.          0.          0.72290802]\n",
      "iter[4]-top1: [ 3.          0.          3.          2.          0.          0.74027304]\n",
      "iter[5]-top1: [ 3.          0.          1.          0.          0.          0.73609261]\n",
      "iter[6]-top1: [ 5.          3.          2.          2.          0.          0.72542787]\n",
      "iter[7]-top1: [ 5.          0.          2.          2.          0.          0.76240384]\n",
      "iter[8]-top1: [ 5.          0.          2.          2.          0.          0.76240384]\n",
      "iter[9]-top1: [ 5.          0.          2.          2.          1.          0.72818117]\n",
      "iter[10]-top1: [ 5.          0.          1.          2.          0.          0.75629733]\n",
      "\n",
      "Modeling... SVC\n",
      "iter[1]-top1: [ 5.          5.          1.          0.          4.          0.81017367]\n",
      "iter[2]-top1: [ 3.          0.          2.          5.          0.          0.81442543]\n",
      "iter[3]-top1: [ 5.          4.          1.          2.          5.          0.81581515]\n",
      "iter[4]-top1: [ 5.          4.          3.          2.          0.          0.80694789]\n",
      "iter[5]-top1: [ 5.         5.         3.         2.         0.         0.8190709]\n",
      "iter[6]-top1: [ 5.          2.          2.          2.          4.          0.82367213]\n",
      "iter[7]-top1: [ 5.          4.          1.          2.          3.          0.81478116]\n",
      "iter[8]-top1: [ 5.          2.          2.          2.          4.          0.82367213]\n",
      "iter[9]-top1: [ 5.          2.          2.          2.          2.          0.80664214]\n",
      "iter[10]-top1: [ 5.          2.          2.          2.          4.          0.82367213]\n",
      "\n",
      "Modeling... GaussianNB\n",
      "iter[1]-top1: [ 4.         0.         2.         2.         0.         0.8212442]\n",
      "iter[2]-top1: [ 3.          0.          5.          3.          0.          0.83104593]\n",
      "iter[3]-top1: [ 3.          0.          2.          4.          0.          0.82183299]\n",
      "iter[4]-top1: [ 5.         3.         2.         2.         0.         0.8205379]\n",
      "iter[5]-top1: [ 5.         0.         2.         3.         5.         0.8193154]\n",
      "iter[6]-top1: [ 5.          0.          2.          2.          0.          0.84697477]\n",
      "iter[7]-top1: [ 3.          0.          5.          2.          0.          0.83202934]\n",
      "iter[8]-top1: [ 5.          0.          2.          2.          2.          0.84160475]\n",
      "iter[9]-top1: [ 5.          0.          1.          2.          0.          0.84258215]\n",
      "iter[10]-top1: [ 5.          0.          1.          2.          0.          0.84258215]\n",
      "\n",
      "Modeling... MLPClassifier\n",
      "iter[1]-top1: [ 3.          0.          5.          1.          0.          0.64334878]\n",
      "iter[2]-top1: [ 3.          0.          3.          2.          0.          0.64247006]\n",
      "iter[3]-top1: [ 3.          0.          3.          3.          0.          0.63748242]\n",
      "iter[4]-top1: [ 3.          0.          2.          0.          0.          0.65746345]\n",
      "iter[5]-top1: [ 3.          0.          3.          3.          0.          0.63913916]\n",
      "iter[6]-top1: [ 3.          4.          3.          0.          0.          0.63130681]\n",
      "iter[7]-top1: [ 3.         5.         1.         0.         0.         0.6375882]\n",
      "iter[8]-top1: [ 3.          4.          3.          2.          0.          0.63697172]\n",
      "iter[9]-top1: [ 5.          5.          3.          3.          0.          0.64767743]\n",
      "iter[10]-top1: [ 5.          5.          3.          0.          0.          0.64912897]\n",
      "\n",
      "Modeling... KNeighborsClassifier\n",
      "iter[1]-top1: [ 5.          0.          0.          5.          4.          0.85175943]\n",
      "iter[2]-top1: [ 5.          3.          1.          2.          5.          0.84730776]\n",
      "iter[3]-top1: [ 5.          0.          2.          3.          4.          0.86270238]\n",
      "iter[4]-top1: [ 5.          0.          1.          0.          3.          0.85268458]\n",
      "iter[5]-top1: [ 5.          0.          2.          3.          0.          0.85476773]\n",
      "iter[6]-top1: [ 5.          0.          1.          2.          3.          0.85770171]\n",
      "iter[7]-top1: [ 5.          0.          2.          2.          2.          0.86311945]\n",
      "iter[8]-top1: [ 5.          0.          2.          2.          1.          0.85553104]\n",
      "iter[9]-top1: [ 5.          3.          1.          2.          0.          0.85354523]\n",
      "iter[10]-top1: [ 5.          4.          1.          2.          0.          0.85331978]\n",
      "\n",
      "Modeling... DecisionTreeClassifier\n",
      "iter[1]-top1: [ 2.          0.          2.          5.          0.          0.82254517]\n",
      "iter[2]-top1: [ 5.          0.          1.          5.          0.          0.83565302]\n",
      "iter[3]-top1: [ 5.          4.          3.          2.          0.          0.81239466]\n",
      "iter[4]-top1: [ 5.         5.         2.         2.         2.         0.8066392]\n",
      "iter[5]-top1: [ 5.          3.          3.          2.          0.          0.81344743]\n",
      "iter[6]-top1: [ 5.          3.          1.          2.          5.          0.82404558]\n",
      "iter[7]-top1: [ 5.          5.          2.          2.          1.          0.82141035]\n",
      "iter[8]-top1: [ 5.          3.          1.          2.          0.          0.81246944]\n",
      "iter[9]-top1: [ 5.          5.          2.          2.          1.          0.82141035]\n",
      "iter[10]-top1: [ 5.          5.          2.          2.          1.          0.82141035]\n",
      "\n",
      "Modeling... LogisticRegression\n",
      "iter[1]-top1: [ 3.          0.          5.          2.          0.          0.68606357]\n",
      "iter[2]-top1: [ 3.          5.          0.          3.          0.          0.64888051]\n",
      "iter[3]-top1: [ 5.         0.         2.         2.         2.         0.6683058]\n",
      "iter[4]-top1: [ 4.          0.          0.          2.          0.          0.64774316]\n",
      "iter[5]-top1: [ 5.          0.          2.          1.          4.          0.67171277]\n",
      "iter[6]-top1: [ 4.          0.          2.          0.          0.          0.66147104]\n",
      "iter[7]-top1: [ 3.          0.          2.          2.          4.          0.65196677]\n",
      "iter[8]-top1: [ 3.          4.          1.          2.          0.          0.69419972]\n",
      "iter[9]-top1: [ 5.          0.          2.          2.          5.          0.66023138]\n",
      "iter[10]-top1: [ 5.          3.          2.          0.          4.          0.66742193]\n",
      "\n",
      "Modeling... ExtraTreesClassifier\n",
      "iter[1]-top1: [ 3.          0.          5.          2.          3.          0.86332518]\n",
      "iter[2]-top1: [ 5.         3.         5.         2.         1.         0.8565199]\n",
      "iter[3]-top1: [ 5.          0.          0.          2.          1.          0.87044189]\n",
      "iter[4]-top1: [ 5.          0.          1.          2.          1.          0.86360427]\n",
      "iter[5]-top1: [ 5.          0.          2.          2.          4.          0.89247169]\n",
      "iter[6]-top1: [ 5.         0.         1.         2.         5.         0.8758304]\n",
      "iter[7]-top1: [ 5.          0.          2.          2.          4.          0.89247169]\n",
      "iter[8]-top1: [ 5.          0.          0.          2.          4.          0.87710181]\n",
      "iter[9]-top1: [ 5.          0.          2.          2.          4.          0.89247169]\n",
      "iter[10]-top1: [ 5.          0.          1.          2.          4.          0.87834312]\n",
      "\n",
      "Modeling... AdaBoostClassifier\n",
      "iter[1]-top1: [ 5.          3.          3.          2.          1.          0.85408743]\n",
      "iter[2]-top1: [ 3.          0.          2.          5.          0.          0.87823961]\n",
      "iter[3]-top1: [ 3.          0.          2.          5.          0.          0.87823961]\n",
      "iter[4]-top1: [ 5.          0.          1.          0.          2.          0.86213907]\n",
      "iter[5]-top1: [ 5.          0.          2.          2.          0.          0.87875842]\n",
      "iter[6]-top1: [ 5.          0.          3.          5.          0.          0.86998709]\n",
      "iter[7]-top1: [ 5.         0.         3.         0.         4.         0.8646951]\n",
      "iter[8]-top1: [ 5.          0.          2.          0.          2.          0.87166975]\n",
      "iter[9]-top1: [ 5.          0.          2.          0.          2.          0.87166975]\n",
      "iter[10]-top1: [ 5.          0.          3.          2.          0.          0.87310513]\n",
      "\n",
      "Modeling... RandomForestClassifier\n",
      "iter[1]-top1: [ 4.          0.          2.          5.          0.          0.86448051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter[2]-top1: [ 5.          0.          2.          2.          4.          0.89841166]\n",
      "iter[3]-top1: [ 5.          3.          2.          2.          2.          0.86839606]\n",
      "iter[4]-top1: [ 5.         0.         2.         0.         4.         0.8803227]\n",
      "iter[5]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[6]-top1: [ 5.          0.          3.          2.          4.          0.87929882]\n",
      "iter[7]-top1: [ 5.         0.         2.         2.         2.         0.8834039]\n",
      "iter[8]-top1: [ 5.          0.          0.          2.          2.          0.88095653]\n",
      "iter[9]-top1: [ 5.         0.         2.         2.         2.         0.8834039]\n",
      "iter[10]-top1: [ 5.          0.          0.          2.          0.          0.87801956]\n",
      "\n",
      "Modeling... GradientBoostingClassifier\n",
      "iter[1]-top1: [ 5.         0.         1.         2.         4.         0.9001382]\n",
      "iter[2]-top1: [ 5.          3.          2.          2.          2.          0.88439608]\n",
      "iter[3]-top1: [ 5.          2.          2.          5.          4.          0.88727779]\n",
      "iter[4]-top1: [ 5.          3.          2.          2.          1.          0.89021192]\n",
      "iter[5]-top1: [ 5.          2.          1.          2.          0.          0.89195301]\n",
      "iter[6]-top1: [ 5.          4.          1.          2.          3.          0.89756468]\n",
      "iter[7]-top1: [ 5.          4.          1.          2.          1.          0.88604868]\n",
      "iter[8]-top1: [ 5.         0.         2.         3.         4.         0.8988932]\n",
      "iter[9]-top1: [ 5.         0.         2.         3.         4.         0.8988932]\n",
      "iter[10]-top1: [ 5.          4.          1.          2.          3.          0.89756468]\n",
      "\n",
      "Modeling... VotingClassifier\n",
      "iter[1]-top1: [ 5.          0.          2.          5.          3.          0.86845966]\n",
      "iter[2]-top1: [ 5.          4.          3.          2.          1.          0.87079118]\n",
      "iter[3]-top1: [ 5.          3.          5.          2.          1.          0.86936811]\n",
      "iter[4]-top1: [ 5.          2.          1.          2.          3.          0.86984826]\n",
      "iter[5]-top1: [ 5.          0.          0.          2.          3.          0.88410758]\n",
      "iter[6]-top1: [ 5.         0.         2.         2.         0.         0.8858465]\n",
      "iter[7]-top1: [ 5.          4.          1.          2.          3.          0.87422857]\n",
      "iter[8]-top1: [ 5.          2.          2.          2.          2.          0.87568937]\n",
      "iter[9]-top1: [ 5.          4.          2.          2.          2.          0.87523968]\n",
      "iter[10]-top1: [ 5.          2.          2.          2.          2.          0.87568937]\n"
     ]
    }
   ],
   "source": [
    "#n_neighbors = 5 7 11\n",
    "#weights = 'distance'\n",
    "#algorithm = 'kd_tree' 'ball_tree'\n",
    "#estimator = KNeighborsClassifier(n_jobs=8, weights = 'distance', n_neighbors = 5, algorithm = 'kd_tree')\n",
    "#a = eda( getAccuracy, frecuencias, estimator )\n",
    "#a.run()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    return models\n",
    "\"\"\"\n",
    "estimadores = set_models()\n",
    "\n",
    "#reserva = {}\n",
    "lista_resultados = []\n",
    "for name, model in estimadores:\n",
    "    print(\"\\nModeling...\", name)\n",
    "    splits = 10\n",
    "    #simetricas = [[i]*5 for i in range(6)]\n",
    "    #for individual in simetricas:\n",
    "    #acc, desv, err = evaluate(frecuencias, individual, model)\n",
    "    #salida[str(name)+\"-\"+str(individual)] = str(acc) + \"-\"+ str(desv) + \"-\" + str(err)\n",
    "    #print(name,\" \", individual, \"\\t\", acc, \"\\t\", desv, \"\\t\", err)\n",
    "    #gs = EvolutiveSearchCV(estimator=model, scoring=\"accuracy\", num_folds=10, n_jobs=num_jobs,\n",
    "    #                    verbose=True, refit=True, \n",
    "    #                    population_size=100, \n",
    "    #                    gene_mutation_prob=0.3, \n",
    "    #                    gene_crossover_prob=0.5,\n",
    "    #                    tournament_size=4,\n",
    "    #                    generations_number=10)\n",
    "    a = eda( getAccuracy, frecuencias, model )\n",
    "    a.run()\n",
    "    #gs.fit(frecuencias)\n",
    "    #reserva[name]=(gs.score_cache, gs.desv_cache , gs.error_cache)\n",
    "    lista_resultados = lista_resultados + list(a.resultados)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11030</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 5]</td>\n",
       "      <td>0.900138</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.212657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11771</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 4, 5]</td>\n",
       "      <td>0.898893</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.197149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10039</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.898412</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 2, 3, 4]</td>\n",
       "      <td>0.897565</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.208228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11720</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.896850</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.152818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11798</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 5]</td>\n",
       "      <td>0.892923</td>\n",
       "      <td>0.013625</td>\n",
       "      <td>0.182199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8281</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.892472</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11666</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 1]</td>\n",
       "      <td>0.891953</td>\n",
       "      <td>0.012587</td>\n",
       "      <td>0.308226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11763</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 2, 3, 1]</td>\n",
       "      <td>0.890237</td>\n",
       "      <td>0.016098</td>\n",
       "      <td>0.301921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 3]</td>\n",
       "      <td>0.890230</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.190046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11673</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 3, 3, 2]</td>\n",
       "      <td>0.890212</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.164364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11909</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 3, 4, 5]</td>\n",
       "      <td>0.890197</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.257682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11344</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 6]</td>\n",
       "      <td>0.889506</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.254250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11983</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 2, 3, 4]</td>\n",
       "      <td>0.889480</td>\n",
       "      <td>0.009786</td>\n",
       "      <td>0.238841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11739</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 3, 3, 1]</td>\n",
       "      <td>0.888998</td>\n",
       "      <td>0.015853</td>\n",
       "      <td>0.153005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12008</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 6, 3, 3, 2]</td>\n",
       "      <td>0.888537</td>\n",
       "      <td>0.007836</td>\n",
       "      <td>0.210591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11359</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[4, 6, 1, 3, 2]</td>\n",
       "      <td>0.888264</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>0.150411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11178</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 6, 5]</td>\n",
       "      <td>0.887278</td>\n",
       "      <td>0.013259</td>\n",
       "      <td>0.231653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11947</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 4, 3]</td>\n",
       "      <td>0.886308</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.238584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12042</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 6, 3, 3, 4]</td>\n",
       "      <td>0.886092</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12015</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 2, 3, 2]</td>\n",
       "      <td>0.886049</td>\n",
       "      <td>0.019826</td>\n",
       "      <td>0.265490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11745</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 6, 3, 3, 5]</td>\n",
       "      <td>0.886044</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>0.200419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10983</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 6, 3, 5]</td>\n",
       "      <td>0.886021</td>\n",
       "      <td>0.012083</td>\n",
       "      <td>0.162775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12595</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.885847</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.227932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11442</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[4, 5, 2, 3, 1]</td>\n",
       "      <td>0.885764</td>\n",
       "      <td>0.020842</td>\n",
       "      <td>0.261801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11180</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[4, 1, 2, 3, 4]</td>\n",
       "      <td>0.885515</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.206111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11436</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[4, 1, 2, 3, 5]</td>\n",
       "      <td>0.885298</td>\n",
       "      <td>0.017266</td>\n",
       "      <td>0.232440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 2, 3, 4]</td>\n",
       "      <td>0.885120</td>\n",
       "      <td>0.018228</td>\n",
       "      <td>0.187477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11951</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 6, 3, 3, 1]</td>\n",
       "      <td>0.885111</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.233112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11971</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 3, 3, 3]</td>\n",
       "      <td>0.884817</td>\n",
       "      <td>0.012312</td>\n",
       "      <td>0.208228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 5, 2, 5, 1]</td>\n",
       "      <td>0.420899</td>\n",
       "      <td>0.051852</td>\n",
       "      <td>1.110714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3287</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 6, 3, 3]</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>0.026625</td>\n",
       "      <td>1.302070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6596</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[1, 5, 2, 5, 3]</td>\n",
       "      <td>0.417947</td>\n",
       "      <td>0.017671</td>\n",
       "      <td>1.199007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 4, 4, 6]</td>\n",
       "      <td>0.416381</td>\n",
       "      <td>0.031255</td>\n",
       "      <td>1.247378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 3, 5, 2, 6]</td>\n",
       "      <td>0.416257</td>\n",
       "      <td>0.034155</td>\n",
       "      <td>1.090593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 6, 2, 2]</td>\n",
       "      <td>0.415818</td>\n",
       "      <td>0.027738</td>\n",
       "      <td>1.273819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 4, 2, 5, 3]</td>\n",
       "      <td>0.415673</td>\n",
       "      <td>0.032601</td>\n",
       "      <td>1.006360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 1, 2, 3]</td>\n",
       "      <td>0.414745</td>\n",
       "      <td>0.016605</td>\n",
       "      <td>1.206289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6598</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[3, 5, 1, 5, 3]</td>\n",
       "      <td>0.412904</td>\n",
       "      <td>0.021819</td>\n",
       "      <td>1.177163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 4, 2, 5]</td>\n",
       "      <td>0.412238</td>\n",
       "      <td>0.012373</td>\n",
       "      <td>1.397320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3749</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 6, 2, 3]</td>\n",
       "      <td>0.410608</td>\n",
       "      <td>0.026062</td>\n",
       "      <td>1.160870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 3, 3, 3, 1]</td>\n",
       "      <td>0.407899</td>\n",
       "      <td>0.056991</td>\n",
       "      <td>0.760859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 2, 4, 3]</td>\n",
       "      <td>0.406834</td>\n",
       "      <td>0.044381</td>\n",
       "      <td>1.204363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 4, 4, 2, 3]</td>\n",
       "      <td>0.406629</td>\n",
       "      <td>0.016390</td>\n",
       "      <td>1.124528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6762</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[3, 5, 4, 5, 3]</td>\n",
       "      <td>0.405455</td>\n",
       "      <td>0.026371</td>\n",
       "      <td>1.113693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 2, 1, 1]</td>\n",
       "      <td>0.401674</td>\n",
       "      <td>0.034883</td>\n",
       "      <td>0.819911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 1, 3, 2, 2]</td>\n",
       "      <td>0.399112</td>\n",
       "      <td>0.033021</td>\n",
       "      <td>0.981167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 2, 6, 3]</td>\n",
       "      <td>0.395754</td>\n",
       "      <td>0.030398</td>\n",
       "      <td>1.331329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3324</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 5, 5, 5, 2]</td>\n",
       "      <td>0.387640</td>\n",
       "      <td>0.021158</td>\n",
       "      <td>1.148850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 5, 2, 3]</td>\n",
       "      <td>0.382944</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>1.316847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 3, 2, 1]</td>\n",
       "      <td>0.382187</td>\n",
       "      <td>0.030844</td>\n",
       "      <td>1.037948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4001</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 2, 3, 1]</td>\n",
       "      <td>0.374510</td>\n",
       "      <td>0.080633</td>\n",
       "      <td>0.976625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3344</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 6, 2, 2, 3]</td>\n",
       "      <td>0.374359</td>\n",
       "      <td>0.034429</td>\n",
       "      <td>1.291797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 3, 2, 2]</td>\n",
       "      <td>0.362058</td>\n",
       "      <td>0.029904</td>\n",
       "      <td>1.083372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 2, 1, 2]</td>\n",
       "      <td>0.361848</td>\n",
       "      <td>0.044017</td>\n",
       "      <td>0.960726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 1, 5, 3]</td>\n",
       "      <td>0.352261</td>\n",
       "      <td>0.036908</td>\n",
       "      <td>1.247550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 5, 5, 3]</td>\n",
       "      <td>0.341956</td>\n",
       "      <td>0.025560</td>\n",
       "      <td>1.514535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3885</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 1, 1, 2]</td>\n",
       "      <td>0.339123</td>\n",
       "      <td>0.048897</td>\n",
       "      <td>0.976625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 1, 3, 3]</td>\n",
       "      <td>0.335920</td>\n",
       "      <td>0.063505</td>\n",
       "      <td>0.931201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 3, 1, 3, 3]</td>\n",
       "      <td>0.305492</td>\n",
       "      <td>0.053533</td>\n",
       "      <td>0.890319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9457 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "11030  GradientBoostingClassifier  [6, 1, 2, 3, 5]  0.900138     0.016621   \n",
       "11771  GradientBoostingClassifier  [6, 1, 3, 4, 5]  0.898893     0.016274   \n",
       "10039      RandomForestClassifier  [6, 1, 3, 3, 5]  0.898412     0.007043   \n",
       "11977  GradientBoostingClassifier  [6, 5, 2, 3, 4]  0.897565     0.009551   \n",
       "11720  GradientBoostingClassifier  [6, 1, 3, 3, 3]  0.896850     0.009726   \n",
       "11798  GradientBoostingClassifier  [6, 3, 3, 3, 5]  0.892923     0.013625   \n",
       "8281         ExtraTreesClassifier  [6, 1, 3, 3, 5]  0.892472     0.013311   \n",
       "11666  GradientBoostingClassifier  [6, 3, 2, 3, 1]  0.891953     0.012587   \n",
       "11763  GradientBoostingClassifier  [6, 5, 2, 3, 1]  0.890237     0.016098   \n",
       "11850  GradientBoostingClassifier  [6, 3, 3, 3, 3]  0.890230     0.010172   \n",
       "11673  GradientBoostingClassifier  [6, 4, 3, 3, 2]  0.890212     0.012968   \n",
       "11909  GradientBoostingClassifier  [6, 5, 3, 4, 5]  0.890197     0.010327   \n",
       "11344  GradientBoostingClassifier  [6, 3, 2, 3, 6]  0.889506     0.013688   \n",
       "11983  GradientBoostingClassifier  [6, 3, 2, 3, 4]  0.889480     0.009786   \n",
       "11739  GradientBoostingClassifier  [6, 4, 3, 3, 1]  0.888998     0.015853   \n",
       "12008  GradientBoostingClassifier  [6, 6, 3, 3, 2]  0.888537     0.007836   \n",
       "11359  GradientBoostingClassifier  [4, 6, 1, 3, 2]  0.888264     0.014834   \n",
       "11178  GradientBoostingClassifier  [6, 3, 3, 6, 5]  0.887278     0.013259   \n",
       "11947  GradientBoostingClassifier  [6, 1, 3, 4, 3]  0.886308     0.014434   \n",
       "12042  GradientBoostingClassifier  [6, 6, 3, 3, 4]  0.886092     0.019324   \n",
       "12015  GradientBoostingClassifier  [6, 5, 2, 3, 2]  0.886049     0.019826   \n",
       "11745  GradientBoostingClassifier  [6, 6, 3, 3, 5]  0.886044     0.015896   \n",
       "10983  GradientBoostingClassifier  [6, 1, 6, 3, 5]  0.886021     0.012083   \n",
       "12595            VotingClassifier  [6, 1, 3, 3, 1]  0.885847     0.012231   \n",
       "11442  GradientBoostingClassifier  [4, 5, 2, 3, 1]  0.885764     0.020842   \n",
       "11180  GradientBoostingClassifier  [4, 1, 2, 3, 4]  0.885515     0.012739   \n",
       "11436  GradientBoostingClassifier  [4, 1, 2, 3, 5]  0.885298     0.017266   \n",
       "11996  GradientBoostingClassifier  [6, 4, 2, 3, 4]  0.885120     0.018228   \n",
       "11951  GradientBoostingClassifier  [6, 6, 3, 3, 1]  0.885111     0.014568   \n",
       "11971  GradientBoostingClassifier  [6, 5, 3, 3, 3]  0.884817     0.012312   \n",
       "...                           ...              ...       ...          ...   \n",
       "4149                MLPClassifier  [5, 5, 2, 5, 1]  0.420899     0.051852   \n",
       "3287                MLPClassifier  [3, 3, 6, 3, 3]  0.418700     0.026625   \n",
       "6596           LogisticRegression  [1, 5, 2, 5, 3]  0.417947     0.017671   \n",
       "3288                MLPClassifier  [1, 3, 4, 4, 6]  0.416381     0.031255   \n",
       "3295                MLPClassifier  [2, 3, 5, 2, 6]  0.416257     0.034155   \n",
       "3533                MLPClassifier  [3, 3, 6, 2, 2]  0.415818     0.027738   \n",
       "3365                MLPClassifier  [3, 4, 2, 5, 3]  0.415673     0.032601   \n",
       "3763                MLPClassifier  [5, 3, 1, 2, 3]  0.414745     0.016605   \n",
       "6598           LogisticRegression  [3, 5, 1, 5, 3]  0.412904     0.021819   \n",
       "3685                MLPClassifier  [3, 2, 4, 2, 5]  0.412238     0.012373   \n",
       "3749                MLPClassifier  [5, 3, 6, 2, 3]  0.410608     0.026062   \n",
       "3645                MLPClassifier  [2, 3, 3, 3, 1]  0.407899     0.056991   \n",
       "3584                MLPClassifier  [3, 3, 2, 4, 3]  0.406834     0.044381   \n",
       "3423                MLPClassifier  [3, 4, 4, 2, 3]  0.406629     0.016390   \n",
       "6762           LogisticRegression  [3, 5, 4, 5, 3]  0.405455     0.026371   \n",
       "3805                MLPClassifier  [3, 3, 2, 1, 1]  0.401674     0.034883   \n",
       "3408                MLPClassifier  [3, 1, 3, 2, 2]  0.399112     0.033021   \n",
       "3325                MLPClassifier  [1, 2, 2, 6, 3]  0.395754     0.030398   \n",
       "3324                MLPClassifier  [1, 5, 5, 5, 2]  0.387640     0.021158   \n",
       "3732                MLPClassifier  [5, 2, 5, 2, 3]  0.382944     0.033344   \n",
       "4074                MLPClassifier  [3, 3, 3, 2, 1]  0.382187     0.030844   \n",
       "4001                MLPClassifier  [3, 2, 2, 3, 1]  0.374510     0.080633   \n",
       "3344                MLPClassifier  [3, 6, 2, 2, 3]  0.374359     0.034429   \n",
       "3459                MLPClassifier  [1, 3, 3, 2, 2]  0.362058     0.029904   \n",
       "3792                MLPClassifier  [3, 3, 2, 1, 2]  0.361848     0.044017   \n",
       "3346                MLPClassifier  [3, 2, 1, 5, 3]  0.352261     0.036908   \n",
       "3290                MLPClassifier  [1, 3, 5, 5, 3]  0.341956     0.025560   \n",
       "3885                MLPClassifier  [3, 2, 1, 1, 2]  0.339123     0.048897   \n",
       "3327                MLPClassifier  [3, 2, 1, 3, 3]  0.335920     0.063505   \n",
       "3409                MLPClassifier  [2, 3, 1, 3, 3]  0.305492     0.053533   \n",
       "\n",
       "       errorMetrico  \n",
       "11030      0.212657  \n",
       "11771      0.197149  \n",
       "10039      0.165400  \n",
       "11977      0.208228  \n",
       "11720      0.152818  \n",
       "11798      0.182199  \n",
       "8281       0.165400  \n",
       "11666      0.308226  \n",
       "11763      0.301921  \n",
       "11850      0.190046  \n",
       "11673      0.164364  \n",
       "11909      0.257682  \n",
       "11344      0.254250  \n",
       "11983      0.238841  \n",
       "11739      0.153005  \n",
       "12008      0.210591  \n",
       "11359      0.150411  \n",
       "11178      0.231653  \n",
       "11947      0.238584  \n",
       "12042      0.226000  \n",
       "12015      0.265490  \n",
       "11745      0.200419  \n",
       "10983      0.162775  \n",
       "12595      0.227932  \n",
       "11442      0.261801  \n",
       "11180      0.206111  \n",
       "11436      0.232440  \n",
       "11996      0.187477  \n",
       "11951      0.233112  \n",
       "11971      0.208228  \n",
       "...             ...  \n",
       "4149       1.110714  \n",
       "3287       1.302070  \n",
       "6596       1.199007  \n",
       "3288       1.247378  \n",
       "3295       1.090593  \n",
       "3533       1.273819  \n",
       "3365       1.006360  \n",
       "3763       1.206289  \n",
       "6598       1.177163  \n",
       "3685       1.397320  \n",
       "3749       1.160870  \n",
       "3645       0.760859  \n",
       "3584       1.204363  \n",
       "3423       1.124528  \n",
       "6762       1.113693  \n",
       "3805       0.819911  \n",
       "3408       0.981167  \n",
       "3325       1.331329  \n",
       "3324       1.148850  \n",
       "3732       1.316847  \n",
       "4074       1.037948  \n",
       "4001       0.976625  \n",
       "3344       1.291797  \n",
       "3459       1.083372  \n",
       "3792       0.960726  \n",
       "3346       1.247550  \n",
       "3290       1.514535  \n",
       "3885       0.976625  \n",
       "3327       0.931201  \n",
       "3409       0.890319  \n",
       "\n",
       "[9457 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(lista_resultados).sort_values(['Accuracy'],ascending=False).drop_duplicates(subset=['Modelo', 'Accuracy', 'stdAccuracy', 'errorMetrico'])\n",
    "df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico', 'values', 'error']].to_csv('EDAS_resultados.csv', sep=',', index=False) \n",
    "display(df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11030</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 5]</td>\n",
       "      <td>0.900138</td>\n",
       "      <td>0.016621</td>\n",
       "      <td>0.212657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10039</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.898412</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8281</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.892472</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.165400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12595</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.885847</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.227932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9171</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.878758</td>\n",
       "      <td>0.013924</td>\n",
       "      <td>0.225342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5077</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.863119</td>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.264194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.846975</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.303046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5671</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[6, 1, 2, 6, 1]</td>\n",
       "      <td>0.835653</td>\n",
       "      <td>0.017729</td>\n",
       "      <td>0.466028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2102</th>\n",
       "      <td>SVC</td>\n",
       "      <td>[6, 6, 3, 3, 5]</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.017179</td>\n",
       "      <td>0.361796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.762404</td>\n",
       "      <td>0.014479</td>\n",
       "      <td>0.388520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7293</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[4, 5, 2, 3, 1]</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.017259</td>\n",
       "      <td>0.621471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3618</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 1, 3, 1, 1]</td>\n",
       "      <td>0.657463</td>\n",
       "      <td>0.024820</td>\n",
       "      <td>0.732443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "11030  GradientBoostingClassifier  [6, 1, 2, 3, 5]  0.900138     0.016621   \n",
       "10039      RandomForestClassifier  [6, 1, 3, 3, 5]  0.898412     0.007043   \n",
       "8281         ExtraTreesClassifier  [6, 1, 3, 3, 5]  0.892472     0.013311   \n",
       "12595            VotingClassifier  [6, 1, 3, 3, 1]  0.885847     0.012231   \n",
       "9171           AdaBoostClassifier  [6, 1, 3, 3, 1]  0.878758     0.013924   \n",
       "5077         KNeighborsClassifier  [6, 1, 3, 3, 3]  0.863119     0.012399   \n",
       "3278                   GaussianNB  [6, 1, 3, 3, 1]  0.846975     0.014854   \n",
       "5671       DecisionTreeClassifier  [6, 1, 2, 6, 1]  0.835653     0.017729   \n",
       "2102                          SVC  [6, 6, 3, 3, 5]  0.829563     0.017179   \n",
       "699    LinearDiscriminantAnalysis  [6, 1, 3, 3, 1]  0.762404     0.014479   \n",
       "7293           LogisticRegression  [4, 5, 2, 3, 1]  0.694200     0.017259   \n",
       "3618                MLPClassifier  [4, 1, 3, 1, 1]  0.657463     0.024820   \n",
       "\n",
       "       errorMetrico  \n",
       "11030      0.212657  \n",
       "10039      0.165400  \n",
       "8281       0.165400  \n",
       "12595      0.227932  \n",
       "9171       0.225342  \n",
       "5077       0.264194  \n",
       "3278       0.303046  \n",
       "5671       0.466028  \n",
       "2102       0.361796  \n",
       "699        0.388520  \n",
       "7293       0.621471  \n",
       "3618       0.732443  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#topDf = df.drop_duplicates(subset=['Modelo'])\n",
    "#display(topDf)\n",
    "#pd.DataFrame(salida).sort_values(['Accuracy'], ascending=False)\n",
    "topDf=df.drop_duplicates(subset=['Modelo']).drop_duplicates()\n",
    "topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico', 'values', 'error']].to_csv('EDAS_resultados_unique.csv', sep=',', index=False) \n",
    "display(topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "      <th>values</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 5]</td>\n",
       "      <td>0.900138</td>\n",
       "      <td>0.212657</td>\n",
       "      <td>[0.910891089109, 0.90099009901, 0.925742574257...</td>\n",
       "      <td>[0.0, 0.0, 2.12132034356, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.898412</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>[0.898514851485, 0.905940594059, 0.89356435643...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.892472</td>\n",
       "      <td>0.165400</td>\n",
       "      <td>[0.910891089109, 0.883663366337, 0.87128712871...</td>\n",
       "      <td>[0.0, 0.0, 2.12132034356, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.885847</td>\n",
       "      <td>0.227932</td>\n",
       "      <td>[0.887804878049, 0.892420537897, 0.88264058679...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.878758</td>\n",
       "      <td>0.225342</td>\n",
       "      <td>[0.878048780488, 0.865525672372, 0.87530562347...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.863119</td>\n",
       "      <td>0.264194</td>\n",
       "      <td>[0.841463414634, 0.867970660147, 0.87530562347...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.846975</td>\n",
       "      <td>0.303046</td>\n",
       "      <td>[0.873170731707, 0.863080684597, 0.85574572127...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[6, 1, 2, 6, 1]</td>\n",
       "      <td>0.835653</td>\n",
       "      <td>0.466028</td>\n",
       "      <td>[0.836930455635, 0.846522781775, 0.80769230769...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC</td>\n",
       "      <td>[6, 6, 3, 3, 5]</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.361796</td>\n",
       "      <td>[0.845588235294, 0.833333333333, 0.78624078624...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.762404</td>\n",
       "      <td>0.388520</td>\n",
       "      <td>[0.768292682927, 0.772616136919, 0.76528117359...</td>\n",
       "      <td>[0.0, 0.0, 2.12132034356, 2.12132034356, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[4, 5, 2, 3, 1]</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.621471</td>\n",
       "      <td>[0.702764976959, 0.716589861751, 0.69585253456...</td>\n",
       "      <td>[0.0, 2.12132034356, 0.0, 0.0, 0.0, 2.12132034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 1, 3, 1, 1]</td>\n",
       "      <td>0.657463</td>\n",
       "      <td>0.732443</td>\n",
       "      <td>[0.668112798265, 0.626086956522, 0.66739130434...</td>\n",
       "      <td>[0.0, 0.0, 2.12132034356, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Modelo    Configuracion  Accuracy  errorMetrico  \\\n",
       "0   GradientBoostingClassifier  [6, 1, 2, 3, 5]  0.900138      0.212657   \n",
       "1       RandomForestClassifier  [6, 1, 3, 3, 5]  0.898412      0.165400   \n",
       "2         ExtraTreesClassifier  [6, 1, 3, 3, 5]  0.892472      0.165400   \n",
       "3             VotingClassifier  [6, 1, 3, 3, 1]  0.885847      0.227932   \n",
       "4           AdaBoostClassifier  [6, 1, 3, 3, 1]  0.878758      0.225342   \n",
       "5         KNeighborsClassifier  [6, 1, 3, 3, 3]  0.863119      0.264194   \n",
       "6                   GaussianNB  [6, 1, 3, 3, 1]  0.846975      0.303046   \n",
       "7       DecisionTreeClassifier  [6, 1, 2, 6, 1]  0.835653      0.466028   \n",
       "8                          SVC  [6, 6, 3, 3, 5]  0.829563      0.361796   \n",
       "9   LinearDiscriminantAnalysis  [6, 1, 3, 3, 1]  0.762404      0.388520   \n",
       "10          LogisticRegression  [4, 5, 2, 3, 1]  0.694200      0.621471   \n",
       "11               MLPClassifier  [4, 1, 3, 1, 1]  0.657463      0.732443   \n",
       "\n",
       "                                               values  \\\n",
       "0   [0.910891089109, 0.90099009901, 0.925742574257...   \n",
       "1   [0.898514851485, 0.905940594059, 0.89356435643...   \n",
       "2   [0.910891089109, 0.883663366337, 0.87128712871...   \n",
       "3   [0.887804878049, 0.892420537897, 0.88264058679...   \n",
       "4   [0.878048780488, 0.865525672372, 0.87530562347...   \n",
       "5   [0.841463414634, 0.867970660147, 0.87530562347...   \n",
       "6   [0.873170731707, 0.863080684597, 0.85574572127...   \n",
       "7   [0.836930455635, 0.846522781775, 0.80769230769...   \n",
       "8   [0.845588235294, 0.833333333333, 0.78624078624...   \n",
       "9   [0.768292682927, 0.772616136919, 0.76528117359...   \n",
       "10  [0.702764976959, 0.716589861751, 0.69585253456...   \n",
       "11  [0.668112798265, 0.626086956522, 0.66739130434...   \n",
       "\n",
       "                                                error  \n",
       "0   [0.0, 0.0, 2.12132034356, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2   [0.0, 0.0, 2.12132034356, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...  \n",
       "4   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...  \n",
       "5   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...  \n",
       "7   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9   [0.0, 0.0, 2.12132034356, 2.12132034356, 0.0, ...  \n",
       "10  [0.0, 2.12132034356, 0.0, 0.0, 0.0, 2.12132034...  \n",
       "11  [0.0, 0.0, 2.12132034356, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#column_plot = 'values'\n",
    "\n",
    "#dataframe_plot = topDf\n",
    "def column_boxplot(dataframe_plot, column_plot):\n",
    "    previos = ['LogisticRegression', 'LinearDiscriminantAnalysis', 'GaussianNB', 'MLPClassifier', \n",
    "               'SVC', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', \n",
    "               'ExtraTreesClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier', 'VotingClassifier']\n",
    "    nuevos = ['LoR', 'LDA', 'GNB', 'MLP', 'SVC', 'DT', 'k-NN', 'RF', 'ET', 'GBM', 'AB', 'VC']\n",
    "    num_models = len(nuevos)\n",
    "    num_splits = 10\n",
    "    dataframe_plot = dataframe_plot[['Modelo', 'Configuracion', 'Accuracy', 'errorMetrico', 'values', 'error']]\n",
    "    for i in range(12):\n",
    "        dataframe_plot['Modelo'] = dataframe_plot['Modelo'].str.replace(previos[i], nuevos[i])\n",
    "        #df['Modelo'] = df['Modelo'].str.replace('LinearDiscriminantAnalysis','LDA')\n",
    "    sorterIndex = dict(zip(nuevos,range(num_models)))\n",
    "    #test\n",
    "    dataframe_plot['Model_Rank'] = dataframe_plot['Modelo'].map(sorterIndex)\n",
    "    dataframe_plot = dataframe_plot.sort_values(['Model_Rank'],ascending=True).reset_index(drop=True)[dataframe_plot.columns[:-1]]\n",
    "    lista_plot = []\n",
    "    for i in range(num_models):\n",
    "        for j in range(num_splits):\n",
    "            d = {'Model':nuevos[i], 'Score':dataframe_plot[column_plot][i][j]}\n",
    "            lista_plot.append(d)\n",
    "    #pd.DataFrame(lista_plot)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    ax_plot = sns.boxplot(data=pd.DataFrame(lista_plot), x=\"Model\", y=\"Score\", linewidth = 1.0)\n",
    "    plt.format='eps'\n",
    "    if column_plot == 'values':\n",
    "        medians = np.round(list(dataframe_plot['Accuracy']),3)\n",
    "        tope = 0.98\n",
    "    else:\n",
    "        medians = np.round(list(dataframe_plot['errorMetrico']),3)\n",
    "        tope = 6.5\n",
    "    median_labels = [str(s) for s in medians]\n",
    "    pos = range(num_models)\n",
    "    for tick,label in zip(pos,ax_plot.get_xticklabels()):\n",
    "        ax_plot.text(pos[tick], tope, median_labels[tick], \n",
    "                horizontalalignment='center', color='black') #, weight='semibold'\n",
    "    axes = plt.gca()\n",
    "    if column_plot == 'values':\n",
    "        axes.set_ylim([0.3,1.0])\n",
    "    #else:\n",
    "    #    axes.set_ylim([0, 4])\n",
    "    plt.savefig('destination_path.eps')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_boxplot(topDf, 'values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_boxplot(topDf, 'errores')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
