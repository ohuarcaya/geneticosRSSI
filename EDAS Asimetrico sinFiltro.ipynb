{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Librería Genética\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Subfunciones de estimadores\n",
    "from sklearn.base import clone\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][30]\n",
    "from sklearn.base import is_classifier\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][535]\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_validation.py][346]\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][386]\n",
    "from sklearn.model_selection._search import check_cv\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_split.py][1866]\n",
    "from sklearn.model_selection._search import _check_param_grid\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][343]\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/scorer.py][250]\n",
    "from sklearn.utils.validation import _num_samples\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][105]\n",
    "from sklearn.utils.validation import indexable\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][208]\n",
    "from multiprocessing import Pool, Manager, cpu_count\n",
    "#from itertools import product\n",
    "import itertools as it #import product\n",
    "\n",
    "# Selección para estimadores\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metricas para estimadores\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Estimadores\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Ensembles algorithms\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find distance error al 0.2%\n",
    "def distance_error(estimator, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 7)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    # coord pred\n",
    "    x1 = np.int32((y_pred + 2) % 3)\n",
    "    y1 = np.int32((y_pred - 1) / 3)\n",
    "    # coord real\n",
    "    x2 = np.int32((y_test + 2) % 3)\n",
    "    y2 = np.int32((y_test - 1) / 3)\n",
    "    # pasar variacion a distancias metros\n",
    "    vx = np.abs(x1 - x2)*1.5\n",
    "    vy = np.abs(y1 - y2)*1.5\n",
    "    #vx = vx*0.5 + (vx-1)*(vx>0)\n",
    "    #vy = vy*0.5 + (vy-1)*(vy>0)\n",
    "    # pitagoras\n",
    "    err_distance = np.sqrt(vx*vx + vy*vy)\n",
    "    return err_distance\n",
    "\n",
    "#def _createDataset(frecuencias, values, seed = 7):\n",
    "def _createDataset(frecuencias, values):\n",
    "    # crear dataset\n",
    "    names_ = frecuencias[0].columns.values\n",
    "    seed = 7\n",
    "    # reestructuracion\n",
    "    salida_final = pd.DataFrame(columns=names_)\n",
    "    for sec in range(1,16):\n",
    "        dataset = pd.DataFrame(columns=names_)\n",
    "        corte = min([frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values])\n",
    "        #l = [frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values]\n",
    "        #corte = max(l)\n",
    "        #tx=l.index(max(l))\n",
    "        tx = 0\n",
    "        dataset[names_[tx]] = dataset[names_[tx]].append(frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]])\n",
    "        dataset = dataset.reset_index(drop=True)\n",
    "        for tx in range(1,5):\n",
    "            dataset[names_[tx]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]].reset_index(drop=True)\n",
    "        dataset[names_[tx+1]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx+1]].reset_index(drop=True)\n",
    "        # join parts\n",
    "        salida_final = salida_final.append(dataset)\n",
    "    # shuffle dataset\n",
    "    salida_final = shuffle(salida_final, random_state=seed).reset_index(drop=True)\n",
    "    salida_final = salida_final.apply(pd.to_numeric)\n",
    "    # dataframe to X,y \n",
    "    X = salida_final[names_[:-1]]\n",
    "    y = salida_final[names_[-1]]\n",
    "    return X,y\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    # LDA : Warning(Variables are collinear)\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('SVC', SVC(random_state=rs)))\n",
    "    models.append(('GaussianNB', GaussianNB()))\n",
    "    models.append(('MLPClassifier', MLPClassifier()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=rs)))\n",
    "    models.append(('LogisticRegression', LogisticRegression()))\n",
    "    # Bagging and Boosting\n",
    "    # models.append(('ExtraTreesClassifier', ExtraTreesClassifier(n_estimators=150)))\n",
    "    models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state=rs)))\n",
    "    models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier(random_state=rs),\n",
    "                                                            random_state=rs)))\n",
    "    # models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier())))\n",
    "    models.append(('RandomForestClassifier', RandomForestClassifier(random_state=rs)))\n",
    "    models.append(('GradientBoostingClassifier',\n",
    "                   GradientBoostingClassifier(random_state=rs)))\n",
    "    # models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "    # Voting\n",
    "    estimators = []\n",
    "    estimators.append((\"Voting_GradientBoostingClassifier\", GradientBoostingClassifier(random_state=rs)))\n",
    "    estimators.append((\"Voting_ExtraTreesClassifier\", ExtraTreesClassifier(random_state=rs)))\n",
    "    voting = VotingClassifier(estimators)\n",
    "    models.append(('VotingClassifier', voting))\n",
    "    return models\n",
    "\n",
    "# The problem to optimize\n",
    "def getAccuracy( frecuencias, individual, estimator, score_cache, resultados ):\n",
    "\tX,y = _createDataset(frecuencias, individual)\n",
    "\t#print(X)\n",
    "\t#print\n",
    "\t#print\n",
    "\t#print(y)\n",
    "\tscore = 0\n",
    "\tscorer = \"accuracy\"\n",
    "\tname = str(estimator).split('(')[0]\n",
    "\tparamkey = str(np.int32(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=10, shuffle=False)\n",
    "\t\tcv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scorer)\n",
    "\t\t#print(name,\"  \",paramkey,\"   \")\n",
    "\t\t#print(len(X),\"  \",len(y),\"   \", kfold)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\tdesv = cv_results.std()\n",
    "\t\terror = distance_error(estimator, X, y)\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\tdict_result = {'Modelo': name, 'Configuracion':np.int32(individual)+1, 'values': cv_results, 'Accuracy': score, 'stdAccuracy': desv, 'errorMetrico': np.mean(error), 'error': error }\n",
    "\t\tresultados.append(dict_result)\n",
    "\treturn score\n",
    "\"\"\"\n",
    "def _evalFunction(individual, frecuencias, scorer, num_folds, score_cache, desv_cache, error_cache, resultados_cache):\n",
    "\tX, y = _individual_to_params(frecuencias, individual)\n",
    "\tscore = 0\n",
    "\tn_test = 0\n",
    "\tname = str(individual.est).split('(')[0]\n",
    "\tparamkey = str(np.array(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=10, shuffle=False)\n",
    "\t\t#cv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scoring)\n",
    "\t\tcv_results = cross_val_score(individual.est, X, y, cv=kfold, scoring=scorer)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\tdesv_cache[paramkey] = cv_results.std()\n",
    "\t\terror_cache[paramkey] = distance_error(individual.est, X, y)\n",
    "\t\tresults = {'Modelo': name, 'Configuracion':np.int32(individual)+1, 'values': cv_results, 'Accuracy': score, 'stdAccuracy': desv_cache[paramkey], 'errorMetrico': error_cache[paramkey]}  \n",
    "\t\tresultados_cache.append(results)\n",
    "\treturn (score,)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class eda:\n",
    "\tdef __init__(self, of, frecuencias, estimator):\n",
    "\t\t# Algorithm parameters\n",
    "\t\tself.iterations = 12\n",
    "\t\tself.sample_size = 100\n",
    "\t\tself.select_ratio = 0.5\n",
    "\t\tself.epsilon = 10e-6\n",
    "\n",
    "\t\t# class members\n",
    "\t\tself.objective_function = of\n",
    "\t\tself.dimensions = 5\n",
    "\t\tself.sample = []\n",
    "\t\tself.means = []\n",
    "\t\tself.stdevs = []\t\n",
    "\n",
    "\t\tself.debug = False\n",
    "\t\t# aditional parameters\n",
    "\t\tself.frecuencias = frecuencias\n",
    "\t\tself.estimator = estimator\n",
    "\t\tself.__manager = Manager()\n",
    "\t\tself.score_cache = {}\n",
    "\t\tself.resultados = self.__manager.list()\n",
    "\t\tself.n_jobs = cpu_count()\n",
    "        \n",
    "\n",
    "\tdef sample_sort(self): \n",
    "\t\t# sort rows on the last column\n",
    "\t\tself.sample = self.sample[ np.argsort( self.sample[:,-1], 0 ) ]\n",
    "\n",
    "\n",
    "\tdef dispersion_reduction(self):\n",
    "\t\tself.sample_sort()\n",
    "\n",
    "\t\t# number of points to select\n",
    "\t\tnb = int( np.floor( self.sample_size * self.select_ratio ) )\n",
    "\n",
    "\t\t# selection\n",
    "\t\t#self.sample = self.sample[:nb]\n",
    "\t\tself.sample = self.sample[self.sample_size-nb:]\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"dispersion reduction\")\n",
    "\t\t\tprint (str(self.sample))\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef estimate_parameters( self ):\n",
    "\t\t# points sub array (without values)\n",
    "\t\tmat = self.sample[:,:self.dimensions]\n",
    "\t\t\n",
    "\t\t# row means (axis 0 in scipy)\n",
    "\t\tself.means = np.mean( mat, 0 )\n",
    "\t\t\n",
    "\t\t# row standard deviation\n",
    "\t\tself.stdevs = np.std( mat, 0 )\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"estimate parameters\")\n",
    "\t\t\tprint (\"\\tmean=\" +str(self.means))\n",
    "\t\t\tprint (\"\\tstd-dev=\" + str(self.stdevs))\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef draw_sample(self):\n",
    "\t\t# for each variable to optimize\n",
    "\t\tfor i in range(self.dimensions):\n",
    "\t\t\t# if the dispersion is null\n",
    "\t\t\tif self.stdevs[i] == 0.0:\n",
    "\t\t\t\t# set it to a minimal value\n",
    "\t\t\t\tself.stdevs[i] = self.epsilon\n",
    "\t\t\n",
    "\t\t# empty sample\n",
    "\t\tself.sample = np.zeros( (self.sample_size, self.dimensions+1) )\n",
    "\t\t\n",
    "\t\t# for each point\n",
    "\t\tfor i in range( self.sample_size ):\n",
    "\t\t\t# draw in random normal\n",
    "\t\t\tp = np.random.normal( self.means, self.stdevs )\n",
    "\t\t\tp = np.array([0 if i<0 else (5 if i>5 else i) for i in p])\n",
    "\t\t\t# put it into the sample\n",
    "\t\t\tself.sample[i][:self.dimensions] = np.round(p)%(self.dimensions+1)\n",
    "\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"draw sample\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef evaluate(self):\n",
    "\t\t# for each point\n",
    "\t\t\"\"\"\n",
    "\t\tfor i in range( self.sample_size ):\n",
    "\t\t\td = self.dimensions\n",
    "\t\t\t# call the objective function\n",
    "\t\t\t#   the third element is the result of the objective function call\n",
    "\t\t\t#   taking the first two elements as variables\n",
    "\t\t\t#r = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache )\n",
    "\t\t\t#self.sample[i][-1] = r\n",
    "\t\t\tself.sample[i][-1] = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache , self.resultados)\n",
    "\t\t\"\"\"\n",
    "\t\td = self.dimensions\n",
    "\t\t_pool = Pool(self.n_jobs)\n",
    "\t\t#self.sample[i][-1] = self.objective_function( self.frecuencias, self.sample[i][:d], self.estimator, self.score_cache , self.resultados)\n",
    "\t\t_iterable = it.product([self.frecuencias], np.int32(self.sample[:,:d]), [self.estimator], [self.score_cache], [self.resultados])\n",
    "\t\tself.sample[:,-1] = _pool.starmap(self.objective_function, _iterable)\n",
    "\t\t_pool.close()\n",
    "\t\t_pool.join()\n",
    "\t\t#getAccuracy( frecuencias, individual, estimator, score_cache, resultados ):\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"evaluate\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\n",
    "\tdef run(self):\n",
    "\t\t# uniform initialization\n",
    "\t\tself.sample = np.random.rand( self.sample_size, self.dimensions+1 )\n",
    "\t\t# cosmetic\n",
    "\t\t#self.sample = self.sample * 200 - 100\n",
    "\t\ttop_freq = 6\n",
    "\t\tself.sample = np.floor(np.random.rand(self.sample_size, self.dimensions +1)*top_freq)\n",
    "\t\t\n",
    "\t\tif self.debug:\n",
    "\t\t\tprint (\"initialization\")\n",
    "\t\t\tprint (self.sample)\n",
    "\t\t\tprint\n",
    "\n",
    "\t\tself.evaluate()\n",
    "\n",
    "\t\t# Multi process\n",
    "\t\t\n",
    "\t\ti = 0\n",
    "\t\twhile i < self.iterations:\n",
    "\t\t\tif self.debug:\n",
    "\t\t\t\tprint (\"iteration\",i)\n",
    "\t\t\t\tprint\n",
    "\n",
    "\t\t\ti += 1\n",
    "\t\t\tself.dispersion_reduction()\n",
    "\t\t\tprint(\"iter[\"+str(i)+\"]-top1: \"+str(self.sample[-1]))\n",
    "\t\t\tself.estimate_parameters()\n",
    "\t\t\tself.draw_sample()\n",
    "\t\t\tself.evaluate()\n",
    "\t\t\t# print top 1\n",
    "\t\t\tself.sample_sort()\n",
    "\n",
    "\t\t# sort the final sample\n",
    "\t\tself.sample_sort()\n",
    "\t\t# output the optimum\n",
    "\t\t#self.pool.close()\n",
    "\t\t#self.pool.join()\n",
    "\t\tranking = self.sample_size\n",
    "\t\t#print (\"#[ Configuración ]\\t Accuracy\")\n",
    "\t\t#for i in range(ranking):\n",
    "\t\t#\tlinea = str(self.sample[-i-1][:-1]+1) + \"\\t\" +str(self.sample[-i-1][-1])\n",
    "\t\t#\tprint(linea)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "frecuencias = []\n",
    "names_ = ['Be01', 'Be02', 'Be03', 'Be04', 'Be05', 'Sector']\n",
    "\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x01'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x02'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x03'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x04'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x05'))#, names=names_))\n",
    "frecuencias.append(pd.read_csv('sinFiltro/Tx_0x06'))#, names=names_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modeling... LinearDiscriminantAnalysis\n",
      "iter[1]-top1: [ 5.          0.          5.          3.          4.          0.73232657]\n",
      "iter[2]-top1: [ 5.         0.         2.         2.         3.         0.7193154]\n",
      "iter[3]-top1: [ 3.          5.          3.          2.          0.          0.71051345]\n",
      "iter[4]-top1: [ 5.          0.          3.          2.          1.          0.71540342]\n",
      "iter[5]-top1: [ 4.          0.          2.          2.          0.          0.73586274]\n",
      "iter[6]-top1: [ 3.          5.          1.          2.          0.          0.71466993]\n",
      "iter[7]-top1: [ 5.          4.          2.          2.          0.          0.71184741]\n",
      "iter[8]-top1: [ 5.          4.          3.          2.          0.          0.72911702]\n",
      "iter[9]-top1: [ 3.          4.          3.          2.          0.          0.73135663]\n",
      "iter[10]-top1: [ 3.          4.          3.          2.          0.          0.73135663]\n",
      "iter[11]-top1: [ 3.          4.          3.          2.          0.          0.73135663]\n",
      "iter[12]-top1: [ 5.          4.          3.          2.          0.          0.72911702]\n",
      "\n",
      "Modeling... SVC\n",
      "iter[1]-top1: [ 5.         5.         3.         2.         0.         0.8190709]\n",
      "iter[2]-top1: [ 5.          2.          1.          2.          4.          0.81310883]\n",
      "iter[3]-top1: [ 5.          2.          2.          2.          2.          0.80664214]\n",
      "iter[4]-top1: [ 5.          4.          2.          2.          2.          0.79764597]\n",
      "iter[5]-top1: [ 5.          5.          2.          2.          0.          0.81030711]\n",
      "iter[6]-top1: [ 5.          4.          1.          2.          3.          0.81478116]\n",
      "iter[7]-top1: [ 5.        5.        2.        2.        1.        0.809553]\n",
      "iter[8]-top1: [ 5.         5.         3.         2.         0.         0.8190709]\n",
      "iter[9]-top1: [ 5.          5.          2.          2.          4.          0.82956292]\n",
      "iter[10]-top1: [ 5.          2.          2.          2.          0.          0.81666647]\n",
      "iter[11]-top1: [ 5.          2.          2.          2.          4.          0.82367213]\n",
      "iter[12]-top1: [ 5.          5.          2.          2.          2.          0.82117527]\n",
      "\n",
      "Modeling... GaussianNB\n",
      "iter[1]-top1: [ 5.          0.          2.          5.          4.          0.84540022]\n",
      "iter[2]-top1: [ 5.          4.          3.          2.          0.          0.82602634]\n",
      "iter[3]-top1: [ 5.          0.          3.          2.          1.          0.82469438]\n",
      "iter[4]-top1: [ 5.          0.          2.          2.          5.          0.82766951]\n",
      "iter[5]-top1: [ 5.          4.          0.          3.          0.          0.81184261]\n",
      "iter[6]-top1: [ 5.          0.          0.          2.          1.          0.82472777]\n",
      "iter[7]-top1: [ 5.          3.          3.          2.          0.          0.82273839]\n",
      "iter[8]-top1: [ 5.          0.          3.          2.          0.          0.84376528]\n",
      "iter[9]-top1: [ 5.          0.          3.          2.          0.          0.84376528]\n",
      "iter[10]-top1: [ 5.          5.          2.          2.          0.          0.82131254]\n",
      "iter[11]-top1: [ 5.          0.          2.          2.          0.          0.84697477]\n",
      "iter[12]-top1: [ 5.          3.          3.          2.          0.          0.82273839]\n",
      "\n",
      "Modeling... MLPClassifier\n",
      "iter[1]-top1: [ 3.          0.          1.          4.          0.          0.62585034]\n",
      "iter[2]-top1: [ 5.          0.          1.          3.          0.          0.63278627]\n",
      "iter[3]-top1: [ 5.          0.          1.          0.          4.          0.64896567]\n",
      "iter[4]-top1: [ 3.          0.          1.          2.          0.          0.65370032]\n",
      "iter[5]-top1: [ 5.          0.          3.          0.          0.          0.65489301]\n",
      "iter[6]-top1: [ 5.          0.          3.          3.          0.          0.65632379]\n",
      "iter[7]-top1: [ 3.          0.          1.          0.          0.          0.67226098]\n",
      "iter[8]-top1: [ 5.          0.          3.          0.          0.          0.64912724]\n",
      "iter[9]-top1: [ 4.          0.          3.          5.          0.          0.65059447]\n",
      "iter[10]-top1: [ 5.          0.          3.          0.          0.          0.65801167]\n",
      "iter[11]-top1: [ 3.          0.          3.          0.          0.          0.67731429]\n",
      "iter[12]-top1: [ 3.          0.          1.          0.          0.          0.67857407]\n",
      "\n",
      "Modeling... KNeighborsClassifier\n",
      "iter[1]-top1: [ 5.          0.          1.          0.          4.          0.85200453]\n",
      "iter[2]-top1: [ 5.          0.          2.          2.          2.          0.86311945]\n",
      "iter[3]-top1: [ 3.          0.          1.          5.          4.          0.84510883]\n",
      "iter[4]-top1: [ 5.          0.          1.          2.          0.          0.86629018]\n",
      "iter[5]-top1: [ 5.          0.          1.          0.          0.          0.85848148]\n",
      "iter[6]-top1: [ 5.          0.          2.          2.          2.          0.86311945]\n",
      "iter[7]-top1: [ 5.          0.          2.          2.          1.          0.85553104]\n",
      "iter[8]-top1: [ 5.          3.          1.          2.          0.          0.85354523]\n",
      "iter[9]-top1: [ 5.          0.          2.          3.          0.          0.85476773]\n",
      "iter[10]-top1: [ 5.          0.          2.          2.          1.          0.85553104]\n",
      "iter[11]-top1: [ 5.          0.          1.          2.          0.          0.86629018]\n",
      "iter[12]-top1: [ 5.          3.          1.          2.          0.          0.85354523]\n",
      "\n",
      "Modeling... DecisionTreeClassifier\n",
      "iter[1]-top1: [ 3.          0.          3.          2.          0.          0.80721541]\n",
      "iter[2]-top1: [ 5.          0.          1.          5.          1.          0.81546071]\n",
      "iter[3]-top1: [ 5.          5.          5.          2.          1.          0.81390195]\n",
      "iter[4]-top1: [ 5.          0.          2.          2.          2.          0.83720675]\n",
      "iter[5]-top1: [ 5.          4.          1.          5.          0.          0.82436358]\n",
      "iter[6]-top1: [ 5.          3.          5.          0.          1.          0.82072381]\n",
      "iter[7]-top1: [ 5.          0.          3.          2.          3.          0.82665037]\n",
      "iter[8]-top1: [ 5.          0.          1.          2.          3.          0.82958435]\n",
      "iter[9]-top1: [ 5.          3.          1.          2.          1.          0.81653189]\n",
      "iter[10]-top1: [ 5.          4.          1.          5.          0.          0.82436358]\n",
      "iter[11]-top1: [ 5.          5.          2.          2.          1.          0.82141035]\n",
      "iter[12]-top1: [ 5.          4.          1.          5.          0.          0.82436358]\n",
      "\n",
      "Modeling... LogisticRegression\n",
      "iter[1]-top1: [ 5.          0.          0.          2.          4.          0.66551851]\n",
      "iter[2]-top1: [ 5.          0.          2.          3.          4.          0.66717072]\n",
      "iter[3]-top1: [ 3.          3.          3.          3.          0.          0.65532173]\n",
      "iter[4]-top1: [ 5.          0.          1.          2.          4.          0.69995332]\n",
      "iter[5]-top1: [ 5.          3.          1.          0.          4.          0.66676195]\n",
      "iter[6]-top1: [ 5.          0.          1.          2.          3.          0.67237164]\n",
      "iter[7]-top1: [ 5.          4.          3.          3.          0.          0.66820977]\n",
      "iter[8]-top1: [ 5.          4.          3.          0.          0.          0.66602785]\n",
      "iter[9]-top1: [ 5.          4.          3.          3.          0.          0.66820977]\n",
      "iter[10]-top1: [ 5.          4.          3.          0.          0.          0.66602785]\n",
      "iter[11]-top1: [ 5.          4.          3.          2.          0.          0.67509889]\n",
      "iter[12]-top1: [ 5.          4.          3.          2.          0.          0.67509889]\n",
      "\n",
      "Modeling... ExtraTreesClassifier\n",
      "iter[1]-top1: [ 3.          5.          0.          2.          5.          0.85696822]\n",
      "iter[2]-top1: [ 3.          0.          2.          2.          4.          0.86868382]\n",
      "iter[3]-top1: [ 5.          4.          0.          0.          4.          0.84539947]\n",
      "iter[4]-top1: [ 5.         4.         2.         2.         2.         0.8678759]\n",
      "iter[5]-top1: [ 5.          3.          0.          2.          4.          0.86047834]\n",
      "iter[6]-top1: [ 5.          3.          2.          2.          0.          0.86479218]\n",
      "iter[7]-top1: [ 5.          2.          2.          2.          2.          0.86526893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter[8]-top1: [ 5.          4.          1.          2.          1.          0.86198511]\n",
      "iter[9]-top1: [ 5.          5.          2.          2.          1.          0.86794295]\n",
      "iter[10]-top1: [ 5.          5.          2.          2.          1.          0.86794295]\n",
      "iter[11]-top1: [ 5.          5.          2.          2.          1.          0.86794295]\n",
      "iter[12]-top1: [ 5.          5.          2.          2.          1.          0.86794295]\n",
      "\n",
      "Modeling... AdaBoostClassifier\n",
      "iter[1]-top1: [ 5.          0.          1.          0.          0.          0.86376188]\n",
      "iter[2]-top1: [ 5.          3.          2.          2.          1.          0.86718482]\n",
      "iter[3]-top1: [ 5.          0.          2.          3.          1.          0.85452323]\n",
      "iter[4]-top1: [ 3.          5.          5.          5.          5.          0.85227299]\n",
      "iter[5]-top1: [ 5.          0.          2.          2.          2.          0.87314151]\n",
      "iter[6]-top1: [ 5.          4.          3.          2.          1.          0.85973346]\n",
      "iter[7]-top1: [ 5.          4.          2.          3.          4.          0.86244098]\n",
      "iter[8]-top1: [ 5.          3.          1.          2.          4.          0.86022908]\n",
      "iter[9]-top1: [ 5.          3.          2.          2.          0.          0.86381418]\n",
      "iter[10]-top1: [ 5.          4.          3.          2.          4.          0.86857988]\n",
      "iter[11]-top1: [ 5.          4.          3.          2.          4.          0.86857988]\n",
      "iter[12]-top1: [ 5.          0.          1.          2.          2.          0.86604806]\n",
      "\n",
      "Modeling... RandomForestClassifier\n",
      "iter[1]-top1: [ 5.          0.          1.          0.          5.          0.87121668]\n",
      "iter[2]-top1: [ 2.          0.          2.          5.          4.          0.86397624]\n",
      "iter[3]-top1: [ 5.          0.          2.          1.          4.          0.87314264]\n",
      "iter[4]-top1: [ 5.         0.         2.         2.         2.         0.8834039]\n",
      "iter[5]-top1: [ 5.          2.          2.          2.          4.          0.87131751]\n",
      "iter[6]-top1: [ 5.         0.         0.         2.         3.         0.8801956]\n",
      "iter[7]-top1: [ 5.         0.         2.         2.         2.         0.8834039]\n",
      "iter[8]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[9]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[10]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[11]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "iter[12]-top1: [ 5.          3.          2.          2.          1.          0.87373352]\n",
      "\n",
      "Modeling... GradientBoostingClassifier\n",
      "iter[1]-top1: [ 5.        0.        0.        2.        3.        0.899511]\n",
      "iter[2]-top1: [ 2.          0.          2.          5.          4.          0.88899713]\n",
      "iter[3]-top1: [ 5.          0.          2.          4.          4.          0.88651144]\n",
      "iter[4]-top1: [ 5.          4.          2.          3.          4.          0.89019728]\n",
      "iter[5]-top1: [ 3.          0.          1.          5.          4.          0.88843305]\n",
      "iter[6]-top1: [ 3.          0.          2.          2.          4.          0.88506508]\n",
      "iter[7]-top1: [ 3.          0.          1.          5.          3.          0.88320651]\n",
      "iter[8]-top1: [ 5.          0.          2.          5.          3.          0.88679707]\n",
      "iter[9]-top1: [ 5.          0.          2.          2.          4.          0.91451981]\n",
      "iter[10]-top1: [ 5.          4.          1.          2.          3.          0.89756468]\n",
      "iter[11]-top1: [ 5.          0.          2.          5.          4.          0.90931381]\n",
      "iter[12]-top1: [ 5.          4.          2.          3.          4.          0.89019728]\n",
      "\n",
      "Modeling... VotingClassifier\n",
      "iter[1]-top1: [ 5.          0.          2.          5.          2.          0.87387143]\n",
      "iter[2]-top1: [ 5.          5.          2.          2.          4.          0.87032567]\n",
      "iter[3]-top1: [ 3.          0.          3.          5.          0.          0.87815613]\n",
      "iter[4]-top1: [ 5.          0.          1.          2.          4.          0.88626883]\n",
      "iter[5]-top1: [ 5.          4.          1.          2.          4.          0.86690153]\n",
      "iter[6]-top1: [ 5.          4.          1.          2.          3.          0.87422857]\n",
      "iter[7]-top1: [ 5.         3.         1.         2.         1.         0.8712981]\n",
      "iter[8]-top1: [ 5.          2.          2.          2.          2.          0.87568937]\n",
      "iter[9]-top1: [ 5.          2.          2.          2.          4.          0.88236197]\n",
      "iter[10]-top1: [ 5.          2.          2.          2.          4.          0.88236197]\n",
      "iter[11]-top1: [ 5.          4.          2.          2.          2.          0.87523968]\n",
      "iter[12]-top1: [ 5.          4.          2.          2.          2.          0.87523968]\n"
     ]
    }
   ],
   "source": [
    "#n_neighbors = 5 7 11\n",
    "#weights = 'distance'\n",
    "#algorithm = 'kd_tree' 'ball_tree'\n",
    "#estimator = KNeighborsClassifier(n_jobs=8, weights = 'distance', n_neighbors = 5, algorithm = 'kd_tree')\n",
    "#a = eda( getAccuracy, frecuencias, estimator )\n",
    "#a.run()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    return models\n",
    "\"\"\"\n",
    "estimadores = set_models()\n",
    "\n",
    "#reserva = {}\n",
    "lista_resultados = []\n",
    "for name, model in estimadores:\n",
    "    print(\"\\nModeling...\", name)\n",
    "    splits = 10\n",
    "    #simetricas = [[i]*5 for i in range(6)]\n",
    "    #for individual in simetricas:\n",
    "    #acc, desv, err = evaluate(frecuencias, individual, model)\n",
    "    #salida[str(name)+\"-\"+str(individual)] = str(acc) + \"-\"+ str(desv) + \"-\" + str(err)\n",
    "    #print(name,\" \", individual, \"\\t\", acc, \"\\t\", desv, \"\\t\", err)\n",
    "    #gs = EvolutiveSearchCV(estimator=model, scoring=\"accuracy\", num_folds=10, n_jobs=num_jobs,\n",
    "    #                    verbose=True, refit=True, \n",
    "    #                    population_size=100, \n",
    "    #                    gene_mutation_prob=0.3, \n",
    "    #                    gene_crossover_prob=0.5,\n",
    "    #                    tournament_size=4,\n",
    "    #                    generations_number=10)\n",
    "    a = eda( getAccuracy, frecuencias, model )\n",
    "    a.run()\n",
    "    #gs.fit(frecuencias)\n",
    "    #reserva[name]=(gs.score_cache, gs.desv_cache , gs.error_cache)\n",
    "    lista_resultados = lista_resultados + list(a.resultados)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13710</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.185316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13885</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 5]</td>\n",
       "      <td>0.909314</td>\n",
       "      <td>0.015718</td>\n",
       "      <td>0.192849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12932</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 3, 4]</td>\n",
       "      <td>0.899511</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.213565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13766</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 2, 3, 4]</td>\n",
       "      <td>0.897565</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.253806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13834</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[4, 1, 3, 6, 5]</td>\n",
       "      <td>0.894677</td>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.232884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13663</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 4, 3, 4]</td>\n",
       "      <td>0.893399</td>\n",
       "      <td>0.015777</td>\n",
       "      <td>0.247722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13659</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 3, 3, 3, 3]</td>\n",
       "      <td>0.890230</td>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.309097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13197</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 3, 4, 5]</td>\n",
       "      <td>0.890197</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.397993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[3, 1, 3, 6, 5]</td>\n",
       "      <td>0.888997</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.251329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 1, 4]</td>\n",
       "      <td>0.888728</td>\n",
       "      <td>0.019052</td>\n",
       "      <td>0.239938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[4, 1, 2, 6, 5]</td>\n",
       "      <td>0.888433</td>\n",
       "      <td>0.014720</td>\n",
       "      <td>0.273324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13781</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 2]</td>\n",
       "      <td>0.888287</td>\n",
       "      <td>0.012881</td>\n",
       "      <td>0.249248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 6, 2]</td>\n",
       "      <td>0.887072</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.263528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14088</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 3]</td>\n",
       "      <td>0.887071</td>\n",
       "      <td>0.018922</td>\n",
       "      <td>0.237948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13667</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 6, 4]</td>\n",
       "      <td>0.886797</td>\n",
       "      <td>0.015271</td>\n",
       "      <td>0.256995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14037</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 5, 5]</td>\n",
       "      <td>0.886511</td>\n",
       "      <td>0.019177</td>\n",
       "      <td>0.279001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13249</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 4, 3]</td>\n",
       "      <td>0.886308</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>0.264331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14464</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 5]</td>\n",
       "      <td>0.886269</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.262776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13359</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[4, 1, 3, 3, 5]</td>\n",
       "      <td>0.885065</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.263297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13296</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 3, 6, 5]</td>\n",
       "      <td>0.884823</td>\n",
       "      <td>0.011447</td>\n",
       "      <td>0.378032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13357</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 4, 3, 3, 3]</td>\n",
       "      <td>0.884396</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>0.287472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13102</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 6, 1, 3, 4]</td>\n",
       "      <td>0.884352</td>\n",
       "      <td>0.015074</td>\n",
       "      <td>0.314145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12917</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 6, 6, 1, 5]</td>\n",
       "      <td>0.884290</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.335713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14081</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 1, 5, 5]</td>\n",
       "      <td>0.883553</td>\n",
       "      <td>0.023536</td>\n",
       "      <td>0.302603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11924</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.883404</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>0.253545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13541</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[4, 1, 2, 6, 4]</td>\n",
       "      <td>0.883207</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.228999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13730</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 2, 6, 3]</td>\n",
       "      <td>0.883155</td>\n",
       "      <td>0.013181</td>\n",
       "      <td>0.210433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14020</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 4, 6, 4]</td>\n",
       "      <td>0.882966</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.252833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13974</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 2, 6, 2]</td>\n",
       "      <td>0.882644</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.273048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12942</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 5, 4, 3, 6]</td>\n",
       "      <td>0.882582</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>0.317966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 4, 6, 4, 3]</td>\n",
       "      <td>0.425824</td>\n",
       "      <td>0.035387</td>\n",
       "      <td>1.551527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 5, 2, 1]</td>\n",
       "      <td>0.425169</td>\n",
       "      <td>0.051252</td>\n",
       "      <td>1.279422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[4, 2, 1, 5, 4]</td>\n",
       "      <td>0.424943</td>\n",
       "      <td>0.022083</td>\n",
       "      <td>1.456938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 3, 6, 3]</td>\n",
       "      <td>0.423095</td>\n",
       "      <td>0.036652</td>\n",
       "      <td>1.849872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 1, 2, 4]</td>\n",
       "      <td>0.422120</td>\n",
       "      <td>0.033957</td>\n",
       "      <td>1.485792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 4, 2, 3]</td>\n",
       "      <td>0.421569</td>\n",
       "      <td>0.030007</td>\n",
       "      <td>1.626150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3872</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 5, 1, 5, 2]</td>\n",
       "      <td>0.420686</td>\n",
       "      <td>0.019816</td>\n",
       "      <td>1.588580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[3, 2, 2, 5, 3]</td>\n",
       "      <td>0.420189</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>1.768278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[5, 2, 5, 2, 3]</td>\n",
       "      <td>0.419962</td>\n",
       "      <td>0.017596</td>\n",
       "      <td>1.585194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8167</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[5, 2, 4, 5, 3]</td>\n",
       "      <td>0.419086</td>\n",
       "      <td>0.025758</td>\n",
       "      <td>1.656085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 5, 5, 2]</td>\n",
       "      <td>0.418820</td>\n",
       "      <td>0.025961</td>\n",
       "      <td>1.729211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 3, 6, 6, 2]</td>\n",
       "      <td>0.417511</td>\n",
       "      <td>0.031097</td>\n",
       "      <td>1.512139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7800</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[3, 4, 5, 5, 3]</td>\n",
       "      <td>0.416591</td>\n",
       "      <td>0.026329</td>\n",
       "      <td>1.814584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3874</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 6, 6, 5, 5]</td>\n",
       "      <td>0.413316</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>2.146908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 6, 2, 4]</td>\n",
       "      <td>0.407589</td>\n",
       "      <td>0.031051</td>\n",
       "      <td>1.607253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1, 2, 6, 2, 2]</td>\n",
       "      <td>0.404846</td>\n",
       "      <td>0.016115</td>\n",
       "      <td>1.613003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 3, 2, 3]</td>\n",
       "      <td>0.404743</td>\n",
       "      <td>0.028854</td>\n",
       "      <td>1.553027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 3, 5, 2, 3]</td>\n",
       "      <td>0.404606</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>1.579895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 5, 1, 3]</td>\n",
       "      <td>0.402160</td>\n",
       "      <td>0.029302</td>\n",
       "      <td>1.656403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 4, 5, 2]</td>\n",
       "      <td>0.398587</td>\n",
       "      <td>0.012604</td>\n",
       "      <td>1.702158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 3, 2, 1]</td>\n",
       "      <td>0.398484</td>\n",
       "      <td>0.056129</td>\n",
       "      <td>1.307222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 3, 4, 2, 3]</td>\n",
       "      <td>0.393708</td>\n",
       "      <td>0.028691</td>\n",
       "      <td>1.802790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4823</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 1, 2, 2]</td>\n",
       "      <td>0.389663</td>\n",
       "      <td>0.043716</td>\n",
       "      <td>1.465619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[2, 2, 6, 5, 6]</td>\n",
       "      <td>0.388204</td>\n",
       "      <td>0.032131</td>\n",
       "      <td>1.898526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 5, 5, 4]</td>\n",
       "      <td>0.387669</td>\n",
       "      <td>0.024006</td>\n",
       "      <td>1.727103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 1, 2, 2]</td>\n",
       "      <td>0.386067</td>\n",
       "      <td>0.030972</td>\n",
       "      <td>1.572112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 1, 3, 2, 3]</td>\n",
       "      <td>0.377915</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>1.316049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[5, 2, 5, 5, 3]</td>\n",
       "      <td>0.372088</td>\n",
       "      <td>0.031593</td>\n",
       "      <td>1.650165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 3, 5, 2, 3]</td>\n",
       "      <td>0.363290</td>\n",
       "      <td>0.031706</td>\n",
       "      <td>1.820268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5051</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[3, 2, 2, 2, 1]</td>\n",
       "      <td>0.360131</td>\n",
       "      <td>0.057476</td>\n",
       "      <td>1.310611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9858 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "13710  GradientBoostingClassifier  [6, 1, 3, 3, 5]  0.914520     0.008447   \n",
       "13885  GradientBoostingClassifier  [6, 1, 3, 6, 5]  0.909314     0.015718   \n",
       "12932  GradientBoostingClassifier  [6, 1, 1, 3, 4]  0.899511     0.013050   \n",
       "13766  GradientBoostingClassifier  [6, 5, 2, 3, 4]  0.897565     0.009551   \n",
       "13834  GradientBoostingClassifier  [4, 1, 3, 6, 5]  0.894677     0.015286   \n",
       "13663  GradientBoostingClassifier  [6, 1, 4, 3, 4]  0.893399     0.015777   \n",
       "13659  GradientBoostingClassifier  [6, 3, 3, 3, 3]  0.890230     0.010172   \n",
       "13197  GradientBoostingClassifier  [6, 5, 3, 4, 5]  0.890197     0.010327   \n",
       "12973  GradientBoostingClassifier  [3, 1, 3, 6, 5]  0.888997     0.015706   \n",
       "12994  GradientBoostingClassifier  [6, 1, 2, 1, 4]  0.888728     0.019052   \n",
       "13238  GradientBoostingClassifier  [4, 1, 2, 6, 5]  0.888433     0.014720   \n",
       "13781  GradientBoostingClassifier  [6, 1, 3, 3, 2]  0.888287     0.012881   \n",
       "14080  GradientBoostingClassifier  [6, 1, 2, 6, 2]  0.887072     0.013476   \n",
       "14088  GradientBoostingClassifier  [6, 1, 3, 6, 3]  0.887071     0.018922   \n",
       "13667  GradientBoostingClassifier  [6, 1, 3, 6, 4]  0.886797     0.015271   \n",
       "14037  GradientBoostingClassifier  [6, 1, 3, 5, 5]  0.886511     0.019177   \n",
       "13249  GradientBoostingClassifier  [6, 1, 3, 4, 3]  0.886308     0.014434   \n",
       "14464            VotingClassifier  [6, 1, 2, 3, 5]  0.886269     0.011046   \n",
       "13359  GradientBoostingClassifier  [4, 1, 3, 3, 5]  0.885065     0.010298   \n",
       "13296  GradientBoostingClassifier  [6, 5, 3, 6, 5]  0.884823     0.011447   \n",
       "13357  GradientBoostingClassifier  [6, 4, 3, 3, 3]  0.884396     0.014626   \n",
       "13102  GradientBoostingClassifier  [6, 6, 1, 3, 4]  0.884352     0.015074   \n",
       "12917  GradientBoostingClassifier  [6, 6, 6, 1, 5]  0.884290     0.009167   \n",
       "14081  GradientBoostingClassifier  [6, 1, 1, 5, 5]  0.883553     0.023536   \n",
       "11924      RandomForestClassifier  [6, 1, 3, 3, 3]  0.883404     0.012360   \n",
       "13541  GradientBoostingClassifier  [4, 1, 2, 6, 4]  0.883207     0.015085   \n",
       "13730  GradientBoostingClassifier  [6, 1, 2, 6, 3]  0.883155     0.013181   \n",
       "14020  GradientBoostingClassifier  [6, 1, 4, 6, 4]  0.882966     0.014815   \n",
       "13974  GradientBoostingClassifier  [6, 5, 2, 6, 2]  0.882644     0.010790   \n",
       "12942  GradientBoostingClassifier  [6, 5, 4, 3, 6]  0.882582     0.009466   \n",
       "...                           ...              ...       ...          ...   \n",
       "3906                MLPClassifier  [3, 4, 6, 4, 3]  0.425824     0.035387   \n",
       "4681                MLPClassifier  [5, 2, 5, 2, 1]  0.425169     0.051252   \n",
       "7993           LogisticRegression  [4, 2, 1, 5, 4]  0.424943     0.022083   \n",
       "3950                MLPClassifier  [3, 2, 3, 6, 3]  0.423095     0.036652   \n",
       "4506                MLPClassifier  [5, 3, 1, 2, 4]  0.422120     0.033957   \n",
       "4694                MLPClassifier  [5, 3, 4, 2, 3]  0.421569     0.030007   \n",
       "3872                MLPClassifier  [3, 5, 1, 5, 2]  0.420686     0.019816   \n",
       "8117           LogisticRegression  [3, 2, 2, 5, 3]  0.420189     0.022776   \n",
       "7795           LogisticRegression  [5, 2, 5, 2, 3]  0.419962     0.017596   \n",
       "8167           LogisticRegression  [5, 2, 4, 5, 3]  0.419086     0.025758   \n",
       "4482                MLPClassifier  [5, 3, 5, 5, 2]  0.418820     0.025961   \n",
       "3949                MLPClassifier  [1, 3, 6, 6, 2]  0.417511     0.031097   \n",
       "7800           LogisticRegression  [3, 4, 5, 5, 3]  0.416591     0.026329   \n",
       "3874                MLPClassifier  [3, 6, 6, 5, 5]  0.413316     0.030596   \n",
       "4036                MLPClassifier  [1, 2, 6, 2, 4]  0.407589     0.031051   \n",
       "3947                MLPClassifier  [1, 2, 6, 2, 2]  0.404846     0.016115   \n",
       "3964                MLPClassifier  [3, 3, 3, 2, 3]  0.404743     0.028854   \n",
       "4117                MLPClassifier  [5, 3, 5, 2, 3]  0.404606     0.018800   \n",
       "4562                MLPClassifier  [3, 3, 5, 1, 3]  0.402160     0.029302   \n",
       "3864                MLPClassifier  [3, 2, 4, 5, 2]  0.398587     0.012604   \n",
       "5104                MLPClassifier  [3, 2, 3, 2, 1]  0.398484     0.056129   \n",
       "4023                MLPClassifier  [2, 3, 4, 2, 3]  0.393708     0.028691   \n",
       "4823                MLPClassifier  [5, 2, 1, 2, 2]  0.389663     0.043716   \n",
       "3882                MLPClassifier  [2, 2, 6, 5, 6]  0.388204     0.032131   \n",
       "3948                MLPClassifier  [3, 2, 5, 5, 4]  0.387669     0.024006   \n",
       "4727                MLPClassifier  [5, 2, 1, 2, 2]  0.386067     0.030972   \n",
       "4080                MLPClassifier  [3, 1, 3, 2, 3]  0.377915     0.047700   \n",
       "4623                MLPClassifier  [5, 2, 5, 5, 3]  0.372088     0.031593   \n",
       "4130                MLPClassifier  [3, 3, 5, 2, 3]  0.363290     0.031706   \n",
       "5051                MLPClassifier  [3, 2, 2, 2, 1]  0.360131     0.057476   \n",
       "\n",
       "       errorMetrico  \n",
       "13710      0.185316  \n",
       "13885      0.192849  \n",
       "12932      0.213565  \n",
       "13766      0.253806  \n",
       "13834      0.232884  \n",
       "13663      0.247722  \n",
       "13659      0.309097  \n",
       "13197      0.397993  \n",
       "12973      0.251329  \n",
       "12994      0.239938  \n",
       "13238      0.273324  \n",
       "13781      0.249248  \n",
       "14080      0.263528  \n",
       "14088      0.237948  \n",
       "13667      0.256995  \n",
       "14037      0.279001  \n",
       "13249      0.264331  \n",
       "14464      0.262776  \n",
       "13359      0.263297  \n",
       "13296      0.378032  \n",
       "13357      0.287472  \n",
       "13102      0.314145  \n",
       "12917      0.335713  \n",
       "14081      0.302603  \n",
       "11924      0.253545  \n",
       "13541      0.228999  \n",
       "13730      0.210433  \n",
       "14020      0.252833  \n",
       "13974      0.273048  \n",
       "12942      0.317966  \n",
       "...             ...  \n",
       "3906       1.551527  \n",
       "4681       1.279422  \n",
       "7993       1.456938  \n",
       "3950       1.849872  \n",
       "4506       1.485792  \n",
       "4694       1.626150  \n",
       "3872       1.588580  \n",
       "8117       1.768278  \n",
       "7795       1.585194  \n",
       "8167       1.656085  \n",
       "4482       1.729211  \n",
       "3949       1.512139  \n",
       "7800       1.814584  \n",
       "3874       2.146908  \n",
       "4036       1.607253  \n",
       "3947       1.613003  \n",
       "3964       1.553027  \n",
       "4117       1.579895  \n",
       "4562       1.656403  \n",
       "3864       1.702158  \n",
       "5104       1.307222  \n",
       "4023       1.802790  \n",
       "4823       1.465619  \n",
       "3882       1.898526  \n",
       "3948       1.727103  \n",
       "4727       1.572112  \n",
       "4080       1.316049  \n",
       "4623       1.650165  \n",
       "4130       1.820268  \n",
       "5051       1.310611  \n",
       "\n",
       "[9858 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame(lista_resultados).sort_values(['Accuracy'],ascending=False).drop_duplicates(subset=['Modelo', 'Accuracy', 'stdAccuracy', 'errorMetrico'])\n",
    "df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']].to_csv('EDAS_resultados.csv', sep=',', index=False) \n",
    "display(df[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>errorMetrico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13710</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>0.914520</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.185316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14464</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 5]</td>\n",
       "      <td>0.886269</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.262776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11924</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.883404</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>0.253545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10745</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.873142</td>\n",
       "      <td>0.018847</td>\n",
       "      <td>0.245679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9134</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[4, 1, 3, 3, 5]</td>\n",
       "      <td>0.868684</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>0.260445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[6, 1, 2, 3, 1]</td>\n",
       "      <td>0.866290</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>0.306281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>0.846975</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>0.357501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>0.837207</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.379879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>SVC</td>\n",
       "      <td>[6, 6, 3, 3, 5]</td>\n",
       "      <td>0.829563</td>\n",
       "      <td>0.017179</td>\n",
       "      <td>0.511966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[5, 1, 3, 3, 1]</td>\n",
       "      <td>0.735863</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>0.610679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[6, 1, 2, 3, 5]</td>\n",
       "      <td>0.699953</td>\n",
       "      <td>0.015875</td>\n",
       "      <td>0.721217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5044</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[4, 1, 2, 1, 1]</td>\n",
       "      <td>0.678574</td>\n",
       "      <td>0.034266</td>\n",
       "      <td>0.751279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Modelo    Configuracion  Accuracy  stdAccuracy  \\\n",
       "13710  GradientBoostingClassifier  [6, 1, 3, 3, 5]  0.914520     0.008447   \n",
       "14464            VotingClassifier  [6, 1, 2, 3, 5]  0.886269     0.011046   \n",
       "11924      RandomForestClassifier  [6, 1, 3, 3, 3]  0.883404     0.012360   \n",
       "10745          AdaBoostClassifier  [6, 1, 3, 3, 3]  0.873142     0.018847   \n",
       "9134         ExtraTreesClassifier  [4, 1, 3, 3, 5]  0.868684     0.008641   \n",
       "5543         KNeighborsClassifier  [6, 1, 2, 3, 1]  0.866290     0.010901   \n",
       "3591                   GaussianNB  [6, 1, 3, 3, 1]  0.846975     0.014854   \n",
       "6810       DecisionTreeClassifier  [6, 1, 3, 3, 3]  0.837207     0.012857   \n",
       "2103                          SVC  [6, 6, 3, 3, 5]  0.829563     0.017179   \n",
       "404    LinearDiscriminantAnalysis  [5, 1, 3, 3, 1]  0.735863     0.018565   \n",
       "8060           LogisticRegression  [6, 1, 2, 3, 5]  0.699953     0.015875   \n",
       "5044                MLPClassifier  [4, 1, 2, 1, 1]  0.678574     0.034266   \n",
       "\n",
       "       errorMetrico  \n",
       "13710      0.185316  \n",
       "14464      0.262776  \n",
       "11924      0.253545  \n",
       "10745      0.245679  \n",
       "9134       0.260445  \n",
       "5543       0.306281  \n",
       "3591       0.357501  \n",
       "6810       0.379879  \n",
       "2103       0.511966  \n",
       "404        0.610679  \n",
       "8060       0.721217  \n",
       "5044       0.751279  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#topDf = df.drop_duplicates(subset=['Modelo'])\n",
    "#display(topDf)\n",
    "#pd.DataFrame(salida).sort_values(['Accuracy'], ascending=False)\n",
    "topDf=df.drop_duplicates(subset=['Modelo'])#.drop_duplicates()\n",
    "topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']].to_csv('EDAS_resultados_top.csv', sep=',', index=False) \n",
    "display(topDf[['Modelo', 'Configuracion', 'Accuracy', 'stdAccuracy', 'errorMetrico']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#dataframe_plot = topDf\n",
    "def column_boxplot(dataframe_plot, column_plot, filename, box_bool=True):\n",
    "    %pylab inline\n",
    "    pylab.rcParams['figure.figsize'] = (14, 8)\n",
    "    previos = ['LogisticRegression', 'LinearDiscriminantAnalysis', 'GaussianNB', 'MLPClassifier', \n",
    "               'SVC', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'RandomForestClassifier', \n",
    "               'ExtraTreesClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier', 'VotingClassifier']\n",
    "    nuevos = ['LoR', 'LDA', 'GNB', 'MLP', 'SVC', 'DT', 'k-NN', 'RF', 'ET', 'GBM', 'AB', 'VC']\n",
    "    num_models = len(nuevos)\n",
    "    dataframe_plot = dataframe_plot[['Modelo', 'Configuracion', 'Accuracy', 'errorMetrico', 'values', 'error']]\n",
    "    for i in range(num_models):\n",
    "        dataframe_plot['Modelo'] = dataframe_plot['Modelo'].str.replace(previos[i], nuevos[i])\n",
    "        #df['Modelo'] = df['Modelo'].str.replace('LinearDiscriminantAnalysis','LDA')\n",
    "    sorterIndex = dict(zip(nuevos,range(num_models)))\n",
    "    #test\n",
    "    dataframe_plot['Model_Rank'] = dataframe_plot['Modelo'].map(sorterIndex)\n",
    "    dataframe_plot = dataframe_plot.sort_values(['Model_Rank'],ascending=True).reset_index(drop=True)[dataframe_plot.columns[:-1]]\n",
    "    if column_plot == 'values':\n",
    "        y_label = 'Score'\n",
    "        x_label = 'Model'\n",
    "    else:\n",
    "        y_label = 'Error (m)'\n",
    "        x_label = 'Model Evaluated'\n",
    "    lista_plot = []\n",
    "    for i in range(num_models):\n",
    "        num_splits = len(list(dataframe_plot[column_plot])[i])\n",
    "        for j in range(num_splits):\n",
    "            d = {x_label:nuevos[i], y_label:dataframe_plot[column_plot][i][j]}\n",
    "            lista_plot.append(d)\n",
    "    #pd.DataFrame(lista_plot)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    if column_plot == 'values':\n",
    "        ax_plot = sns.boxplot(data=pd.DataFrame(lista_plot), x=x_label, y=y_label, linewidth = 1.0)\n",
    "    else:\n",
    "        #ax_plot = sns.barplot(data=pd.DataFrame(lista_plot), x=x_label, y=y_label, linewidth = 1.0)\n",
    "        if box_bool==True:\n",
    "            ax_plot = sns.boxplot(data=pd.DataFrame(lista_plot), x=x_label, y=y_label, linewidth = 1.0)\n",
    "        else:\n",
    "            ax_plot = sns.barplot(data=pd.DataFrame(lista_plot), x=x_label, y=y_label, linewidth = 1.0)\n",
    "    plt.format='eps'\n",
    "    if column_plot == 'values':\n",
    "        medians = np.round(list(dataframe_plot['Accuracy']),3)\n",
    "        tope = 0.98\n",
    "    else:\n",
    "        medians = np.round(list(dataframe_plot['errorMetrico']),3)\n",
    "        if box_bool==True:\n",
    "            tope = 6.8\n",
    "        else:\n",
    "            tope = 2.8\n",
    "    median_labels = [str(s) for s in medians]\n",
    "    pos = range(num_models)\n",
    "    for tick,label in zip(pos,ax_plot.get_xticklabels()):\n",
    "        ax_plot.text(pos[tick], tope, median_labels[tick], \n",
    "                horizontalalignment='center', color='black') #, weight='semibold'\n",
    "    axes = plt.gca()\n",
    "    if column_plot == 'values':\n",
    "        axes.set_ylim([0.3,1.0])\n",
    "    else:\n",
    "        axes.set_ylim([-0.1, tope+0.2])\n",
    "    plt.savefig(filename + \".eps\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy EDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAHeCAYAAABT+34JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac766f7588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'values', 'accuracy_edas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error EDAS Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzEAAAHeCAYAAACrG4X+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVBRiREREREQkqCjEiIiIiIhIUPkLoZojEycWTGoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac7431e5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'error', 'error_edas_box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAHeCAYAAABT+34JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsoP/j9EVs3EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faca01ac978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "column_boxplot(topDf, 'error', 'error_edas_bar', box_bool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Configuracion</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>error</th>\n",
       "      <th>errorMetrico</th>\n",
       "      <th>stdAccuracy</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13710</th>\n",
       "      <td>0.914520</td>\n",
       "      <td>[6, 1, 3, 3, 5]</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.12132034356, 0.0, ...</td>\n",
       "      <td>0.185316</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>[0.915841584158, 0.898514851485, 0.91584158415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14464</th>\n",
       "      <td>0.886269</td>\n",
       "      <td>[6, 1, 2, 3, 5]</td>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>[0.0, 0.0, 3.35410196625, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.262776</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>[0.883663366337, 0.89603960396, 0.886138613861...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11924</th>\n",
       "      <td>0.883404</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.253545</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>[0.878048780488, 0.887530562347, 0.89975550122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10745</th>\n",
       "      <td>0.873142</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.245679</td>\n",
       "      <td>0.018847</td>\n",
       "      <td>[0.851219512195, 0.855745721271, 0.89731051344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9134</th>\n",
       "      <td>0.868684</td>\n",
       "      <td>[4, 1, 3, 3, 5]</td>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>[3.0, 3.35410196625, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.260445</td>\n",
       "      <td>0.008641</td>\n",
       "      <td>[0.861751152074, 0.873271889401, 0.86405529953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>0.866290</td>\n",
       "      <td>[6, 1, 2, 3, 1]</td>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.306281</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>[0.873170731707, 0.848410757946, 0.87286063569...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>0.846975</td>\n",
       "      <td>[6, 1, 3, 3, 1]</td>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...</td>\n",
       "      <td>0.357501</td>\n",
       "      <td>0.014854</td>\n",
       "      <td>[0.873170731707, 0.863080684597, 0.85574572127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810</th>\n",
       "      <td>0.837207</td>\n",
       "      <td>[6, 1, 3, 3, 3]</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.379879</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>[0.824390243902, 0.850855745721, 0.83374083129...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>0.829563</td>\n",
       "      <td>[6, 6, 3, 3, 5]</td>\n",
       "      <td>SVC</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.511966</td>\n",
       "      <td>0.017179</td>\n",
       "      <td>[0.845588235294, 0.833333333333, 0.78624078624...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.735863</td>\n",
       "      <td>[5, 1, 3, 3, 1]</td>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 2.12132034356, 0.0, 0.0, ...</td>\n",
       "      <td>0.610679</td>\n",
       "      <td>0.018565</td>\n",
       "      <td>[0.697940503432, 0.755148741419, 0.73455377574...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060</th>\n",
       "      <td>0.699953</td>\n",
       "      <td>[6, 1, 2, 3, 5]</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>[0.0, 0.0, 3.35410196625, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.721217</td>\n",
       "      <td>0.015875</td>\n",
       "      <td>[0.690594059406, 0.712871287129, 0.68564356435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5044</th>\n",
       "      <td>0.678574</td>\n",
       "      <td>[4, 1, 2, 1, 1]</td>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>[1.5, 0.0, 3.35410196625, 0.0, 3.0, 2.12132034...</td>\n",
       "      <td>0.751279</td>\n",
       "      <td>0.034266</td>\n",
       "      <td>[0.683438155136, 0.618448637317, 0.68553459119...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accuracy    Configuracion                      Modelo  \\\n",
       "13710  0.914520  [6, 1, 3, 3, 5]  GradientBoostingClassifier   \n",
       "14464  0.886269  [6, 1, 2, 3, 5]            VotingClassifier   \n",
       "11924  0.883404  [6, 1, 3, 3, 3]      RandomForestClassifier   \n",
       "10745  0.873142  [6, 1, 3, 3, 3]          AdaBoostClassifier   \n",
       "9134   0.868684  [4, 1, 3, 3, 5]        ExtraTreesClassifier   \n",
       "5543   0.866290  [6, 1, 2, 3, 1]        KNeighborsClassifier   \n",
       "3591   0.846975  [6, 1, 3, 3, 1]                  GaussianNB   \n",
       "6810   0.837207  [6, 1, 3, 3, 3]      DecisionTreeClassifier   \n",
       "2103   0.829563  [6, 6, 3, 3, 5]                         SVC   \n",
       "404    0.735863  [5, 1, 3, 3, 1]  LinearDiscriminantAnalysis   \n",
       "8060   0.699953  [6, 1, 2, 3, 5]          LogisticRegression   \n",
       "5044   0.678574  [4, 1, 2, 1, 1]               MLPClassifier   \n",
       "\n",
       "                                                   error  errorMetrico  \\\n",
       "13710  [0.0, 0.0, 0.0, 0.0, 0.0, 2.12132034356, 0.0, ...      0.185316   \n",
       "14464  [0.0, 0.0, 3.35410196625, 0.0, 0.0, 0.0, 0.0, ...      0.262776   \n",
       "11924  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.253545   \n",
       "10745  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.245679   \n",
       "9134   [3.0, 3.35410196625, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.260445   \n",
       "5543   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.306281   \n",
       "3591   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.121...      0.357501   \n",
       "6810   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.379879   \n",
       "2103   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...      0.511966   \n",
       "404    [0.0, 0.0, 0.0, 0.0, 2.12132034356, 0.0, 0.0, ...      0.610679   \n",
       "8060   [0.0, 0.0, 3.35410196625, 0.0, 0.0, 0.0, 0.0, ...      0.721217   \n",
       "5044   [1.5, 0.0, 3.35410196625, 0.0, 3.0, 2.12132034...      0.751279   \n",
       "\n",
       "       stdAccuracy                                             values  \n",
       "13710     0.008447  [0.915841584158, 0.898514851485, 0.91584158415...  \n",
       "14464     0.011046  [0.883663366337, 0.89603960396, 0.886138613861...  \n",
       "11924     0.012360  [0.878048780488, 0.887530562347, 0.89975550122...  \n",
       "10745     0.018847  [0.851219512195, 0.855745721271, 0.89731051344...  \n",
       "9134      0.008641  [0.861751152074, 0.873271889401, 0.86405529953...  \n",
       "5543      0.010901  [0.873170731707, 0.848410757946, 0.87286063569...  \n",
       "3591      0.014854  [0.873170731707, 0.863080684597, 0.85574572127...  \n",
       "6810      0.012857  [0.824390243902, 0.850855745721, 0.83374083129...  \n",
       "2103      0.017179  [0.845588235294, 0.833333333333, 0.78624078624...  \n",
       "404       0.018565  [0.697940503432, 0.755148741419, 0.73455377574...  \n",
       "8060      0.015875  [0.690594059406, 0.712871287129, 0.68564356435...  \n",
       "5044      0.034266  [0.683438155136, 0.618448637317, 0.68553459119...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topDf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
