{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Librería Genética\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "# Subfunciones de estimadores\n",
    "from sklearn.base import clone\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][30]\n",
    "from sklearn.base import is_classifier\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py][535]\n",
    "from sklearn.model_selection._validation import _fit_and_score\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_validation.py][346]\n",
    "from sklearn.model_selection._search import BaseSearchCV\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][386]\n",
    "from sklearn.model_selection._search import check_cv\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_split.py][1866]\n",
    "from sklearn.model_selection._search import _check_param_grid\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/model_selection/_search.py][343]\n",
    "from sklearn.metrics.scorer import check_scoring\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/metrics/scorer.py][250]\n",
    "from sklearn.utils.validation import _num_samples\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][105]\n",
    "from sklearn.utils.validation import indexable\n",
    "# [https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/validation.py][208]\n",
    "from multiprocessing import Pool, Manager\n",
    "\n",
    "# Selección para estimadores\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Metricas para estimadores\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Estimadores\n",
    "from sklearn.ensemble import ExtraTreesClassifier#\n",
    "from sklearn.ensemble import RandomForestClassifier#\n",
    "from sklearn.ensemble import AdaBoostClassifier#\n",
    "from sklearn.ensemble import GradientBoostingClassifier#\n",
    "from sklearn.tree import DecisionTreeClassifier#\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "PYMACH\n",
    "\"\"\"\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "#Algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Ensembles algorithms\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "\n",
    "# The problem to optimize\n",
    "def evaluate( frecuencias, individual, estimator, score_cache={}, error_cache={}, n_splits = 10, shuffle = False, scorer = \"accuracy\"):\n",
    "\tX,y = _createDataset(frecuencias, individual)\n",
    "\tscore = 0\n",
    "\tparamkey = str(np.int32(individual)+1)\n",
    "\tif paramkey in score_cache:\n",
    "\t\tscore = score_cache[paramkey]\n",
    "\t\terror = error_cache[paramkey]\n",
    "\telse:\n",
    "\t\tkfold = KFold(n_splits=n_splits, shuffle=shuffle)\n",
    "\t\tcv_results = cross_val_score(estimator, X, y, cv=kfold, scoring=scorer)\n",
    "\t\tscore = cv_results.mean()\n",
    "\t\terror = cv_results.std()\n",
    "\t\tscore_cache[paramkey] = score\n",
    "\t\terror_cache[paramkey] = error\n",
    "\treturn score, error\n",
    "\n",
    "\n",
    "def _createDataset(frecuencias, values, seed = 7):\n",
    "    # crear dataset\n",
    "    names_ = frecuencias[0].columns.values\n",
    "    # reestructuracion\n",
    "    salida_final = pd.DataFrame(columns=names_)\n",
    "    for sec in range(1,16):\n",
    "        dataset = pd.DataFrame(columns=names_)\n",
    "        corte = min([frecuencias[i][frecuencias[i]['Sector']==sec].shape[0] for i in values])\n",
    "        tx = 0\n",
    "        dataset[names_[tx]] = dataset[names_[tx]].append(frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]])\n",
    "        for tx in range(1,5):\n",
    "            dataset[names_[tx]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx]]\n",
    "        dataset[names_[tx+1]] = frecuencias[int(values[tx])][frecuencias[int(values[tx])]['Sector']==sec][:corte][names_[tx+1]]\n",
    "        # join parts\n",
    "        salida_final = salida_final.append(dataset)\n",
    "    # shuffle dataset\n",
    "    salida_final = shuffle(salida_final, random_state=seed).reset_index(drop=True)\n",
    "    salida_final = salida_final.apply(pd.to_numeric)\n",
    "    # dataframe to X,y \n",
    "    X = salida_final[names_[:-1]]\n",
    "    y = salida_final[names_[-1]]\n",
    "    return X,y\n",
    "\n",
    "def set_models():\n",
    "    rs = 1\n",
    "    models = []\n",
    "    # LDA : Warning(Variables are collinear)\n",
    "    models.append(('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()))\n",
    "    models.append(('SVC', SVC(random_state=rs)))\n",
    "    models.append(('GaussianNB', GaussianNB()))\n",
    "    models.append(('MLPClassifier', MLPClassifier()))\n",
    "    models.append(('KNeighborsClassifier', KNeighborsClassifier()))\n",
    "    models.append(('DecisionTreeClassifier', DecisionTreeClassifier(random_state=rs)))\n",
    "    models.append(('LogisticRegression', LogisticRegression()))\n",
    "    # Bagging and Boosting\n",
    "    # models.append(('ExtraTreesClassifier', ExtraTreesClassifier(n_estimators=150)))\n",
    "    models.append(('ExtraTreesClassifier', ExtraTreesClassifier(random_state=rs)))\n",
    "    models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier(random_state=rs),\n",
    "                                                            random_state=rs)))\n",
    "    # models.append(('AdaBoostClassifier', AdaBoostClassifier(DecisionTreeClassifier())))\n",
    "    models.append(('RandomForestClassifier', RandomForestClassifier(random_state=rs)))\n",
    "    models.append(('GradientBoostingClassifier',\n",
    "                   GradientBoostingClassifier(random_state=rs)))\n",
    "    # models.append(('GradientBoostingClassifier', GradientBoostingClassifier()))\n",
    "    # Voting\n",
    "    estimators = []\n",
    "    estimators.append((\"Voting_GradientBoostingClassifier\", GradientBoostingClassifier(random_state=rs)))\n",
    "    estimators.append((\"Voting_ExtraTreesClassifier\", ExtraTreesClassifier(random_state=rs)))\n",
    "    voting = VotingClassifier(estimators)\n",
    "    models.append(('VotingClassifier', voting))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling... LinearDiscriminantAnalysis \n",
      "\n",
      "LinearDiscriminantAnalysis [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "LinearDiscriminantAnalysis [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "LinearDiscriminantAnalysis [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "/home/oscarhc/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:442: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... SVC \n",
      "\n",
      "SVC [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "SVC [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "SVC [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "SVC [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "SVC [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "SVC [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... GaussianNB \n",
      "\n",
      "GaussianNB [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "GaussianNB [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "GaussianNB [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "GaussianNB [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "GaussianNB [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "GaussianNB [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... MLPClassifier \n",
      "\n",
      "MLPClassifier [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "MLPClassifier [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "MLPClassifier [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "MLPClassifier [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "MLPClassifier [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "MLPClassifier [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... KNeighborsClassifier \n",
      "\n",
      "KNeighborsClassifier [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "KNeighborsClassifier [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "KNeighborsClassifier [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "KNeighborsClassifier [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "KNeighborsClassifier [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "KNeighborsClassifier [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... DecisionTreeClassifier \n",
      "\n",
      "DecisionTreeClassifier [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "DecisionTreeClassifier [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "DecisionTreeClassifier [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "DecisionTreeClassifier [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "DecisionTreeClassifier [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "DecisionTreeClassifier [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... LogisticRegression \n",
      "\n",
      "LogisticRegression [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "LogisticRegression [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "LogisticRegression [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "LogisticRegression [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "LogisticRegression [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "LogisticRegression [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... ExtraTreesClassifier \n",
      "\n",
      "ExtraTreesClassifier [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "ExtraTreesClassifier [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "ExtraTreesClassifier [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "ExtraTreesClassifier [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "ExtraTreesClassifier [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "ExtraTreesClassifier [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... AdaBoostClassifier \n",
      "\n",
      "AdaBoostClassifier [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "AdaBoostClassifier [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "AdaBoostClassifier [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "AdaBoostClassifier [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "AdaBoostClassifier [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "AdaBoostClassifier [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... RandomForestClassifier \n",
      "\n",
      "RandomForestClassifier [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "RandomForestClassifier [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "RandomForestClassifier [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "RandomForestClassifier [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "RandomForestClassifier [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "RandomForestClassifier [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... GradientBoostingClassifier \n",
      "\n",
      "GradientBoostingClassifier [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "GradientBoostingClassifier [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "GradientBoostingClassifier [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "GradientBoostingClassifier [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "GradientBoostingClassifier [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "GradientBoostingClassifier [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n",
      "Modeling... VotingClassifier \n",
      "\n",
      "VotingClassifier [0, 0, 0, 0, 0]\t0.638416766467\t0.0187798305257\n",
      "VotingClassifier [1, 1, 1, 1, 1]\t0.520026421949\t0.0105850241566\n",
      "VotingClassifier [2, 2, 2, 2, 2]\t0.586515323426\t0.0181231830843\n",
      "VotingClassifier [3, 3, 3, 3, 3]\t0.637316773242\t0.0172482980064\n",
      "VotingClassifier [4, 4, 4, 4, 4]\t0.568553958315\t0.0196238575959\n",
      "VotingClassifier [5, 5, 5, 5, 5]\t0.676727161251\t0.0181642713004\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "frecuencias = []\n",
    "names_ = ['Be01', 'Be02', 'Be03', 'Be04', 'Be05', 'Sector']\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx1.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx2.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx3.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx4.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx5.csv', names=names_))\n",
    "frecuencias.append(pd.read_csv('Filtrado/LocalizationNew_Tx6.csv', names=names_))\n",
    "num_jobs=8\n",
    "estimadores = set_models()\n",
    "salida = {}\n",
    "\n",
    "for name, model in estimadores:\n",
    "    print(\"Modeling...\", name, \"\\n\")\n",
    "    splits = 10\n",
    "    simetricas = [[i]*5 for i in range(6)]\n",
    "    for individual in simetricas:\n",
    "        acc, err = evaluate( frecuencias, individual, model, n_splits = splits, shuffle = False, scorer = \"accuracy\")\n",
    "        salida[str(name)+\"-\"+str(individual)] = str(acc) +\"\\t\"+ str(err)\n",
    "        print(str(name) + \" \" + str(individual) + \"\\t\" + str(acc) + \"\\t\" + str(err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    def build_pipelines(self):\\n        pipelines = []\\n        models = self.set_models()\\n\\n        for m in models:\\n            pipelines.append((m[0],\\n                Pipeline([\\n                    ('preparer', self.preparer),\\n                    m,\\n                ])\\n            ))\\n\\n        self.pipelines = pipelines\\n\\n        return pipelines\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    def build_pipelines(self):\n",
    "        pipelines = []\n",
    "        models = self.set_models()\n",
    "\n",
    "        for m in models:\n",
    "            pipelines.append((m[0],\n",
    "                Pipeline([\n",
    "                    ('preparer', self.preparer),\n",
    "                    m,\n",
    "                ])\n",
    "            ))\n",
    "\n",
    "        self.pipelines = pipelines\n",
    "\n",
    "        return pipelines\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
